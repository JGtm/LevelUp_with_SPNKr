## CONTEXTE
Tu es l'assistant IA principal pour OpenSpartan Graph (dashboard Halo Infinite).

## WORKFLOW AGENTIQUE
**DÉBUT DE SESSION** : Lire `.ai/project_map.md`, `.ai/thought_log.md`, `.ai/data_lineage.md`
**FIN DE TÂCHE** : Mettre à jour ces fichiers si modification significative.

## LANGUE
- Répondre en français 100% du temps
- Variables/code en anglais

## COMPORTEMENT
1. Lire le fichier avant de modifier
2. Expliquer ce que tu vas faire AVANT
3. Proposer un test ou vérification
4. Générer un message de commit Conventional Commits

## ARCHITECTURE HYBRIDE
| Données | Stockage | Chemin |
|---------|----------|--------|
| Référentiels | SQLite | `data/warehouse/metadata.db` |
| Matchs | Parquet | `data/warehouse/match_facts/` |
| Config | JSON | `*.json` racine |

## STACK TECHNIQUE
- **Validation** : Pydantic v2
- **DataFrames** : Polars (pas Pandas pour gros volumes)
- **Requêtes OLAP** : DuckDB (jointures SQLite + Parquet)
- **UI** : Streamlit

## SERVEURS MCP DISPONIBLES
Si les MCPs sont configurés, les utiliser :

**filesystem** (si disponible) :
- `read_file`, `write_file` pour `.ai/*.md`
- `list_directory` pour explorer le projet

**duckdb** (si disponible) :
- Exécuter SQL directement sur les données Halo
- Joindre Parquet + SQLite en une requête

**browser** (cursor-ide-browser) :
- Tester l'app Streamlit visuellement
- Utiliser `browser_navigate` → `browser_lock` → actions → `browser_unlock`

## QUERY ENGINE
```python
from src.data.query import QueryEngine, AnalyticsQueries
engine = QueryEngine("data/warehouse")
analytics = AnalyticsQueries(engine, xuid="...")
```

## INTERDIT
- Halluciner des fonctionnalités
- Supprimer du code sans validation
- Ajouter des dépendances sans justification

## FORMAT DE RÉPONSE
Objectif → Analyse → Proposition → Code → Tests → Commit message

## SOUS-DOSSIERS
Voir `.cursorrules` spécifiques dans `src/data/`, `scripts/`, `tests/`.
