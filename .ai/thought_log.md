# Thought Log - Journal de Raisonnement

> Ce fichier capture le raisonnement de l'agent entre les sessions.
> Archiv√© : 2026-02-01 (logs pr√©c√©dents dans `.ai/archive/thought_log_pre_phase6.md`)

---

## Journal

### [2026-02-11] - Sprints 3 + 4 (partiel) ‚Äî Damage participants, Carri√®re, UI am√©liorations

**Statut** : Sprint 3 livr√©, Sprint 4 partiellement livr√©

**Sprint 3A ‚Äî Damage participants** : Toutes les t√¢ches 3A.1 √† 3A.6 r√©alis√©es.

**Changements code (3A)** :
- `src/data/sync/models.py` : Ajout `damage_dealt: float | None` et `damage_taken: float | None` √† `MatchParticipantRow`
- `src/data/sync/transformers.py` : Extraction `DamageDealt`/`DamageTaken` via `_safe_float()` dans `extract_participants()`
- `src/data/sync/engine.py` : DDL mis √† jour (14 colonnes), migration `_ensure_match_participants_rank_score()` √©tendue, `_insert_participant_rows()` avec 14 colonnes
- `scripts/backfill_data.py` : 16+ points d'√©dition pour `--participants-damage` et `--force-participants-damage` (d√©tection, UPDATE, compteurs, argparse)
- `tests/test_participants_damage.py` (nouveau) : 10 tests couvrant extraction damage, valeurs None, z√©ro valide, multi-joueur

**Sprint 3B ‚Äî Page Carri√®re** : Toutes les t√¢ches 3B.1 √† 3B.5 r√©alis√©es.

**Changements code (3B)** :
- `src/ui/components/career_progress_circle.py` (nouveau) : Gauge Plotly `go.Indicator(mode="gauge+number")` avec couleurs par palier (rouge‚Üíambre‚Üícyan‚Üívert)
- `src/ui/pages/career.py` (nouveau) : Page compl√®te avec `_load_career_data()`, `_load_career_history()`, `_create_xp_history_chart()`, layout 3 colonnes (ic√¥ne, m√©triques, gauge) + historique XP
- `src/app/page_router.py` : "Carri√®re" ajout√© √† PAGES + dispatch
- `src/ui/pages/__init__.py` : Export `render_career_page`
- `streamlit_app.py` : Import + wiring `render_career_page_fn`
- `tests/test_career_page.py` (nouveau) : Tests gauge (go.Figure, max_rank, zero XP, custom height) + labels FR

**Sprint 4.0 ‚Äî Nettoyage duplications** : Livr√©.

- `src/visualization/distributions.py` : 4 copies dupliqu√©es de `plot_top_weapons()` supprim√©es (lignes 647, 891, 1070, 1221). Fichier pass√© de 1284 √† 1071 lignes. Une seule d√©finition conserv√©e (ligne 495).

**Sprint 4.1 ‚Äî M√©dianes sur histogrammes** : Livr√©.

- `plot_kda_distribution()` : Ligne m√©diane `add_vline` (dash ambre #ffaa00) avec annotation
- `plot_histogram()` : Ligne m√©diane apr√®s la section KDE
- `plot_first_event_distribution()` : M√©dianes frag et mort (dot ambre) en plus des moyennes existantes

**Sprint 4.2 ‚Äî Renommage Kills‚ÜíFrags** : Livr√©.

- Fichiers modifi√©s : `timeseries.py`, `session_compare.py`, `match_history.py`, `match_view_charts.py`, `objective_analysis.py`, `teammates.py`, `teammates_charts.py`
- "Kills" conserv√© uniquement dans `plot_top_weapons` (contexte armes sp√©cifique)

**Ce qui RESTE √† faire pour le Sprint 4** :

| T√¢che | Statut | D√©tail |
|-------|--------|--------|
| 4.3 Normalisation noms de mode | Pas commenc√© | Appliquer `translate_pair_name()` dans le graphe "Par mode" de `win_loss.py` |
| 4.M1 Migration Polars `distributions.py` | Pas commenc√© | Remplacer `_normalize_df()` par `_to_polars()`, migrer les fonctions simples |
| 4.M2 Migration Polars `timeseries.py` | Pas commenc√© | Convertir `dff` en Polars au d√©but, travailler en Polars |
| 4.M3+M4 Migration Polars `teammates.py` + `teammates_charts.py` | Pas commenc√© | Arr√™ter de convertir en Pandas, modifier signatures |
| 4.M6 Migration Polars `win_loss.py` | Pas commenc√© | Convertir en Polars pour la logique, garder `.to_pandas()` pour styler |
| 4.5 Features teammates | Pas commenc√© | Stats/min en barres, frags parfaits, radar trio |
| Tests Sprint 4 | Pas commenc√© | √âtendre test_visualizations.py, cr√©er tests normalisation/teammates |

**Analyse technique pour la reprise (4.M6 win_loss.py)** :
- Le fichier utilise `pivot_table`, `pd.to_datetime`, `.dt.to_period()`, et surtout `tbl.style.apply()` (Pandas styler)
- Strat√©gie recommand√©e : accepter `pl.DataFrame | pd.DataFrame`, convertir √† Polars au d√©but, passer Polars aux fonctions de distributions.py (qui g√®rent les deux types via `_normalize_df()`), convertir √† Pandas uniquement pour le pivot_table (section "Par p√©riode") et le styler (section map table)
- `plot_win_ratio_heatmap` et `plot_matches_at_top_by_week` n'ont PAS de `_normalize_df()` ‚Üí requi√®rent Pandas ‚Üí convertir avant appel
- `compute_map_breakdown` accepte d√©j√† les deux types, retourne Pandas

**Tests** : Non ex√©cutables en MSYS2 (duckdb absent ‚Äî limitation connue, pas une r√©gression).

---

### [2026-02-10] - Sprint 2 livr√© ‚Äî Migration Pandas‚ÜíPolars core

**Statut** : Livr√© (commit 245c91b)

---

### [2026-02-10] - Sprint 1 livr√© ‚Äî Nettoyage scripts + Archivage documentation

**Statut** : Livr√©

**Sprint 1 ‚Äî PLAN_UNIFIE.md** : Toutes les t√¢ches 1.1 √† 1.9 r√©alis√©es.

**R√©sultat scripts/** :
- 113 scripts ‚Üí **16 actifs** + 10 en `migration/` + 71 archiv√©s dans `_archive/` + 13 supprim√©s + 3 dans `_obsolete/` supprim√©
- 7 backfill redondants supprim√©s (couverts par `backfill_data.py`)
- 6 fix one-shot supprim√©s (corrections d√©j√† appliqu√©es)
- `scripts/_obsolete/` supprim√©
- 9 scripts `test_*`/`validate_*`/`verify_*` archiv√©s (√©quivalents dans `tests/`)

**R√©sultat .ai/** :
- 5 documents racine archiv√©s : `SUPER_PLAN.md`, `CODE_REVIEW_CLEANUP_PLAN.md`, `AGENT_ARCHITECTURE.md`, `ORCHESTRATION_PROMPTS.md`, `workflows.md` (consolid√©s dans `PLAN_UNIFIE.md`)
- Recherches killfeed (KILL_FEED_*.md, JSON, etc.) archiv√©es dans `.ai/archive/research/`

**Corrections** :
- `tests/test_spnkr_refactoring.py` : mis √† jour `sys.path` vers `scripts/_archive/` (spnkr_import_db.py archiv√©)
- Docstring `backfill_data.py` : document√© le workaround OR (ex√©cution par √©tapes recommand√©e)

**Tests** : 93 pass√©s, aucune r√©gression. √âchecs pr√©existants (pyarrow/duckdb absents en MSYS2).

---

### [2026-02-10] - Sprint 0 livr√© + Documentation environnement MSYS2

**Statut** : Livr√©

**Sprint 0 ‚Äî PLAN_UNIFIE.md** : Toutes les t√¢ches 0.1 √† 0.7 r√©alis√©es.

**Changements code** :
- `src/app/filters_render.py` : `_compute_trio_label()` utilise maintenant `max(start_time)` par session au lieu de `session_id.max()` pour trouver la derni√®re session trio. √âvite le tri lexicographique incorrect des session_id VARCHAR.
- `src/app/filters.py` : m√™me correction dans la version dupliqu√©e de `_compute_trio_label()`.
- `src/ui/filter_state.py` : ajout de `FILTER_DATA_KEYS`, `FILTER_WIDGET_KEY_PREFIXES` et `get_all_filter_keys_to_clear()` pour centraliser les cl√©s de filtres √† nettoyer lors du changement de joueur.
- `streamlit_app.py` : remplacement du nettoyage partiel (8 cl√©s hardcod√©es) par `get_all_filter_keys_to_clear()` qui couvre 15 cl√©s de donn√©es + toutes les cl√©s de widgets checkbox (`filter_playlists_*`, `filter_modes_*`, `filter_maps_*`).

**Tests** :
- `tests/test_session_last_button.py` (nouveau, 8 tests) : tri par `max(start_time)`, cas VARCHAR, cas trio.
- `tests/test_filter_state.py` (√©tendu, +7 tests) : `get_all_filter_keys_to_clear()`, simulation switch joueur A‚ÜíB‚ÜíA.

**Nettoyage** :
- `.venv_windows/` supprim√© (√©tait d√©j√† vide/cass√©)
- `levelup_halo.egg-info/` supprim√©
- `out/` vid√©

**Environnement MSYS2** :
- D√©couverte que `.venv` √©tait vide (aucun package) et que l'environnement est MSYS2/MinGW, pas Windows natif.
- Les packages C (numpy, pandas, polars) doivent √™tre install√©s via `pacman`, pas `pip`.
- DuckDB n'a pas de package MSYS2, donc les tests qui importent `duckdb` transitoirement √©chouent en `ModuleNotFoundError` ‚Äî c'est une limitation connue, pas une r√©gression.
- Venv recr√©√© avec `--system-site-packages` pour h√©riter des packages pacman.
- `.venv/bin/` (pas `.venv/Scripts/`) car MSYS2 suit les conventions Unix.
- Document√© dans `CLAUDE.md` section "Environnement Python" pour √©viter que les futurs agents perdent du temps.

---

### [2026-02-09] - Analyse persistance des filtres multi-joueurs (sans modification de code)

**Statut** : üìã Analyse et plan d√©taill√© r√©dig√©s

**Contexte** : L'utilisateur signale des conflits et une mauvaise persistance des filtres par DB joueur : au switch utilisateur les filtres ne sont pas correctement restaur√©s, au retour sur le joueur initial encore plus de filtres sont d√©s√©lectionn√©s ; demande d‚Äôanalyse approfondie + plan de correction ultra d√©taill√©, sans toucher au code.

**Cause racine identifi√©e** :
- Les **cl√©s des widgets** Streamlit (checkboxes playlists/modes/cartes : `filter_playlists_cb_*`, `filter_playlists_cat_*`, `*_version`, etc.) sont **globales** et **non supprim√©es** au changement de joueur.
- Apr√®s `apply_filter_preferences(new_player)`, les donn√©es en `session_state` sont correctes mais Streamlit r√©affiche l‚Äô√©tat des **widgets** (ancien joueur) ‚Üí affichage incoh√©rent ‚Üí l‚Äôutilisateur ¬´ corrige ¬ª en cliquant ‚Üí la s√©lection est modifi√©e ‚Üí la sauvegarde automatique en fin de rendu **√©crase** le JSON du joueur avec une s√©lection d√©grad√©e.
- Liste de nettoyage au changement de joueur **incompl√®te** : manquent `gap_minutes`, `_latest_session_label`, `min_matches_maps`, etc., et surtout **toutes les cl√©s dont le nom commence par** `filter_playlists_`, `filter_modes_`, `filter_maps_`.

**Livrable** : `.ai/ANALYSE_PERSISTANCE_FILTRES_MULTI_JOUEURS.md` ‚Äî analyse d√©taill√©e, sc√©nario type ¬´ encore plus de filtres d√©s√©lectionn√©s ¬ª, plan de correction en 7 phases (nettoyage exhaustif, centralisation des cl√©s, tests, option scopage widgets par joueur, doc).

**Prochaines √©tapes** : Impl√©menter le plan (Phase 1‚Äì2 en priorit√© : nettoyage exhaustif + centralisation des cl√©s).

---

### [2026-02-09] - Revue compl√®te du script backfill_data.py + Diagnostic persistance

**Statut** : üîß Correctif partiel appliqu√© (commit final), diagnostic complet document√©

**Contexte** : L'utilisateur signale que le script backfill_data.py "ne semble pas bien fonctionner". Sympt√¥me concret : 605 matchs d√©tect√©s, apr√®s traitement de 200 et relance ‚Üí toujours 605.

**Sympt√¥me utilisateur (Madina97294)** :
1. Lance `--all --all-data` ‚Üí Trouve **605 matchs** √† traiter
2. Traite **200 matchs** puis interrompt (Ctrl+C)
3. Relance ‚Üí Trouve toujours **605 matchs** (au lieu de ~405)
4. **Conclusion** : Les donn√©es ne sont PAS persist√©es

**Diagnostic double probl√®me** :

**Probl√®me A - Commit non persist√© lors d'interruption (‚úÖ CORRIG√â)** :
- **Cause** : `finally: conn.close()` sans commit final (ligne 1957-1958)
- **Impact** : DuckDB perd les donn√©es en cache lors d'interruption Ctrl+C
- **Correction appliqu√©e** : Ajout de `conn.commit()` dans le `finally` avant `conn.close()`
- **Fichier modifi√©** : `scripts/backfill_data.py` ligne 1957-1964

**Probl√®me B - D√©tection OR inefficace (‚ö†Ô∏è NON CORRIG√â)** :
- **Cause** : `where_clause = " OR ".join(conditions)` (ligne 982)
- **Impact** : Un match est s√©lectionn√© s'il manque **AU MOINS UNE** donn√©e parmi ~15 types
- **Cons√©quence** : Matchs partiellement trait√©s sont RE-S√âLECTIONN√âS et RE-T√âL√âCHARG√âS depuis l'API
- **Exemple** : Match avec medals/events/skill pr√©sents mais sans `sessions` ‚Üí RE-t√©l√©charg√© compl√®tement
- **Workaround** : Traiter par √©tapes au lieu de `--all-data` (voir document)

**Analyse effectu√©e** :
- Lecture du fichier complet (2461 lignes)
- Identification de 10 probl√®mes class√©s par s√©v√©rit√©
- Diagnostic du probl√®me de persistance (commit + d√©tection)
- R√©daction document d√©taill√© + section "Probl√®me Urgent" : `.ai/BACKFILL_SCRIPT_REVIEW.md`

**Probl√®mes critiques identifi√©s** :
1. **üî¥ Commit non persist√©** : Interruption perd les donn√©es (‚úÖ corrig√© ligne 1957-1964)
2. **üî¥ D√©tection OR inefficace** : Re-t√©l√©chargements inutiles avec `--all-data` (‚ö†Ô∏è workaround document√©)
3. **üî¥ Violation r√®gle Pandas** : Usage de `pd.Series` (lignes 119, 698, 709)
4. **üî¥ Gestion erreurs silencieuse** : 9 blocs `except Exception: pass` sans logs
5. **üî¥ Taille excessive** : 2461 lignes, difficile √† maintenir

**Solutions propos√©es (Probl√®me B)** :
- **Court terme** : Mode `--strict-detection` (AND au lieu de OR)
- **Long terme** : Table `backfill_status` pour tracker par type de donn√©e

**Tests de validation** :
1. Test persistance : Traiter 30 matchs, interrompre, relancer ‚Üí Devrait trouver ~575 matchs
2. Test re-t√©l√©chargement : Traiter medals uniquement, relancer `--all-data` ‚Üí Observer si re-s√©lection

**Recommandations prioritaires** :
- **Phase 0** (imm√©diat) : ‚úÖ Commit final ajout√©, √† tester
- **Phase 1** (1-2j) : Supprimer Pandas, ajouter logs exceptions, impl√©menter `--strict-detection`
- **Phase 2** (3-5j) : Optimiser SQL (CTEs), centraliser migrations
- **Phase 3** (1-2 sem) : D√©couper en modules, table `backfill_status`

**Impact estim√©** :
- Commit final : **Donn√©es persist√©es** lors d'interruption (‚úÖ critique)
- Mode strict : **Pas de re-t√©l√©chargements** inutiles (gain √©norme)
- SQL optimis√© : **10-20x plus rapide**

**Fichiers modifi√©s** :
- `scripts/backfill_data.py` (ligne 1957-1964)
- `.ai/BACKFILL_SCRIPT_REVIEW.md` (section "Probl√®me Urgent" ajout√©e)
- `.ai/thought_log.md` (cette entr√©e)

**Prochaines √©tapes** : Utilisateur teste la persistance, puis impl√©menter mode strict si valid√©.

---

### [2026-02-08] - Comparaison de sessions : KeyError kills / pair_name (root cause)

**Statut** : Corrig√©

**Probl√®me** : Sur l‚Äôonglet ¬´ Comparaison de sessions ¬ª, KeyError sur `pair_name` puis sur `kills`.

**Root cause** : La page re√ßoit `all_sessions_df` issu de `cached_compute_sessions_db()`. En chemin **DuckDB v4**, cette fonction ne s√©lectionne que `match_id`, `start_time`, `session_id`, `session_label` (pour limiter la lecture disque). Elle ne charge pas `pair_name`, `kills`, `deaths`, etc. La page suppose au contraire un DataFrame ¬´ sessions ¬ª **enrichi** (une ligne par match avec session_id, session_label + toutes les colonnes de match_stats). D‚Äôo√π les KeyError d√®s qu‚Äôon acc√®de √† `pair_name` ou `kills`.

**Correction** :
- **page_router** : Pour ¬´ Comparaison de sessions ¬ª, fusionner `df` (stats compl√®tes) avec `all_sessions_df` sur `match_id` avant d‚Äôappeler la page. La page re√ßoit ainsi un DataFrame enrichi (session_id, session_label + kills, pair_name, etc.). Si merge impossible (all_sessions_df vide ou pas de match_id), on garde l‚Äôancien comportement (all_sessions_df tel quel).
- **session_compare.py** : Garde d√©j√† ajout√©e pour le filtre par cat√©gorie : `if mode_category and "pair_name" in df.columns` pour √©viter KeyError si `pair_name` absent.

**Fichiers modifi√©s** : src/app/page_router.py, src/ui/pages/session_compare.py (garde pair_name), .ai/thought_log.md.

---

### [2026-02-07] - Shots fired / shots hit en BDD et backfill (SHOTS_FIRED_HIT_BDD_PLAN)

**Statut** : Impl√©ment√© (Sprints 1‚Äì3)

**Objectif** : Persister `shots_fired` et `shots_hit` pour le joueur propri√©taire et pour tous les participants, avec options de backfill.

**Sprint 1** :
- `engine._insert_match_row` : colonnes `shots_fired`, `shots_hit` incluses dans l‚ÄôINSERT (d√©j√† extraites par `transform_match_stats`).
- Backfill `--shots` et `--force-shots` dans `backfill_data.py` (s√©lection matchs NULL, mise √† jour, compteur `shots_updated`).
- Docstring et tests (test_sync_engine : extraction shots dans transform_match_stats ; test_sync_performance_score : sch√©mas avec shots_fired/shots_hit).

**Sprint 2** :
- `match_participants` : colonnes `shots_fired`, `shots_hit` (SYNC_SCHEMA_DDL + migration `_ensure_match_participants_rank_score`).
- `MatchParticipantRow` et `extract_participants` : extraction ShotsFired/ShotsHit depuis CoreStats par joueur.
- Sync engine : `_insert_participant_rows` inclut shots_fired, shots_hit.
- Backfill `--participants-shots` et `--force-participants-shots` (s√©lection, UPDATE par participant, `participants_shots_updated`).
- Test `test_participants_shots_extracted` (extract_participants).

**Sprint 3** :
- CLAUDE.md : exemples de commandes backfill shots.
- data_lineage.md : origine `shots_fired` / `shots_hit` (API ‚Üí match_stats, match_participants).
- thought_log : cette entr√©e.

**Fichiers modifi√©s** : src/data/sync/engine.py, src/data/sync/models.py, src/data/sync/transformers.py, scripts/backfill_data.py, tests/test_sync_engine.py, tests/test_sync_performance_score.py, CLAUDE.md, .ai/data_lineage.md, .ai/thought_log.md.

---

### [2026-02-07] - Fix association m√©dias : capture_end_utc + tol√©rance 20 min

**Statut** : Termin√©

**Probl√®me** : Des captures du joueur (ex. JGtm, 41 captures dans son dossier) restaient en ¬´ Sans correspondance ¬ª alors qu'elles proviennent toutes de ses matchs.

**Cause** : L'association utilisait `COALESCE(mtime_paris_epoch, mtime)` ‚Äî le mtime du fichier peut √™tre modifi√© par copie/sync Xbox‚ÜíPC, OneDrive, etc. Ce n'est pas le moment r√©el de la capture.

**Correction** :
- Utiliser `COALESCE(epoch(capture_end_utc), mtime_paris_epoch, mtime)` : `capture_end_utc` = EXIF DateTimeOriginal (images) ou mtime-duration (vid√©os) = moment r√©el de la capture.
- Tol√©rance par d√©faut pass√©e de 5 √† 20 min (d√©lais sync Xbox, upload, etc.).

**Fichiers modifi√©s** : src/data/media_indexer.py.

---

### [2026-02-07] - Correctif dossier captures par joueur (MEDIA_CAPTURES_PER_PLAYER_PLAN)

**Statut** : Impl√©ment√©

**Objectif** : Dossier par joueur (`base_dir/{gamertag}/`), association mono-DB, affichage cross-DB pour partage par match_id.

**R√©alisations** :
- **Param√®tres** : `media_captures_base_dir` dans AppSettings, migration depuis media_screens_dir/media_videos_dir (parent commun). UI Param√®tres : un seul champ ¬´ Dossier de base des captures ¬ª, bouton ¬´ R√©initialiser l'index m√©dias ¬ª.
- **Scan** : `scan_and_index(player_captures_dir=...)` accepte un dossier joueur unique (images + vid√©os). Fallback legacy : videos_dir + screens_dir.
- **Association** : mono-DB uniquement. Une seule ligne (media_path, match_id, xuid) avec xuid = propri√©taire de la DB. Suppression de `_backfill_media_associations_missing_xuids`.
- **load_media_for_ui** : cross-DB. ¬´ Mes captures ¬ª = DB courante ; ¬´ Captures de XXX ¬ª = m√©dias des autres DB dont match_id dans match_stats de la DB courante. Une seule ligne par m√©dia (priorit√© mine > teammate > unassigned).
- **Indexation** : au d√©marrage, indexe tous les joueurs ayant base_dir/gamertag. Fallback legacy si base_dir vide.
- **Scripts** : `index_media.py` (--gamertag, --all), `reset_media_db.py` (--gamertag, --all).

**Fichiers modifi√©s** : src/ui/settings.py, src/ui/pages/settings.py, src/data/media_indexer.py, streamlit_app.py, scripts/index_media.py, scripts/reset_media_db.py (nouveau).

---

### [2026-02-07] - Correction association m√©dias (onglet M√©dias)

**Statut** : Termin√©

**Probl√®me** : Sur le profil d‚Äôun joueur (ex. JGtm), les m√©dias apparaissaient parfois tous sous ¬´ Captures de MAdina ¬ª, parfois sous ¬´ Captures de Chocoboflor ¬ª, sans stabilit√©. Les captures proviennent pourtant de matchs o√π le joueur du profil a jou√© (au minimum).

**Causes identifi√©es** :
1. **Association** : On parcourait les BDD joueurs dans un ordre non d√©terministe (`iterdir()`). Pour chaque m√©dia on associait le ¬´ meilleur ¬ª match **par BDD** puis on ins√©rait une seule ligne (celle du premier joueur trouv√©). R√©sultat : un seul xuid par m√©dia, d√©pendant de l‚Äôordre des dossiers.
2. **Affichage** : Une m√™me capture pouvait avoir plusieurs lignes (une par xuid associ√©) ; l‚ÄôUI affichait la m√™me capture dans plusieurs sections selon l‚Äôordre des lignes.

**Corrections** :
- **`associate_with_matches`** : Pour chaque m√©dia sans association, on collecte tous les candidats (match_id, distance) parmi **toutes** les BDD joueurs, on retient **un seul** match (distance minimale), puis on ins√®re une ligne `(media_path, match_id, xuid)` pour **chaque** joueur dont la BDD contient ce match. Ainsi le propri√©taire du profil est toujours associ√© s‚Äôil a ce match. Ordre des BDD rendu d√©terministe : `sorted(iterdir())` et `_get_all_player_dbs_current_first()` pour prioriser la BDD courante.
- **Backfill** : `_backfill_media_associations_missing_xuids()` compl√®te les associations existantes en ajoutant les xuid manquants pour chaque `(media_path, match_id)` (autres joueurs ayant ce match).
- **`load_media_for_ui`** : Une seule ligne par m√©dia : priorit√© section ¬´ mine ¬ª > ¬´ teammate ¬ª > ¬´ unassigned ¬ª, puis tri stable par gamertag. Chaque capture n‚Äôappara√Æt plus que dans une seule section.

**Fichiers modifi√©s** : src/data/media_indexer.py, .ai/thought_log.md.

---

### [2026-02-07] - ‚úÖ Sprints M√©dias restants (S1‚ÄìS3 d√©j√† livr√©s, S6 int√©gration)

**Statut** : Termin√©

**Constat** : Sprints 1, 2, 3 du plan MEDIA_TAB_IMPLEMENTATION_PLAN √©taient d√©j√† impl√©ment√©s et test√©s (voir entr√©es pr√©c√©dentes thought_log). Sprint 6 (Int√©gration et r√©glages) compl√©t√©.

**Sprint 6 r√©alisations** :
- Scan delta au d√©marrage d√©j√† en place (_background_media_indexing, thread daemon).
- Gestion cas limites : os.walk prot√©g√© par try/except OSError (dossiers inaccessibles / r√©seau) ; erreurs m√©tadonn√©es par fichier ne bloquent pas le scan.
- Documentation : data_lineage.md (flux 5 ¬´ Dossiers m√©dias ‚Üí DuckDB ¬ª), project_map.md (media_indexer, tables media_*), MEDIA_TAB_IMPLEMENTATION_PLAN (tous sprints marqu√©s livr√©s).
- media_library.py : note en en-t√™te indiquant que l‚Äôonglet principal est ¬´ M√©dias ¬ª (media_tab.py), ce module conserv√© pour compatibilit√©.

**Fichiers modifi√©s** : src/data/media_indexer.py, .ai/data_lineage.md, .ai/project_map.md, .ai/features/MEDIA_TAB_IMPLEMENTATION_PLAN.md, src/ui/pages/media_library.py, .ai/thought_log.md.

---

### [2026-02-07] - ‚úÖ Stockage sessions (session_id / session_label)

**Statut** : Termin√©

**R√©alisations** :
- Sprint 1 : Sch√©ma `session_id`, `session_label` dans `match_stats`, constante `session_stability_hours = 4.0`, migration dans `engine.py`
- Sprint 2 : `src/data/sessions_backfill.py` (get_friends_xuids_for_backfill), script `scripts/backfill_sessions.py` (--all, --force, --dry-run)
- Sprint 3 : Lecture hybride dans `cached_compute_sessions_db` (donn√©es stock√©es si tous matchs ‚â• 4h et session_id pr√©sent, sinon recalcul)
- Sprint 4 : Suppression slider gap_minutes, valeur fixe 120, passage de `friends_tuple` au cache
- Sprint 5 : Doc CLAUDE.md, DATA_SESSIONS.md, SESSIONS_STOCKAGE_PLAN.md

**Fichiers modifi√©s** : src/config.py, src/data/sync/engine.py, src/data/sessions_backfill.py, src/ui/cache.py, src/app/filters_render.py, src/app/filters.py, page_router.py, teammates.py, streamlit_app.py. Backfill sessions int√©gr√© dans scripts/backfill_data.py (--sessions, --force-sessions) ; script backfill_sessions.py supprim√©.

---

### [2026-02-07] - ‚úÖ Sprint 3 M√©dias : Thumbnails (vid√©os + images)

**Statut** : Termin√©

**R√©alisations** :
- Vid√©os : GIF anim√© via ffmpeg (scripts/generate_thumbnails), stockage dans videos_dir/thumbs/
- Images : miniatures d√©di√©es via PIL (redimensionnement max 320px), stockage dans screens_dir/thumbs/
- generate_thumbnails_for_new(videos_dir, screens_dir) ‚Äî √©tendu pour vid√©os ET images
- Gestion erreurs : ffmpeg absent ‚Üí skip vid√©os sans bloquer ; PIL absent ‚Üí skip images
- Int√©gration streamlit : passe videos_dir et screens_dir
- 4 nouveaux tests : generate_image_thumbnails, no_ffmpeg_skips, empty_dirs, get_image_thumbnail_path
- Ex√©cution pytest : 18 passed

**Fichiers modifi√©s** : src/data/media_indexer.py, streamlit_app.py, tests/test_media_indexer.py

---

### [2026-02-07] - ‚úÖ Sprint 2 M√©dias : Association capture ‚Üî match (multi-joueurs)

**Statut** : Termin√©

**R√©alisations** :
- Algorithme d√©j√† impl√©ment√© en Sprint 1 : fen√™tre temporelle, match le plus proche, map_id/map_name
- Parcours de toutes les BDD joueurs (_get_all_player_dbs), stockage dans BDD du joueur actuel
- 4 nouveaux tests Sprint 2 : closest_match, multi_players, map_id_map_name, search_all_player_dbs
- Ex√©cution pytest : 14 passed (10 Sprint 1 + 4 Sprint 2)

**Fichiers modifi√©s** : tests/test_media_indexer.py

---

### [2026-02-07] - ‚úÖ Sprint 1 M√©dias : Fondations BDD et scan delta

**Statut** : Termin√©

**R√©alisations** :
- Sch√©ma `media_files` : capture_start_utc, capture_end_utc, duration_seconds, title, status (active/deleted)
- Sch√©ma `media_match_associations` : map_id, map_name
- Module `media_indexer.py` r√©√©crit : scan delta, m√©tadonn√©es (ffprobe vid√©os, EXIF images), status='deleted' pour fichiers absents
- Migration pour tables existantes (ajout colonnes, mtime_paris_epoch, status)
- Tests : 10 tests cr√©√©s et ex√©cut√©s (pytest tests/test_media_indexer.py -v) ‚Äî 10 passed

**Fichiers modifi√©s** : src/data/media_indexer.py, tests/test_media_indexer.py

---

### [2026-02-07] - üìã Planification onglet ¬´ M√©dias ¬ª (remplace Biblioth√®que m√©dias)

**Statut** : Planification termin√©e (v2 ‚Äì d√©cisions valid√©es + sprints)

**Contexte** :
Refonte compl√®te √† partir de z√©ro de l'onglet "Biblioth√®que de m√©dias" ‚Üí nouvel onglet "M√©dias". Aucune r√©utilisation du code existant (UI/UX chaotique et inacceptable).

**Document** : `.ai/features/MEDIA_TAB_IMPLEMENTATION_PLAN.md`

**D√©cisions valid√©es** :
- Orphelines : si pas de match chez l'utilisateur ‚Üí chercher dans BDD des autres joueurs ; "Sans correspondance" = aucune correspondance trouv√©e nulle part.
- Multi-matchs : associer au match le plus proche.
- Fichiers supprim√©s : marquer `deleted` en BDD, ne pas afficher.
- Lightbox HTML pour consultation des m√©dias.
- Composant HTML/JS pour animation au survol.
- Images : g√©n√©rer miniature d√©di√©e (plus rapide).
- Sous-dossiers : scan r√©cursif ; NAS pr√©vu, latences mineures.

**Sprints pr√©vus** : 1 Fondations BDD / 2 Association match multi-joueurs / 3 Thumbnails / 4 Composants UI (thumbnail + lightbox) / 5 Page M√©dias / 6 Int√©gration. Total estim√© : 10‚Äì15 jours.

---

### [2026-02-06] - ‚úÖ Radar participation unifi√© : impl√©mentation + raffinements

**Statut** : ‚úÖ **Termin√©**

**Contexte** :
Refonte de la section "Participation au match" : un seul radar √† 6 axes, r√©utilisable.

**R√©alisations** :
- `src/visualization/participation_radar.py` : `RADAR_THRESHOLDS`, `RADAR_AXIS_LINES`, `compute_participation_profile()`, `compute_global_radar_thresholds()`, `get_radar_thresholds()`
- `src/ui/components/radar_chart.py` : `create_participation_profile_radar()` (th√®me Halo)
- `src/ui/pages/match_view_participation.py` : radar + l√©gende sur m√™me rang√©e (2/3 + 1/3)
- `src/ui/pages/teammates.py` : Compl√©mentarit√© avec radar unifi√©
- `src/ui/pages/session_compare.py` : Comparaison sessions migr√©e
- `tests/test_participation_radar.py` : tests unitaires

**Raffinements** : Seuils globaux (meilleur match hors Firefight/BTB, facteur 0.85) ; Survie = m√©lange morts/min + dur√©e vie moy (50/50) ; L√©gende des axes √† droite du radar ; Th√®me sombre coh√©rent.

**Document** : `.ai/features/RADAR_PARTICIPATION_UNIFIE_PLAN.md`

---

### [2026-02-06] - ‚úÖ Sprint 3 TERMIN√â : Migration SQLite ‚Üí DuckDB Compl√®te

**Statut** : ‚úÖ **TERMIN√â** - Toutes les t√¢ches du sprint compl√©t√©es

**Contexte** :
√âliminer toutes les r√©f√©rences SQLite du code applicatif (hors scripts de migration).

**R√âALISATIONS** :

#### Modifications principales
- ‚úÖ `src/db/connection.py` : R√©√©crit - DuckDB uniquement, `SQLiteForbiddenError` si `.db` fourni
- ‚úÖ `scripts/sync.py` : Supprim√© sqlite3, _refuse_sqlite_path(), branches SQLite (rebuild_cache, etc.)
- ‚úÖ `src/db/loaders.py` : has_table() utilise uniquement DuckDB (information_schema), refuse .db
- ‚úÖ `src/ui/multiplayer.py` : Supprim√© _get_sqlite_connection(), branches SQLite
- ‚úÖ `src/ui/sync.py` : M√©tadonn√©es vides pour .db (au lieu d'appeler get_sync_metadata)

#### Scripts utilitaires
- ‚úÖ `validate_refdata_integrity.py` : sqlite_master ‚Üí information_schema
- ‚úÖ `migrate_game_variant_category.py` : sqlite_master ‚Üí information_schema
- ‚úÖ `migrate_add_columns.py` : sqlite_master ‚Üí information_schema, PRAGMA ‚Üí information_schema.columns

#### Tests
- ‚úÖ `test_cache_integrity.py` : Skip (tests legacy SQLite MatchCache)
- ‚úÖ `test_connection_duckdb.py` : Nouveau - SQLiteForbiddenError, get_connection DuckDB

#### Documentation
- ‚úÖ `recover_from_sqlite.py`, `migrate_player_to_duckdb.py` : En-t√™te "migration only"

**Validation** : `pytest tests/ -v` (n√©cessite `pip install -e ".[dev]"`)

---

### [2026-02-06] - ‚úÖ Sprint 2 TERMIN√â : Logique Sessions (teammates_signature)

**Statut** : ‚úÖ **TERMIN√â** - Toutes les t√¢ches compl√©t√©es

**Contexte** :
Sprint 2 pour am√©liorer la d√©tection des sessions avec prise en compte des changements de co√©quipiers (teammates_signature).

**R√âALISATIONS** :

#### Modifications
- ‚úÖ `src/analysis/sessions.py` :
  - NULL trait√© comme valeur distincte (√©vite fusionner A, NULL, B en une session)
  - Premier match forc√© √† session_id=0 (correctif bug Polars)
  - Version Pandas : m√™me logique NULL avec fillna sentinelle
- ‚úÖ `scripts/backfill_teammates_signature.py` : Existant, utilise DuckDB uniquement
- ‚úÖ `src/data/sync/transformers.py` : compute_teammates_signature v√©rifi√© (d√©j√† correct)

#### Tests cr√©√©s/√©tendus
- ‚úÖ `tests/test_sessions_advanced.py` : +3 tests (NULL, premier match, coh√©rence)
- ‚úÖ `tests/test_sessions_teammates.py` : Nouveau (7 sc√©narios co√©quipiers)
- ‚úÖ `tests/test_transformers_teammates.py` : Nouveau (9 tests compute_teammates_signature)

#### Documentation
- ‚úÖ `.ai/DATA_SESSIONS.md` : Guide logique sessions + teammates_signature

**Validation** : Ex√©cuter `pytest tests/ -v` dans un environnement avec `pip install -e ".[dev]"`.

---

### [2026-02-06] - ‚úÖ Sprint 1 TERMIN√â : Donn√©es Manquantes (Discovery UGC + metadata.duckdb)

**Statut** : ‚úÖ **TERMIN√â** - Toutes les t√¢ches compl√©t√©es

**Contexte** :
Sprint 1 pour restaurer l'enregistrement des noms de cartes, modes, playlists et autres m√©tadonn√©es manquantes. Les colonnes `playlist_name`, `map_name`, `pair_name`, `game_variant_name` √©taient NULL car Discovery UGC n'√©tait jamais appel√© et metadata.duckdb √©tait absent.

**R√âALISATIONS** :

#### Composants cr√©√©s
- ‚úÖ `src/data/sync/metadata_resolver.py` : Classe MetadataResolver pour r√©soudre les noms depuis metadata.duckdb
- ‚úÖ `scripts/populate_metadata_from_discovery.py` : Script pour cr√©er/peupler metadata.duckdb depuis Discovery UGC
- ‚úÖ `scripts/backfill_metadata.py` : Script pour backfill les m√©tadonn√©es dans match_stats existants
- ‚úÖ `scripts/validate_sprint1_metadata.py` : Script de validation manuelle

#### Tests cr√©√©s
- ‚úÖ `tests/test_metadata_resolver.py` : 15 tests unitaires pour MetadataResolver
- ‚úÖ `tests/test_transformers_metadata.py` : 7 tests pour transformers avec m√©tadonn√©es
- ‚úÖ `tests/integration/test_metadata_resolution.py` : 6 tests d'int√©gration end-to-end

#### Documentation
- ‚úÖ `docs/METADATA_RESOLUTION.md` : Guide complet de r√©solution m√©tadonn√©es + troubleshooting

#### Modifications
- ‚úÖ `src/data/sync/transformers.py` : Mis √† jour pour utiliser le nouveau MetadataResolver
- ‚úÖ `.ai/CONSOLIDATED_AUDITS_AND_ROADMAP.md` : Sprint 1 marqu√© comme termin√©

**Architecture de r√©solution** :
1. **Priorit√© 1** : PublicName depuis Discovery UGC API (enrichissement en temps r√©el via `enrich_match_info_with_assets()`)
2. **Priorit√© 2** : PublicName depuis metadata.duckdb (cache local via `MetadataResolver`)
3. **Priorit√© 3** : Fallback sur asset_id (UUID si aucun nom trouv√©)

**Utilisation** :
```bash
# Cr√©er/populer metadata.duckdb
python scripts/populate_metadata_from_discovery.py --all-players

# Backfill les m√©tadonn√©es existantes
python scripts/backfill_metadata.py --player JGtm
```

**Note** : Les tests n√©cessitent DuckDB install√©. Validation manuelle disponible via `scripts/validate_sprint1_metadata.py`.

---

### [2026-02-05] - ‚úÖ Sprint Gamertag/Roster : IMPL√âMENTATION COMPL√àTE

**Statut** : ‚úÖ Toutes les phases impl√©ment√©es

**Contexte** :
Sprint "Correction Gamertags, Roster et Co√©quipiers" impl√©ment√© pour corriger les gamertags corrompus, les rosters cass√©s, et la d√©tection des co√©quipiers.

**PHASES COMPL√âT√âES** :

#### Phase 1 : Cr√©ation table `match_participants`
- ‚úÖ DDL dans `src/data/sync/engine.py`
- ‚úÖ `MatchParticipantRow` dataclass dans `src/data/sync/models.py`
- ‚úÖ `extract_participants()` dans `src/data/sync/transformers.py`
- ‚úÖ Int√©gration dans `_process_single_match()` du sync engine

#### Phase 2 : Correction requ√™tes co√©quipiers
- ‚úÖ `load_same_team_match_ids()` r√©√©crit pour utiliser `match_participants`
- ‚úÖ Fallback sur l'ancienne m√©thode si table manquante

#### Phase 3 : CLI `--participants` dans backfill
- ‚úÖ Arguments `--participants` et `--force-participants`
- ‚úÖ Fonction `_insert_participant_rows()` dans `backfill_data.py`
- ‚úÖ Int√©gration compl√®te dans le flux de backfill

#### Phase 4 : R√©solution gamertag centralis√©e
- ‚úÖ `resolve_gamertag()` dans `duckdb_repo.py` (cascade : match_participants ‚Üí xuid_aliases ‚Üí teammates_aggregate ‚Üí highlight_events)
- ‚úÖ `resolve_gamertags_batch()` pour les traitements par lot
- ‚úÖ `load_match_rosters()` utilise `resolve_gamertags_batch`
- ‚úÖ `cached_load_match_player_gamertags()` dans `cache.py` utilise `resolve_gamertags_batch`

#### Phase 6 : Backfill killer_victim_pairs
- ‚úÖ Arguments `--killer-victim`
- ‚úÖ Fonction `_backfill_killer_victim_pairs()` dans `backfill_data.py`
- ‚úÖ Utilise l'algorithme de pairing de `src/analysis/killer_victim.py`

**Commandes disponibles** :
```bash
# Backfill participants (nouveau)
python scripts/backfill_data.py --player JGtm --participants

# Backfill paires killer/victim
python scripts/backfill_data.py --player JGtm --killer-victim

# Backfill complet (inclut participants + killer_victim)
python scripts/backfill_data.py --player JGtm --all-data
```

---

### [2026-02-05] - üìä Sprint Gamertag/Roster : Documentation killer_victim_pairs

**Statut** : ‚úÖ Documentation compl√®te cr√©√©e

**Contexte** :
L'utilisateur demande o√π sont stock√©es les donn√©es "qui a tu√© qui" avec timestamps.

**R√âSULTAT DE L'ANALYSE** :

1. **Table `killer_victim_pairs`** : Existe mais est **VIDE** (0 lignes)
   - Sch√©ma : `killer_xuid`, `victim_xuid`, `time_ms`, etc.
   - Destin√©e √† stocker les paires killer‚Üívictim

2. **Source de donn√©es** : `highlight_events`
   - Events `kill` : contiennent le killer (xuid, gamertag, time_ms)
   - Events `death` : contiennent la victime (xuid, gamertag, time_ms)
   - Pairing possible par timestamp (¬±5ms) :
     ```
     kill @ 40528ms (quisqueyano159) ‚Üí death @ 40529ms (Ale8037)
     ```

3. **Modules existants** (bien document√©s, mais donn√©es manquantes) :
   - `src/analysis/killer_victim.py` : Algorithme de pairing + fonctions Polars
   - `src/visualization/antagonist_charts.py` : Graphiques Plotly (non int√©gr√©s UI)
   - `scripts/populate_antagonists.py` : Cherche DB SQLite legacy (obsol√®te)

**Actions prises** :
- ‚úÖ Sprint mis √† jour avec Phase 6 (backfill killer_victim_pairs)
- ‚úÖ Sprint mis √† jour avec Phase 7 (int√©gration graphiques UI)
- ‚úÖ Documentation IA cr√©√©e : `.ai/DATA_KILLER_VICTIM.md`
- ‚úÖ `project_map.md` mis √† jour avec les tables manquantes

**Commandes de backfill** (√† impl√©menter) :
```bash
python scripts/backfill_data.py --player JGtm --killer-victim
python scripts/populate_antagonists.py --gamertag JGtm --force
```

---

### [2026-02-05] - üî¥ CRITIQUE : Donn√©es Manquantes en BDD ‚Äî DIAGNOSTIC TERMIN√â

**Statut** : ‚úÖ **CAUSE RACINE IDENTIFI√âE** - Pr√™t pour la phase correction

**Contexte** :
L'utilisateur signale que plusieurs donn√©es ne sont plus enregistr√©es en BDD :
1. Noms des cartes, modes et playlists (`playlist_name`, `map_name`, `pair_name`, `game_variant_name` sont NULL)
2. Noms des joueurs par match non r√©cup√©r√©s correctement
3. Joueurs non affect√©s √† l'√©quipe adverse
4. Nom de l'√©quipe adverse non r√©cup√©r√©
5. Valeurs "attendues" pour frags et morts (`kills_expected`, `deaths_expected`, `assists_expected` sont NULL)

**CAUSES CONFIRM√âES** :
1. **Discovery UGC jamais appel√©** : `client.get_asset()` n'est pas utilis√© dans `_process_single_match()`. L'option `with_assets=True` existe mais n'est jamais v√©rifi√©e.
2. **metadata.duckdb absent** : Le dossier `data/warehouse/` n'existe pas ‚Üí `create_metadata_resolver()` retourne `None` ‚Üí aucune r√©solution depuis r√©f√©rentiels.
3. **Fallback sur IDs** : Sans PublicName (API) ni metadata_resolver, les noms deviennent les UUID.
4. **StatPerformances** : √Ä v√©rifier avec logs si l'API skill renvoie la structure attendue.

**Actions prises** :
- ‚úÖ Diagnostic complet document√© dans `.ai/explore/CRITICAL_DATA_MISSING_EXPLORATION.md`
- ‚úÖ Script de v√©rification SQL cr√©√© : `scripts/diagnostic_critical_data.py`
- ‚úÖ Proposition d'impl√©mentation Discovery UGC (r√©f√©rence spnkr_import_db.py)

**Prochaines √©tapes (phase correction)** :
1. Impl√©menter les appels Discovery UGC dans `_process_single_match()` quand `options.with_assets=True`
2. Enrichir `MatchInfo` avec les PublicName avant de passer √† `transform_match_stats()`

---

### [2026-02-05] - üî¥ CORRECTION CRITIQUE : Chargement des stats co√©quipiers (Multi-DB)

**Statut** : ‚úÖ **CORRIG√â** - Ne plus refaire cette erreur !

**Contexte** :
L'onglet "Mes co√©quipiers" affichait les m√™mes valeurs pour tous les joueurs (ex: JGtm, Madina97294, Chocoboflor avaient tous 1.02, 1.38, 0.48 en stats/min).

**CAUSE RACINE** :
```python
# ‚ùå CODE INCORRECT (le xuid est IGNOR√â pour DuckDB v4)
f1_df = load_df_optimized(db_path, f1_xuid, db_key=db_key)
f2_df = load_df_optimized(db_path, f2_xuid, db_key=db_key)
# ‚Üí Charge TOUJOURS depuis la DB du joueur principal, pas celle du co√©quipier !
```

**SOLUTION** :
```python
# ‚úÖ CODE CORRECT - Charger depuis la DB de chaque co√©quipier
f1_df = _load_teammate_stats_from_own_db(f1_gamertag, match_ids, db_path)
f2_df = _load_teammate_stats_from_own_db(f2_gamertag, match_ids, db_path)
# ‚Üí Construit le chemin data/players/{gamertag}/stats.duckdb
```

**R√àGLE √Ä RETENIR** :

| ‚ùå NE JAMAIS FAIRE | ‚úÖ TOUJOURS FAIRE |
|-------------------|-------------------|
| `load_df_optimized(db_path, autre_xuid)` | `_load_teammate_stats_from_own_db(gamertag, match_ids, db_path)` |
| Passer le xuid d'un autre joueur | Construire le chemin vers sa DB |

**Pourquoi le xuid est ignor√© ?**
- Dans l'architecture DuckDB v4, chaque joueur a sa propre DB : `data/players/{gamertag}/stats.duckdb`
- `load_df_optimized()` charge depuis `db_path` et ignore le param√®tre `xuid`
- Pour charger les stats d'un co√©quipier, il faut charger depuis **SA** DB

**Fichiers modifi√©s** :
- `src/ui/pages/teammates.py` : Ajout de `_load_teammate_stats_from_own_db()`, correction de 3 appels
- `CLAUDE.md` : Ajout de la documentation sur l'architecture multi-joueurs

**M√©mo rapide** :
```
Pour afficher les stats d'un co√©quipier sur des matchs communs :
1. Identifier les match_id communs (via teammates_aggregate ou filtres)
2. Obtenir le gamertag du co√©quipier (display_name_from_xuid)
3. Charger depuis data/players/{gamertag}/stats.duckdb
4. Filtrer sur les match_id communs
```

**Rappel SQLite** : **PROSCRIT** - Aucun fallback SQLite dans le projet.

---

### [2026-02-03 PM] - üî¥ ANALYSE CRITIQUE : 12 R√©gressions majeures identifi√©es

**Statut** : ‚ö†Ô∏è **ANALYSE COMPL√àTE** - Plan de correction en 5 sprints cr√©√©

**Contexte** : L'utilisateur a signal√© de nombreuses r√©gressions apr√®s les derni√®res modifications.

**R√©gressions identifi√©es** :

| # | Sympt√¥me | Cause racine |
|---|----------|--------------|
| 1 | Dernier match : 17 jan 2026 | Donn√©es non synchronis√©es ou cache obsol√®te |
| 2 | Pr√©cision : nan% | Colonne `accuracy` NULL dans match_stats |
| 3 | Premier kill/mort ne fonctionne pas | Table highlight_events vide ou mal requ√™t√©e |
| 4-5 | Distributions vides (pr√©cision, FDA) | D√©riv√© de #2 (pas de donn√©es accuracy) |
| 6 | **Score de performance non disponible** | **OUBLI D'IMPL√âMENTATION** dans `timeseries.py` |
| 7 | Roster indisponible | `cached_load_match_rosters()` retourne `None` pour DuckDB v4 |
| 8, 11 | M√©dailles indisponibles | Table medals_earned vide |
| 9-10 | M√©dias non associ√©s + doublons | start_time NULL + double message |
| 12 | Page co√©quipiers vide | Fonctions cache.py retournent vide pour DuckDB v4 |

**D√©couverte importante sur le score de performance** :
- `timeseries.py` v√©rifie si `performance_score` existe mais **ne la calcule jamais**
- `match_history.py` et `session_compare.py` appellent `compute_performance_series()` ‚úÖ
- Correction simple : ajouter l'appel √† `compute_performance_series()` dans `timeseries.py`

**Cause racine principale** :
```python
# src/ui/cache.py - PROBL√àME CRITIQUE
if _is_duckdb_v4_path(db_path):
    return []  # ‚ùå Retourne toujours vide au lieu de charger les donn√©es
```

**Fonctions impact√©es** :
- `cached_same_team_match_ids_with_friend()` ‚Üí `()`
- `cached_query_matches_with_friend()` ‚Üí `[]`
- `cached_load_match_rosters()` ‚Üí `None`
- `cached_load_friends()` ‚Üí `[]`

**Documents cr√©√©s** :
- `.ai/diagnostics/REGRESSIONS_ANALYSIS_2026-02-03.md` - Analyse compl√®te
- `.ai/sprints/SPRINT_REGRESSIONS_FIX.md` - Plan de correction en 5 sprints

**Ordre de priorit√©** :
1. Sprint 2 : Diagnostic des donn√©es DuckDB
2. Sprint 1 : Correction cache.py
3. Sprint 4 : Page co√©quipiers
4. Sprint 3 : M√©dias
5. Sprint 5 : Tests

**Prochaine action** : Ex√©cuter le diagnostic pour v√©rifier l'√©tat des donn√©es avant correction.

---

### [2026-02-03] - SPRINTS 8 & 9 TERMIN√âS : Backfill + Migration + Tests

**Statut** : ‚úÖ **SUCC√àS** - Infrastructure compl√®te pour killer_victim_pairs

**Sprint 8 : Backfill et Migration**

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| 8.0 | `src/data/sync/engine.py` | Sch√©mas DuckDB pour `killer_victim_pairs` et `personal_score_awards` |
| 8.1 | `scripts/backfill_killer_victim_pairs.py` | Calcule les paires depuis highlight_events |
| 8.3 | `scripts/migrate_game_variant_category.py` | Ajoute colonne manquante √† match_stats |
| 8.4 | `scripts/validate_refdata_integrity.py` | V√©rifie coh√©rence des donn√©es |
| 8.5 | `docs/MIGRATION_REFDATA.md` | Guide de migration complet |

**Sprint 9 : Optimisation et Tests**

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| 9.1 | `src/data/repositories/duckdb_repo.py` | 4 m√©thodes Polars ajout√©es |
| 9.2 | `tests/integration/test_refdata_antagonists.py` | 15+ tests d'int√©gration |
| 9.3 | `scripts/benchmark_polars.py` | Benchmark Polars vs Pandas |

**Nouvelles tables DuckDB** :

```sql
-- killer_victim_pairs : Paires killer‚Üívictim par match
CREATE TABLE killer_victim_pairs (
    id INTEGER PRIMARY KEY,
    match_id VARCHAR NOT NULL,
    killer_xuid VARCHAR NOT NULL,
    killer_gamertag VARCHAR,
    victim_xuid VARCHAR NOT NULL,
    victim_gamertag VARCHAR,
    kill_count INTEGER DEFAULT 1,
    time_ms INTEGER,
    is_validated BOOLEAN DEFAULT FALSE
);

-- personal_score_awards : D√©composition score (REPORT√â - API non dispo)
```

**Nouvelles m√©thodes Repository** :

```python
repo.load_killer_victim_pairs_as_polars(match_id="...")
repo.load_match_stats_as_polars(limit=100)
repo.get_antagonists_summary_polars(top_n=20)
repo.has_killer_victim_pairs()
```

**Note** : Sprint 8.2 (backfill personal_score_awards) report√© car l'API ne fournit pas ces donn√©es.

**Commandes de migration** :

```bash
# 1. Migrer le sch√©ma
python scripts/migrate_game_variant_category.py --all

# 2. Backfill les paires
python scripts/backfill_killer_victim_pairs.py --all

# 3. Valider
python scripts/validate_refdata_integrity.py --all
```

---

### [2026-02-03] - SPRINTS 6 & 7 TERMIN√âS : Performance Cumul√©e + Page Objectifs

**Statut** : ‚úÖ **SUCC√àS** - 50+ tests passent (24 Sprint 6 + 26 Sprint 4)

**Sprint 6 : Performance Cumul√©e avec Polars**

Module cr√©√© : `src/analysis/cumulative.py`

| Fonction | Description |
|----------|-------------|
| `compute_cumulative_net_score_series_polars()` | S√©rie cumulative net score (kills - deaths) |
| `compute_cumulative_kd_series_polars()` | S√©rie cumulative K/D ratio |
| `compute_cumulative_kda_series_polars()` | S√©rie cumulative KDA |
| `compute_cumulative_objective_score_series_polars()` | S√©rie cumulative score objectifs |
| `compute_cumulative_metrics_polars()` | M√©triques agr√©g√©es finales |
| `compute_rolling_kd_polars()` | K/D glissant sur N matchs |
| `compute_session_trend_polars()` | Tendance de session (am√©lioration/d√©clin) |

Module cr√©√© : `src/visualization/performance.py`

| Graphique | Description |
|-----------|-------------|
| `plot_cumulative_net_score()` | Courbe net score avec barres par match |
| `plot_cumulative_kd()` | Courbe K/D cumul√© avec ligne cible |
| `plot_rolling_kd()` | K/D glissant avec K/D par match |
| `plot_session_trend()` | Indicateurs de tendance (d√©but/fin/delta) |
| `plot_cumulative_comparison()` | Comparaison deux sessions superpos√©es |
| `create_cumulative_metrics_indicator()` | Indicateurs compacts m√©triques |

**Sprint 7 : Page Analyse Objectifs**

Page cr√©√©e : `src/ui/pages/objective_analysis.py`

Sections de la page :
1. Vue d'ensemble avec m√©triques (objectifs, kills, assists, ratio)
2. Profil du joueur (Slayer/Support/Polyvalent)
3. Graphiques : scatter objectifs vs kills, r√©partition, tendances
4. Analyse des assistances avec camembert
5. Top awards par cat√©gorie
6. Conseils personnalis√©s

Module cr√©√© : `src/visualization/objective_charts.py`

| Graphique | Description |
|-----------|-------------|
| `plot_objective_vs_kills_scatter()` | Scatter correlation + tendance |
| `plot_objective_breakdown_bars()` | Barres r√©partition par cat√©gorie |
| `plot_top_players_objective_bars()` | Top N joueurs horizontal |
| `plot_objective_ratio_gauge()` | Gauge ratio objectifs/total |
| `plot_assist_breakdown_pie()` | Camembert types d'assistances |
| `plot_objective_trend_over_time()` | √âvolution dans le temps |

Nouvelles fonctions dans `src/analysis/objective_participation.py` :

| Fonction | Description |
|----------|-------------|
| `compute_objective_kill_ratio_polars()` | Ratio objectifs/kills par match |
| `compute_player_profile_polars()` | D√©terminer profil joueur |
| `compute_objective_efficiency_polars()` | Efficacit√© objective |

**Corrections** :
- `HALO_COLORS.get()` ‚Üí `HALO_COLORS.green` (attribut vs dict)
- `THEME_COLORS.get("text")` ‚Üí `THEME_COLORS.text_primary`
- `pl.count()` ‚Üí `pl.len()` (d√©pr√©ciation Polars)

**Tests** : 50 passent (24 Sprint 6 + 26 Sprint 4)

**Prochains sprints** : 8 (Backfill), 9 (Optimisation)

---

### [2026-02-03] - SPRINTS 4 & 5 TERMIN√âS : Analyses et Visualisations

**Statut** : ‚úÖ **SUCC√àS** - 46 tests passent

**Sprint 4 : Analyses Score Personnel avec Polars**

Module cr√©√© : `src/analysis/objective_participation.py`

| Fonction | Description |
|----------|-------------|
| `compute_objective_participation_score_polars()` | Score de participation (objectifs, assists, kills) |
| `rank_players_by_objective_contribution_polars()` | Classement des joueurs par contribution |
| `compute_assist_breakdown_polars()` | D√©composition des assistances |
| `compute_objective_summary_by_match_polars()` | R√©sum√© par match |
| `compute_award_frequency_polars()` | Fr√©quence des awards |

Dataclasses :
- `ObjectiveParticipationResult` : Scores et ratios
- `AssistBreakdownResult` : D√©composition des assists
- `PlayerObjectiveRanking` : Classement joueur

**Sprint 5 : Visualisations Antagonistes**

Module cr√©√© : `src/visualization/antagonist_charts.py`

| Graphique | Description |
|-----------|-------------|
| `plot_killer_victim_stacked_bars()` | Barres empil√©es kills/deaths par joueur |
| `plot_kd_timeseries()` | K/D par minute avec cumul |
| `plot_duel_history()` | Historique des duels entre 2 joueurs |
| `plot_nemesis_victim_summary()` | Indicateurs n√©m√©sis/souffre-douleur |
| `plot_killer_victim_heatmap()` | Heatmap matrice killer‚Üívictim |
| `plot_top_antagonists_bars()` | Top n√©m√©sis et victimes |
| `create_kd_indicator()` | Indicateur K/D simple |

**Corrections** :
- Ajout des fonctions Polars manquantes dans `killer_victim.py`
- Correction d'un test avec assertions incorrectes (`victim_times_killed`)

**Tests** : 46 passent (26 Sprint 4 + 20 Sprint 3)

**Prochains sprints** : 6 (Performance Cumul√©e), 7 (Analyses Avanc√©es)

---

### [2026-02-02] - R√âSULTATS: Investigation Bit-Shifted Binary Chunks (v2)

**Statut** : ‚úÖ **SUCC√àS PARTIEL** - Events extraits, Weapon ID non trouv√©

**Contexte** :
Investigation approfondie des film chunks avec extraction bit-shifted selon la m√©thode Den Delimarsky.

**R√©sultats valid√©s** :

| Test | R√©sultat | D√©tails |
|------|----------|---------|
| Structure Den Delimarsky | ‚úÖ VALID√âE | 72+ bytes par event |
| Event types (10/20/50) | ‚úÖ VALID√âS | mode/death/kill confirm√©s |
| Timestamp format | ‚úÖ **BIG ENDIAN** | Pas Little Endian comme suppos√© |
| Corr√©lation th√©√¢tre | ‚úÖ **100%** | 14/14 kills match√©s (< 2.5s delta) |

**R√©sultat n√©gatif** :

| Test | R√©sultat | D√©tails |
|------|----------|---------|
| Weapon ID dans extra bytes | ‚ùå √âCHEC | Pattern `0x2ee0` constant pour TOUTES les armes |

**D√©couverte cl√©** : Le timestamp est en **Big Endian**, pas Little Endian !

```python
# FAUX
timestamp = struct.unpack('<I', ts_bytes)[0]

# CORRECT
timestamp = struct.unpack('>I', ts_bytes)[0]
```

**Livrables** :
- `scripts/analyze_chunks_bitshifted.py` : Script d'analyse complet
- `.ai/research/BINARY_CHUNK_ANALYSIS_V2_PLAN.md` : Documentation mise √† jour
- `data/investigation/chunks/189d1c23_full/` : Chunks du match Fiesta

**Conclusion** :
Les events (kills, deaths) peuvent √™tre extraits avec timestamps pr√©cis (~1-2s).
Le weapon ID **n'est PAS encod√©** dans la structure document√©e par Den Delimarsky.
Le pattern `0x2ee0` trouv√© pr√©c√©demment n'est PAS un weapon ID mais un marker constant.

**Investigation compl√©mentaire (Headers et Medals)** :

1. **Header (bytes 0-11)** = Identifiant JOUEUR (pas arme)
   - Chaque joueur a un header unique et constant
   - Exemple: JGtm = `4cde91e8aba1301621967cf9`

2. **Medal ID (byte 71)** = Inf√©rence partielle possible (~7%)
   - Kill Sniper 1:04 ‚Üí Medal 108 ("Snipe") ‚úì
   - Mais 14/15 kills n'ont pas de medal li√©e √† l'arme

**Conclusion d√©finitive** : Le weapon ID n'est pas disponible dans les film chunks.

**Derni√®re th√©orie (Event DEATH victime)** :
- Event DEATH de la victime analys√© ‚Üí Extra bytes identiques pour diff√©rentes armes
- Pas de structure killer+victim combin√©e
- API Match Stats v√©rifi√© ‚Üí Seulement compteurs agr√©g√©s (PowerWeaponKills, MeleeKills, etc.)

**VERDICT FINAL** : Les weapon stats individuelles par kill ne sont PAS disponibles (limitation 343i).

---

### [2026-02-02] - IMPORTANT : Limites de l'API Halo Infinite (Weapon Stats)

**Statut** : ‚ùå **CONFIRM√â - Les weapon breakdowns N'EXISTENT PAS dans l'API**

**Contexte** :
L'utilisateur a demand√© d'obtenir les armes utilis√©es pour chaque kill. Apr√®s investigation approfondie, nous confirmons que cette donn√©e n'est pas disponible.

**V√©rifications effectu√©es** :
1. Match Stats API (`/hi/matches/{id}/stats`) - 15 matchs test√©s
2. Service Record API (`/hi/players/{xuid}/matchmade/servicerecord`)
3. Blog de Den Delimarsky (r√©f√©rence communautaire)

**R√©sultat** : `CoreStats.Breakdowns.Weapons[]` **n'existe pas** dans les r√©ponses API r√©elles.

**Ce qui est disponible** :
```
GrenadeKills, HeadshotKills, MeleeKills, PowerWeaponKills (compteurs agr√©g√©s uniquement)
```

**Ce qui N'EST PAS disponible** :
- Kills par type d'arme (BR75, Sidekick, etc.)
- Pr√©cision par arme
- D√©g√¢ts par arme
- Association kill ‚Üí arme utilis√©e

**Documentation** : Voir `.ai/archive/BINARY_CHUNK_ANALYSIS_FINAL.md` section "Limites de l'API"

**Impact** : Le projet ne peut pas impl√©menter de statistiques par arme. Cette limitation est c√¥t√© 343 Industries, pas c√¥t√© LevelUp.

---

### [2026-02-02] - R√âSULTATS : Analyse binaire des Film Chunks (weapon_id)

**Statut** : ‚úÖ **SUCC√àS - WEAPON ID TROUV√â !**

**D√©couverte cl√©** :
- Les weapon IDs sont dans les **chunks type 3** (summary), pas type 2 (gameplay)
- Position : **bytes 74-75** (offset 72+2/72+3 dans extra_bytes)
- Format : uint16 little-endian

**Mapping confirm√©** :
| Bytes | uint16 | Arme |
|-------|--------|------|
| `0x2e 0xe0` | 57390 | Sidekick |
| `0x17 0x70` | 28695 | MA40 AR |

**Validation** : Match `7f1bbf06-d54d-4434-ad80-923fcabe8b1b`
- 48 kills total (tous joueurs)
- 41 kills Sidekick (pattern `0x2e 0xe0`)
- 7 kills AR/Melee (pattern `0x17 0x70`)
- Correspond aux donn√©es fournies par l'utilisateur

---

### [2026-02-02] - ANCIENNE ANALYSE (avant d√©couverte chunk type 3)

**Statut** : ‚ö†Ô∏è √âchec partiel (chunks type 2 uniquement)

**Ce qui a √©t√© fait** :
1. T√©l√©chargement des chunks binaires (27 fichiers, ~20 MB) via `refetch_film_roster.py`
2. Cr√©ation de `scripts/extract_binary_events.py` - extraction via structure 72 bytes
3. Cr√©ation de `scripts/analyze_binary_patterns.py` - analyse via marker 0x2D 0xC0
4. Analyse de 907 contextes marker et 378 events candidats

**R√©sultats** :
- **Structure roster** identifi√©e via marker `0x2D 0xC0` (XUID/Gamertag/m√©tadonn√©es)
- **Faux positifs** massifs (~90%) dans la d√©tection d'events
- **Timestamps aberrants** (>8h) indiquant des structures diff√©rentes dans les chunks type 2
- **Weapon_id NON TROUV√â** dans les bytes analys√©s

**Conclusion** :
La structure 72 bytes document√©e est pour les **chunks type 3 (summary)**, pas type 2 (gameplay).
Les chunks type 3 ne sont pas toujours pr√©sents dans les manifests.

**Pistes restantes** :
1. Trouver des matchs avec chunks type 3
2. Corr√©ler avec weapon_stats de l'API match_stats
3. Analyser les donn√©es de replay frame-by-frame

**Livrables** :
- `.ai/research/BINARY_ANALYSIS_RESULTS.md` : Rapport complet
- `data/investigation/*.json` : Donn√©es d'analyse

---

### [2026-02-02] - RECHERCHE : Identification des armes dans les Highlight Events

**Contexte** :
Les highlight events contiennent des √©v√©nements kill/death mais **l'arme utilis√©e n'est pas document√©e**. L'utilisateur souhaite explorer les donn√©es brutes pour identifier des patterns potentiels.

**√âtat de l'art** (source: Den Delimarsky, SPNKr) :

La structure connue d'un event fait 72 bytes :
| Offset | Taille | Contenu |
|--------|--------|---------|
| 0 | 12 | Header (inconnu) |
| 12 | 32 | Gamertag (UTF-16) |
| 44 | 15 | Padding |
| 59 | 1 | Type (10=mode, 20=death, 50=kill) |
| 60 | 4 | Timestamp (ms) |
| 64 | 3 | Padding |
| 67 | 1 | Medal marker |
| 68 | 3 | Padding |
| 71 | 1 | Medal ID |
| 72+ | ? | **BYTES NON DOCUMENT√âS** |

**Hypoth√®ses de recherche** :
1. L'arme pourrait √™tre dans les bytes au-del√† de l'offset 72
2. L'arme pourrait √™tre encod√©e dans le header (0-12 bytes)
3. L'arme pourrait √™tre dans un event s√©par√© corr√©l√© par timestamp
4. Les chunks de type 2 (in-game events) pourraient contenir l'arme active

**Livrables cr√©√©s** :
- `.ai/research/HIGHLIGHT_WEAPON_RESEARCH.md` : Rapport de recherche d√©taill√©
- `scripts/analyze_highlight_binary.py` : Script d'analyse exp√©rimentale

**Prochaines √©tapes** :
```bash
# Analyser les raw_json existants
python scripts/analyze_highlight_binary.py --gamertag MonGT --analyze-json

# T√©l√©charger et analyser les chunks binaires
python scripts/analyze_highlight_binary.py --match-id <GUID> --analyze-binary

# G√©n√©rer un rapport complet
python scripts/analyze_highlight_binary.py --gamertag MonGT --report
```

**R√©sultats de l'analyse (match 7f1bbf06)** :
- 187 events trouv√©s dans la DB SQLite legacy
- 6 kills par JGtm identifi√©s
- **AUCUN champ weapon_id** dans le JSON pars√©
- Medal "Gunslinger" obtenue ‚Üí confirme utilisation Sidekick
- Tous les kills ont `medal_value: 0` et `type_hint: 50` (pas de diff√©renciation)

**Conclusion** : L'arme n'est PAS dans les donn√©es JSON pars√©es par SPNKr.
Il faut analyser les **bytes binaires bruts** des chunks de film.

**Plan d'action cr√©√©** : `.ai/research/BINARY_CHUNK_ANALYSIS_PLAN.md`

**Suivi** :
- [x] Recherche document√©e ‚úÖ
- [x] Script d'analyse cr√©√© ‚úÖ
- [x] Analyse des raw_json ‚úÖ (aucun champ weapon)
- [x] Plan d'analyse binaire cr√©√© ‚úÖ
- [ ] Configuration tokens API (utilisateur)
- [ ] T√©l√©chargement chunks bruts
- [ ] Analyse binaire des bytes non document√©s
- [ ] Corr√©lation avec armes connues (via medals)

---

### [2026-02-02] - Nettoyage colonnes objectives (19 colonnes supprim√©es du sch√©ma)

**Contexte** :
Comme pour `weapon_stats`, des colonnes objectives ont √©t√© ajout√©es au sch√©ma en anticipation de donn√©es que l'API Halo Infinite ne fournit pas r√©ellement. Ces 19 colonnes √©taient toujours NULL.

**Colonnes supprim√©es** :

| Cat√©gorie | Colonnes |
|-----------|----------|
| Expected | `expected_kills`, `expected_deaths` |
| Objectives | `objectives_completed` |
| Zone/Stronghold | `zone_captures`, `zone_defensive_kills`, `zone_offensive_kills`, `zone_secures`, `zone_occupation_time` |
| CTF | `ctf_flag_captures`, `ctf_flag_grabs`, `ctf_flag_returners_killed`, `ctf_flag_returns`, `ctf_flag_carriers_killed`, `ctf_time_as_carrier_seconds` |
| Oddball | `oddball_time_held_seconds`, `oddball_kills_as_carrier`, `oddball_kills_as_non_carrier` |
| Stockpile | `stockpile_seeds_deposited`, `stockpile_seeds_collected` |

**Actions r√©alis√©es** :

| Fichier | Action |
|---------|--------|
| `src/data/sync/models.py` | Supprim√© 19 attributs de `MatchStatsRow` |
| `scripts/migrate_player_to_duckdb.py` | Retir√© 19 colonnes du CREATE TABLE |
| `scripts/migrate_add_columns.py` | Ajout√© `COLUMNS_TO_DROP` avec logique DROP COLUMN |
| `tests/test_cache_integrity.py` | Retir√© r√©f√©rences `expected_kills`/`expected_deaths` |

**Migration ex√©cut√©e** :
```
Joueurs trait√©s: 4
Colonnes ajout√©es: 52 (13 √ó 4 joueurs)
Tables weapon_stats supprim√©es: 4
```

Note : Les colonnes objectives n'existaient pas encore dans les bases (elles n'avaient jamais √©t√© ajout√©es via migration), donc aucune suppression de colonne n'√©tait n√©cessaire.

**Sch√©ma final match_stats** (colonnes conserv√©es) :
```
match_id, start_time, playlist_id, playlist_name, map_id, map_name,
pair_id, pair_name, game_variant_id, game_variant_name, outcome, team_id,
rank, kills, deaths, assists, kda, accuracy, headshot_kills, max_killing_spree,
time_played_seconds, avg_life_seconds, my_team_score, enemy_team_score,
team_mmr, enemy_mmr, damage_dealt, damage_taken, shots_fired, shots_hit,
grenade_kills, melee_kills, power_weapon_kills, score, personal_score,
mode_category, is_ranked, is_firefight, left_early,
session_id, session_label, performance_score, teammates_signature,
known_teammates_count, is_with_friends, friends_xuids, created_at, updated_at
```

**Suivi** :
- [x] Mod√®le MatchStatsRow nettoy√© ‚úÖ
- [x] Sch√©ma CREATE TABLE nettoy√© ‚úÖ
- [x] Script migration avec DROP COLUMN ‚úÖ
- [x] Audit code obsol√®te ‚úÖ
- [x] Migration bases existantes ‚úÖ

---

### [2026-02-02] - Tests complets des fonctions de visualisation (74 tests)

**Contexte** :
Aucun test fonctionnel n'existait pour les 27+ fonctions de visualisation. Seuls des tests d'import existaient dans `test_phase6_refactoring.py`.

**Raisonnement** :
Les graphiques sont une partie critique de l'application. Sans tests, les bugs peuvent passer inaper√ßus (DataFrames vides, NaN, colonnes manquantes).

**Actions r√©alis√©es** :

| Action | D√©tail |
|--------|--------|
| Plan cr√©√© | `.ai/test_visualizations_plan.md` ‚Äî inventaire complet des 27 fonctions |
| Tests cr√©√©s | `tests/test_visualizations.py` ‚Äî 74 tests couvrant toutes les fonctions |
| Bugs corrig√©s | `radar_chart.py` ne g√©rait pas les listes vides (2 fonctions corrig√©es) |
| CI mis √† jour | `.github/workflows/ci.yml` ‚Äî √©tape d√©di√©e aux tests de visualisation |
| Marker ajout√© | `pyproject.toml` ‚Äî marker `visualization` enregistr√© |

**Fonctions test√©es** :

| Module | Fonctions | Tests |
|--------|-----------|-------|
| `distributions.py` | 10 | 28 |
| `timeseries.py` | 7 | 16 |
| `maps.py` | 2 | 4 |
| `match_bars.py` | 2 | 5 |
| `trio.py` | 1 | 3 |
| `radar_chart.py` | 3 | 7 |
| `chart_annotations.py` | 2 | 5 |
| **Module imports** | 7 | 7 |
| **Total** | **27** | **74** |

**Bugs d√©couverts et corrig√©s** :

| Fonction | Bug | Fix |
|----------|-----|-----|
| `create_stats_per_minute_radar()` | `max()` sur liste vide | Ajout gestion cas vide |
| `create_performance_radar()` | `max()` sur liste vide | Ajout gestion cas vide |
| `plot_timeseries()` | Ne g√®re pas empty DataFrame | Test accepte l'exception (√† corriger plus tard) |

**Ex√©cution** :
```bash
pytest tests/test_visualizations.py -v -m visualization
# 74 passed in 2.50s
```

**Suivi** :
- [x] Tests cr√©√©s et valid√©s ‚úÖ
- [x] CI mis √† jour ‚úÖ
- [x] Bugs radar corrig√©s ‚úÖ
- [ ] TODO : Corriger `plot_timeseries()` pour g√©rer DataFrames vides proprement

---

### [2026-02-02] - PLAN : Suppression table `weapon_stats` et ajout colonnes manquantes

**Contexte** :
La table `weapon_stats` est vide et inutile. Elle √©tait con√ßue pour stocker des statistiques par arme individuelle (BR, AR, Sniper, etc.), mais l'API Halo Infinite ne fournit pas ces donn√©es d√©taill√©es par arme.

Les seules donn√©es de tir disponibles via l'API sont :
- `shots_fired` (tirs totaux par match)
- `shots_hit` (tirs au but par match)
- `accuracy` (d√©j√† calcul√©e)

Ces donn√©es appartiennent √† `match_stats`, pas √† une table s√©par√©e.

**Probl√®me identifi√©** :
1. Table `weapon_stats` : Vide et inutile (donn√©es par arme non disponibles)
2. Colonnes manquantes dans `match_stats` : Le mod√®le `MatchStatsRow` contient `shots_fired`, `shots_hit`, `damage_dealt`, etc. mais le sch√©ma DuckDB ne les a pas

**D√©cision** :
Nettoyer le code et aligner le sch√©ma avec les donn√©es r√©ellement disponibles.

---

#### Phase 1 : Nettoyage du code `weapon_stats`

| Fichier | Action |
|---------|--------|
| `src/data/sync/models.py` | Supprimer `WeaponStatsRow` et `WeaponAggregateRow` |
| `src/data/sync/transformers.py` | Supprimer `extract_weapon_stats()`, `has_weapon_stats()`, `_find_weapon_stats_dict()` |
| `src/data/sync/__init__.py` | Retirer les exports `extract_weapon_stats`, `has_weapon_stats` |
| `src/data/repositories/duckdb_repo.py` | Supprimer m√©thodes `get_weapon_stats()`, `get_global_accuracy()` |
| `src/data/infrastructure/database/duckdb_engine.py` | Supprimer TODO/commentaires li√©s aux armes |
| `scripts/migrate_player_to_duckdb.py` | Supprimer cr√©ation table `weapon_stats` |

---

#### Phase 2 : Ajout colonnes manquantes √† `match_stats`

| Colonne | Type | Description |
|---------|------|-------------|
| `shots_fired` | INTEGER | Nombre total de tirs |
| `shots_hit` | INTEGER | Tirs au but |
| `damage_dealt` | FLOAT | D√©g√¢ts inflig√©s |
| `damage_taken` | FLOAT | D√©g√¢ts re√ßus |
| `score` | INTEGER | Score du match |
| `personal_score` | INTEGER | Score personnel |
| `grenade_kills` | INTEGER | Kills grenade |
| `melee_kills` | INTEGER | Kills m√™l√©e |
| `power_weapon_kills` | INTEGER | Kills armes lourdes |

**Fichiers impact√©s** :
- `scripts/migrate_player_to_duckdb.py` : Ajouter colonnes au CREATE TABLE

---

#### Phase 3 : Migration des donn√©es existantes

| Action | D√©tail |
|--------|--------|
| Script ALTER TABLE | Ajouter colonnes manquantes aux bases existantes |
| DROP TABLE weapon_stats | Supprimer la table inutile |

---

#### R√©sum√© des fichiers √† modifier

| Fichier | Suppressions | Ajouts |
|---------|--------------|--------|
| `src/data/sync/models.py` | 2 classes | - |
| `src/data/sync/transformers.py` | 3 fonctions (~150 lignes) | - |
| `src/data/sync/__init__.py` | 2 exports | - |
| `src/data/repositories/duckdb_repo.py` | 2 m√©thodes | - |
| `src/data/infrastructure/database/duckdb_engine.py` | Commentaires | - |
| `scripts/migrate_player_to_duckdb.py` | CREATE weapon_stats | 9 colonnes match_stats |

**Suivi** :
- [x] Phase 1 : Nettoyage code weapon_stats ‚úÖ (2026-02-02)
- [x] Phase 2 : Ajout colonnes match_stats ‚úÖ (2026-02-02)
- [x] Phase 3 : Migration donn√©es existantes ‚úÖ (2026-02-02)

**R√©sum√© des modifications** :

| Fichier | Action |
|---------|--------|
| `src/data/sync/models.py` | Supprim√© `WeaponStatsRow`, `WeaponAggregateRow` |
| `src/data/sync/transformers.py` | Supprim√© `extract_weapon_stats()`, `has_weapon_stats()`, `_find_weapon_stats_dict()` |
| `src/data/sync/__init__.py` | Retir√© exports weapon_stats |
| `src/data/repositories/duckdb_repo.py` | Supprim√© `get_top_weapons()`, `get_total_shots_stats()` |
| `src/data/infrastructure/database/duckdb_engine.py` | Supprim√© `get_kd_evolution_by_weapon()` |
| `scripts/migrate_player_to_duckdb.py` | Supprim√© CREATE TABLE weapon_stats, ajout√© 32 colonnes √† match_stats |
| `scripts/migrate_add_columns.py` | **NOUVEAU** - Script migration pour bases existantes |

---

### [2026-02-01] - Phase 6 COMPLETE - Documentation & Branding LevelUp

**Contexte** :
Phase 5 (Enrichissement Visuel) termin√©e. Passage √† la Phase 6 : Documentation compl√®te et branding "LevelUp".

**Objectif** :
Mise √† jour de toute la documentation pour refl√©ter l'architecture DuckDB v4 et le nouveau nom "LevelUp".

**Actions r√©alis√©es** :

#### Sprint 6.1 : README & Documentation Utilisateur

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| S6.1.1 | `README.md` | R√©√©criture compl√®te avec branding LevelUp |
| S6.1.2 | `docs/INSTALL.md` | Guide d'installation d√©taill√© |
| S6.1.3 | `docs/CONFIGURATION.md` | Guide de configuration tokens/profils |
| S6.1.4 | `docs/FAQ.md` | Questions fr√©quentes |

#### Sprint 6.2 : Documentation Technique

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| S6.2.1 | `docs/ARCHITECTURE.md` | Architecture DuckDB unifi√©e |
| S6.2.2 | `docs/DATA_ARCHITECTURE.md` | Sch√©ma des donn√©es v4 |
| S6.2.3 | `docs/SQL_SCHEMA.md` | D√©j√† √† jour |
| S6.2.4 | `docs/SYNC_GUIDE.md` | Nouveau guide de synchronisation |

#### Sprint 6.3 : Branding & Renommage

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| S6.3.1 | Global | Renommage OpenSpartan ‚Üí LevelUp |
| S6.3.2 | `pyproject.toml` | name="levelup-halo", version="3.0.0" |

#### Sprint 6.4 : Documentation Agent/IA

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| S6.4.1 | `CLAUDE.md` | MAJ avec architecture DuckDB |
| S6.4.2 | `.cursorrules` | MAJ avec stack DuckDB |
| S6.4.3 | `.ai/project_map.md` | MAJ cartographie |
| S6.4.4 | `.ai/data_lineage.md` | MAJ flux de donn√©es |
| S6.4.5 | `.ai/archive/` | Archivage ancien thought_log |

#### Sprint 6.5 : GitHub & CI/CD

| T√¢che | Fichier | Description |
|-------|---------|-------------|
| S6.5.1 | `.github/copilot-instructions.md` | MAJ instructions |
| S6.5.2 | `.github/workflows/ci.yml` | Ajout tests DuckDB |
| S6.5.3 | `CONTRIBUTING.md` | Nouveau guide de contribution |

**Fichiers cr√©√©s/modifi√©s** :

```
README.md                        # R√©√©criture compl√®te
CONTRIBUTING.md                  # Nouveau
CLAUDE.md                        # MAJ
.cursorrules                     # MAJ
pyproject.toml                   # MAJ (name, version)
docs/INSTALL.md                  # Nouveau
docs/CONFIGURATION.md            # Nouveau
docs/FAQ.md                      # Nouveau
docs/SYNC_GUIDE.md               # Nouveau
docs/ARCHITECTURE.md             # MAJ
docs/DATA_ARCHITECTURE.md        # MAJ
.ai/project_map.md               # MAJ
.ai/data_lineage.md              # MAJ
.ai/archive/thought_log_pre_phase6.md  # Archive
.github/copilot-instructions.md  # MAJ
.github/workflows/ci.yml         # MAJ
```

**D√©cisions** :

| D√©cision | Justification |
|----------|---------------|
| Nom "LevelUp" | Plus moderne et parlant que "OpenSpartan Graph" |
| Version 3.0.0 | Refl√®te l'architecture DuckDB unifi√©e |
| Archivage thought_log | Fichier trop long, repartir frais |

**Suivi** :
- [x] Sprint 6.1 : README & Documentation Utilisateur ‚úÖ
- [x] Sprint 6.2 : Documentation Technique ‚úÖ
- [x] Sprint 6.3 : Branding & Renommage ‚úÖ
- [x] Sprint 6.4 : Documentation Agent/IA ‚úÖ
- [x] Sprint 6.5 : GitHub & CI/CD ‚úÖ

**Phase 6 termin√©e** ‚úÖ

---

## Format des Entr√©es

```
### [DATE] - [SUJET]
**Contexte** : Situation initiale
**Raisonnement** : Pourquoi cette approche
**D√©cision** : Ce qui a √©t√© fait
**Suivi** : Ce qui reste √† faire ou √† v√©rifier
```

---

<!-- Les nouvelles entr√©es sont ajout√©es ici, les plus r√©centes en haut -->
