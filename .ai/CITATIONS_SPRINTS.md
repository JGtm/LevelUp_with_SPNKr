# Citations - Plan de Sprints

**Date crÃ©ation** : 2026-02-14  
**Statut global** : âœ… COMPLETED  
**Architecture cible** : DuckDB v4 + Table `match_citations` par match  
**Date fin** : 2026-02-15

---

## ğŸ“‹ Vue d'ensemble

**Objectif** : Migrer le systÃ¨me de citations vers architecture DuckDB-first avec stockage par match.

**BÃ©nÃ©fices** :
- 41 â†’ 47 citations (+14.6%)
- Performance affichage : -90% (500ms â†’ 50ms)
- Graphiques temporels d'Ã©volution nativement possibles

**Sprint 0** : âœ… COMPLETED - DÃ©cisions validÃ©es, fichiers crÃ©Ã©s  
**Sprint 1** : âœ… COMPLETED - Tables DuckDB + Nettoyage  
**Sprint 2** : âœ… COMPLETED - CitationEngine core  
**Sprint 3** : âœ… COMPLETED - IntÃ©gration sync + backfill  
**Sprint 4** : âœ… COMPLETED - Refactoring UI  
**Sprint 5** : âœ… COMPLETED - Tests finaux + Documentation

---

## âœ… Sprint 0 : Analyse & DÃ©cisions (TERMINÃ‰)

**DurÃ©e** : 2h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-14

### Livrables

- [x] Analyse 114 citations exclues
- [x] Identification 18 citations mappables
- [x] Validation utilisateur : 6 citations
- [x] CrÃ©ation `scripts/create_citation_mappings_table.py`
- [x] CrÃ©ation `src/analysis/citations/custom_rules.py`
- [x] Documentation [CITATIONS_DECISIONS_FINALES.md](CITATIONS_DECISIONS_FINALES.md)
- [x] Documentation [CITATIONS_ARCHITECTURE_ANALYSIS.md](CITATIONS_ARCHITECTURE_ANALYSIS.md)

### Review âœ…

**Agent validateur** : Analyse terminÃ©e, documents crÃ©Ã©s, prÃªt pour implÃ©mentation.

---

## âœ… Sprint 1 : Tables DuckDB + Nettoyage

**DurÃ©e** : 2-3h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-15  
**DÃ©pendances** : Sprint 0 âœ…  
**Owner** : Developer

### ğŸ“¦ TÃ¢ches

#### 1.1 Table `citation_mappings` (rÃ©fÃ©rentiel)

**Fichier** : `scripts/create_citation_mappings_table.py` (existe dÃ©jÃ  âœ…)

- [ ] **TÃ¢che 1.1.1** : ExÃ©cuter le script
  ```bash
  python scripts/create_citation_mappings_table.py
  ```
  - **VÃ©rification** : `SELECT COUNT(*) FROM citation_mappings` doit retourner 14
  - **Test** : VÃ©rifier colonnes (citation_name_norm, mapping_type, award_name, custom_function)

- [ ] **TÃ¢che 1.1.2** : Valider les donnÃ©es insÃ©rÃ©es
  ```sql
  SELECT citation_name_display, mapping_type, award_name, custom_function 
  FROM citation_mappings 
  ORDER BY mapping_type, citation_name_display;
  ```
  - **Attendu** : 5 awards + 1 custom + 8 existantes

#### 1.2 Table `match_citations` (donnÃ©es par match)

**Fichier** : `scripts/create_match_citations_table.py` (Ã  crÃ©er)

- [ ] **TÃ¢che 1.2.1** : CrÃ©er le script
  - **Template** : S'inspirer de `create_citation_mappings_table.py`
  - **SchÃ©ma SQL** :
    ```sql
    CREATE TABLE IF NOT EXISTS match_citations (
        match_id TEXT NOT NULL,
        citation_name_norm TEXT NOT NULL,
        value INTEGER NOT NULL,
        PRIMARY KEY (match_id, citation_name_norm)
    );
    CREATE INDEX IF NOT EXISTS idx_match_citations_name 
        ON match_citations(citation_name_norm);
    ```
  - **Emplacement** : Doit crÃ©er la table dans **chaque** DB joueur `data/players/{gamertag}/stats.duckdb`

- [ ] **TÃ¢che 1.2.2** : ExÃ©cuter le script
  ```bash
  python scripts/create_match_citations_table.py
  ```
  - **VÃ©rification multi-joueurs** : VÃ©rifier que la table existe dans au moins 2 DBs joueurs
  - **Test** : `SELECT name FROM sqlite_master WHERE type='table' AND name='match_citations'` (pour chaque DB)

- [ ] **TÃ¢che 1.2.3** : CrÃ©er tests unitaires
  - **Fichier** : `tests/test_match_citations_table.py`
  - **Tests** :
    - `test_table_exists()` : VÃ©rifier existence table
    - `test_schema_correct()` : VÃ©rifier colonnes (match_id, citation_name_norm, value)
    - `test_primary_key()` : VÃ©rifier PK (match_id, citation_name_norm)
    - `test_index_exists()` : VÃ©rifier index sur citation_name_norm

#### 1.3 Retirer citations de la blacklist

**Fichier** : `data/wiki/halo5_commendations_exclude.json`

- [ ] **TÃ¢che 1.3.1** : Ã‰diter le fichier
  - **Supprimer** :
    - "DÃ©fenseur du drapeau"
    - "Je te tiens !"
    - "Sus au porteur du drapeau"
    - "Partie prenante"
    - "Ã€ la charge"
    - "Annexion forcÃ©e"
  - **VÃ©rification** : Fichier JSON valide aprÃ¨s modification

- [ ] **TÃ¢che 1.3.2** : Tester affichage
  - **Lancer app** : `streamlit run streamlit_app.py`
  - **VÃ©rifier** : 47 citations affichÃ©es (41 + 6) dans la section Citations

#### 1.4 Archiver fichiers obsolÃ¨tes

- [ ] **TÃ¢che 1.4.1** : CrÃ©er dossier archive
  ```bash
  mkdir -p scripts/_archive/obsolete_citations
  ```

- [ ] **TÃ¢che 1.4.2** : DÃ©placer fichiers JSON (si existent)
  ```bash
  # VÃ©rifier existence puis dÃ©placer
  if [ -f out/commendations_mapping_assumed.json ]; then
      mv out/commendations_mapping_assumed.json scripts/_archive/obsolete_citations/
  fi
  if [ -f out/commendations_mapping_unmatched.json ]; then
      mv out/commendations_mapping_unmatched.json scripts/_archive/obsolete_citations/
  fi
  ```

- [ ] **TÃ¢che 1.4.3** : Mettre Ã  jour `.gitignore`
  - **Ajouter** : `out/commendations_*.json`

- [ ] **TÃ¢che 1.4.4** : Documenter dans CHANGELOG
  - **Section** : `[Unreleased] - 2026-02-14`
  - **Type** : `### Deprecated`
  - **Message** : "Fichiers JSON de tracking citations (out/*.json) remplacÃ©s par tables DuckDB"

### âœ… CritÃ¨res de validation Sprint 1

- [ ] Table `citation_mappings` crÃ©Ã©e avec 14 lignes
- [ ] Table `match_citations` crÃ©Ã©e dans toutes les DBs joueurs
- [ ] 47 citations affichÃ©es dans l'app
- [ ] Fichiers JSON archivÃ©s (si existaient)
- [ ] Tests unitaires tables passent (âœ… 4/4)
- [ ] `.gitignore` mis Ã  jour
- [ ] CHANGELOG documentÃ©

### ğŸ” Review obligatoire avant validation

**Agent reviewer** :
1. VÃ©rifier tables crÃ©Ã©es (`SELECT * FROM citation_mappings LIMIT 5`)
2. VÃ©rifier schÃ©ma `match_citations` (colonnes, PK, index)
3. Tester affichage 47 citations
4. VÃ©rifier tests unitaires passent
5. **Marquer Sprint 1 comme** :
   - âœ… COMPLETED si tout OK
   - âš ï¸ WARNING si problÃ¨mes mineurs
   - âŒ FAILED si bloquant

---

## âœ… Sprint 2 : CitationEngine Core

**DurÃ©e** : 3-4h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-15  
**DÃ©pendances** : Sprint 1 âœ…  
**Owner** : Developer

### ğŸ“¦ TÃ¢ches

#### 2.1 Module `engine.py`

**Fichier** : `src/analysis/citations/engine.py` (Ã  crÃ©er)

- [ ] **TÃ¢che 2.1.1** : CrÃ©er classe `CitationEngine`
  - **Architecture** :
    ```python
    class CitationEngine:
        def __init__(self, db_path: str, xuid: str):
            """Initialise le moteur avec connexion DB joueur."""
            pass
        
        def load_mappings(self) -> dict[str, dict]:
            """Charge depuis citation_mappings (metadata.duckdb)."""
            pass
        
        def compute_citation_for_match(
            self, 
            mapping: dict, 
            match_data: dict
        ) -> int:
            """Calcule 1 citation pour 1 match."""
            pass
        
        def compute_all_for_match(
            self, 
            match_id: str, 
            match_data: dict
        ) -> dict[str, int]:
            """Calcule toutes citations pour 1 match.
            
            Returns:
                {"citation_name_norm": value}
            """
            pass
        
        def aggregate_citations(
            self, 
            citation_names: list[str], 
            match_ids: list[str] | None = None
        ) -> dict[str, int]:
            """AgrÃ¨ge depuis match_citations (SELECT SUM).
            
            Args:
                citation_names: Liste citations Ã  agrÃ©ger
                match_ids: Filtrer par matchs (None = tous)
            
            Returns:
                {"citation_name_norm": total_value}
            """
            pass
    ```

- [ ] **TÃ¢che 2.1.2** : ImplÃ©menter `load_mappings()`
  - **Source** : `data/warehouse/metadata.duckdb`
  - **RequÃªte** : `SELECT * FROM citation_mappings`
  - **Retour** : `{"citation_name_norm": {mapping dict}}`

- [ ] **TÃ¢che 2.1.3** : ImplÃ©menter `compute_citation_for_match()`
  - **Support types** :
    - `medal` : Lookup dans `match_data["medals"]` (dict medal_id â†’ count)
    - `stat` : Lookup dans `match_data["stats"]` (dict stat_name â†’ value)
    - `award` : Somme dans `match_data["awards"]` (dict award_name â†’ count)
    - `custom` : Appel fonction depuis `CUSTOM_FUNCTIONS` registry

- [ ] **TÃ¢che 2.1.4** : ImplÃ©menter `compute_all_for_match()`
  - **Logique** :
    1. Charger tous les mappings
    2. Pour chaque mapping, calculer la valeur
    3. Retourner dict sparse (seulement value > 0)

- [ ] **TÃ¢che 2.1.5** : ImplÃ©menter `aggregate_citations()`
  - **RequÃªte SQL** :
    ```sql
    SELECT citation_name_norm, SUM(value) as total
    FROM match_citations
    WHERE citation_name_norm IN (?)
      AND (match_id IN (?) OR ? IS NULL)
    GROUP BY citation_name_norm
    ```

#### 2.2 Support types de donnÃ©es

- [ ] **TÃ¢che 2.2.1** : Helper `_load_match_medals(match_id)`
  - **Source** : `SELECT medal_name_id, count FROM medals_earned WHERE match_id = ?`
  - **Retour** : `{medal_id: count}`

- [ ] **TÃ¢che 2.2.2** : Helper `_load_match_stats(match_id)`
  - **Source** : `SELECT * FROM match_stats WHERE match_id = ?`
  - **Retour** : `{"kills": 10, "deaths": 5, ...}`

- [ ] **TÃ¢che 2.2.3** : Helper `_load_match_awards(match_id)`
  - **Source** : `SELECT award_name, SUM(award_count) FROM personal_score_awards WHERE match_id = ? GROUP BY award_name`
  - **Retour** : `{"Flag Defense": 3, "Zone Capture": 5}`

- [ ] **TÃ¢che 2.2.4** : IntÃ©gration `CUSTOM_FUNCTIONS`
  - **Import** : `from src.analysis.citations.custom_rules import CUSTOM_FUNCTIONS`
  - **Appel** : `func = CUSTOM_FUNCTIONS.get(mapping["custom_function"])` puis `func(data)`

#### 2.3 Tests unitaires `CitationEngine`

**Fichier** : `tests/test_citation_engine.py`

- [ ] **TÃ¢che 2.3.1** : Tests `load_mappings()`
  - `test_load_mappings_returns_dict()`
  - `test_load_mappings_has_14_entries()`
  - `test_load_mappings_structure()`

- [ ] **TÃ¢che 2.3.2** : Tests `compute_citation_for_match()`
  - `test_compute_medal_type()` : Citation type medal
  - `test_compute_stat_type()` : Citation type stat
  - `test_compute_award_type()` : Citation type award
  - `test_compute_custom_type()` : Citation type custom
  - `test_compute_returns_zero_if_missing()` : DonnÃ©es manquantes

- [ ] **TÃ¢che 2.3.3** : Tests `compute_all_for_match()`
  - `test_compute_all_returns_sparse()` : Seulement value > 0
  - `test_compute_all_includes_all_types()` : Tous types supportÃ©s
  - `test_compute_all_empty_match()` : Match sans donnÃ©es

- [ ] **TÃ¢che 2.3.4** : Tests `aggregate_citations()`
  - `test_aggregate_all_matches()` : Tous matchs
  - `test_aggregate_filtered_matches()` : Sous-ensemble matchs
  - `test_aggregate_returns_totals()` : Sommes correctes

### âœ… CritÃ¨res de validation Sprint 2

- [ ] `CitationEngine` implÃ©mentÃ©e avec 4 mÃ©thodes publiques
- [ ] Support 4 types (medal, stat, award, custom)
- [ ] Tests unitaires passent (âœ… 12/12 minimum)
- [ ] Coverage > 80% sur `engine.py`
- [ ] Documentation docstrings complÃ¨te

### ğŸ” Review obligatoire avant validation

**Agent reviewer** :
1. ExÃ©cuter `python -m pytest tests/test_citation_engine.py -v`
2. VÃ©rifier couverture `python -m pytest --cov=src/analysis/citations/engine`
3. Tester manuellement avec 1 match rÃ©el
4. VÃ©rifier que `aggregate_citations()` retourne bonnes valeurs
5. **Marquer Sprint 2 comme** :
   - âœ… COMPLETED si tests OK + coverage > 80%
   - âš ï¸ WARNING si coverage 60-80%
   - âŒ FAILED si tests fail

---

## âœ… Sprint 3 : IntÃ©gration Sync + Backfill

**DurÃ©e** : 3-4h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-15  
**DÃ©pendances** : Sprint 2 âœ…  
**Owner** : Developer

### ğŸ“¦ TÃ¢ches

#### 3.1 IntÃ©gration au sync

**Fichier** : `scripts/sync.py`

- [ ] **TÃ¢che 3.1.1** : Ajouter calcul citations aprÃ¨s insertion matchs
  - **Emplacement** : AprÃ¨s `repo.insert_match_data()`
  - **Logique** :
    ```python
    from src.analysis.citations.engine import CitationEngine
    
    # AprÃ¨s insertion match
    engine = CitationEngine(db_path, xuid)
    match_data = {
        "medals": medals_dict,
        "stats": stats_dict,
        "awards": awards_dict
    }
    citations = engine.compute_all_for_match(match_id, match_data)
    
    # INSERT sparse (seulement value > 0)
    for citation_norm, value in citations.items():
        if value > 0:
            repo.insert_citation(match_id, citation_norm, value)
    ```

- [ ] **TÃ¢che 3.1.2** : CrÃ©er mÃ©thode `DuckDBRepository.insert_citation()`
  - **Fichier** : `src/data/repositories/duckdb_repo.py`
  - **Signature** :
    ```python
    def insert_citation(
        self, 
        match_id: str, 
        citation_name_norm: str, 
        value: int
    ) -> None:
        """InsÃ¨re ou met Ã  jour une citation pour un match."""
        pass
    ```
  - **SQL** : `INSERT OR REPLACE INTO match_citations VALUES (?, ?, ?)`

- [ ] **TÃ¢che 3.1.3** : Logger nb citations insÃ©rÃ©es
  - **Message** : `f"âœ… Citations insÃ©rÃ©es: {len(citations)} pour match {match_id}"`

- [ ] **TÃ¢che 3.1.4** : Tester avec 1 match rÃ©el
  - **Commande** : `python scripts/sync.py --delta --player TestPlayer --max-matches 1`
  - **VÃ©rification** : `SELECT * FROM match_citations WHERE match_id = ?`

#### 3.2 Option backfill `--citations`

**Fichier** : `scripts/backfill/cli.py`

- [ ] **TÃ¢che 3.2.1** : Ajouter argument `--citations`
  - **Ligne ~150** :
    ```python
    parser.add_argument(
        "--citations",
        action="store_true",
        help="Calculer et insÃ©rer les citations pour les matchs existants"
    )
    parser.add_argument(
        "--force-citations",
        action="store_true",
        help="Force le recalcul des citations pour TOUS les matchs"
    )
    ```

- [ ] **TÃ¢che 3.2.2** : Passer argument Ã  `backfill_player_data()`
  - **Fichier** : `scripts/backfill_data.py`
  - **Ajouter paramÃ¨tres** : `citations=args.citations, force_citations=args.force_citations`

**Fichier** : `scripts/backfill/orchestrator.py`

- [ ] **TÃ¢che 3.2.3** : Ajouter paramÃ¨tre `citations` Ã  `backfill_player_data()`
  - **Signature** :
    ```python
    async def backfill_player_data(
        player: str,
        ...,
        citations: bool = False,
        force_citations: bool = False,
        ...
    ) -> dict:
    ```

- [ ] **TÃ¢che 3.2.4** : ImplÃ©menter logique backfill citations
  - **Fichier** : CrÃ©er `scripts/backfill/strategies.py` (section citations)
  - **Fonction** :
    ```python
    def backfill_citations_for_match(
        match_id: str,
        db_path: str,
        xuid: str,
        force: bool = False
    ) -> int:
        """Calcule et insÃ¨re citations pour 1 match.
        
        Args:
            force: Si True, recalcule mÃªme si dÃ©jÃ  prÃ©sent
        
        Returns:
            Nombre de citations insÃ©rÃ©es
        """
        # 1. VÃ©rifier si dÃ©jÃ  calculÃ© (sauf si force=True)
        if not force:
            existing = check_citations_exist(match_id, db_path)
            if existing:
                return 0
        
        # 2. Charger donnÃ©es match
        engine = CitationEngine(db_path, xuid)
        match_data = load_match_data(match_id, db_path)
        
        # 3. Calculer citations
        citations = engine.compute_all_for_match(match_id, match_data)
        
        # 4. InsÃ©rer (sparse)
        repo = DuckDBRepository(db_path, xuid)
        count = 0
        for citation_norm, value in citations.items():
            if value > 0:
                repo.insert_citation(match_id, citation_norm, value)
                count += 1
        
        return count
    ```

- [ ] **TÃ¢che 3.2.5** : IntÃ©grer dans orchestrator
  - **Logique** :
    ```python
    if citations or all_data:
        logger.info("Traitement citations...")
        for match_id in match_ids:
            count = backfill_citations_for_match(
                match_id, db_path, xuid, force_citations
            )
            results["citations_inserted"] += count
    ```

- [ ] **TÃ¢che 3.2.6** : Ajouter progress bar
  - **Utiliser** : `tqdm` comme pour les autres backfills
  - **Message** : `"Calcul citations"`

#### 3.3 Tests backfill

**Fichier** : `tests/test_backfill_citations.py`

- [ ] **TÃ¢che 3.3.1** : Test backfill 1 match
  - `test_backfill_citations_single_match()` : VÃ©rifie INSERT citations

- [ ] **TÃ¢che 3.3.2** : Test backfill avec force
  - `test_backfill_citations_force_recalculates()` : Force recalcul

- [ ] **TÃ¢che 3.3.3** : Test backfill skip si existe
  - `test_backfill_citations_skips_existing()` : Ne recalcule pas par dÃ©faut

- [ ] **TÃ¢che 3.3.4** : Test intÃ©gration complÃ¨te
  - `test_backfill_player_with_citations()` : Backfill joueur complet

#### 3.4 Documentation CLI

- [ ] **TÃ¢che 3.4.1** : Mettre Ã  jour help `--citations`
  - **Ajouter exemples** dans `_get_usage_examples()` :
    ```python
    Examples:
        # Calculer citations pour matchs existants
        python scripts/backfill_data.py --player JGtm --citations
        
        # Force recalcul toutes citations
        python scripts/backfill_data.py --player JGtm --citations --force-citations
        
        # Backfill tout (inclut citations)
        python scripts/backfill_data.py --player JGtm --all-data
    ```

- [ ] **TÃ¢che 3.4.2** : Mettre Ã  jour `_print_totals()`
  - **Ajouter** :
    ```python
    if getattr(args, "citations", False):
        logger.info(f"Citations insÃ©rÃ©es: {totals.get('citations_inserted', 0)}")
    ```

### âœ… CritÃ¨res de validation Sprint 3

- [ ] Sync insÃ¨re citations automatiquement aprÃ¨s chaque match
- [ ] Option `--citations` fonctionnelle dans backfill
- [ ] Option `--force-citations` recalcule tout
- [ ] Progress bar affichÃ©e pendant backfill
- [ ] Tests backfill passent (âœ… 4/4)
- [ ] Help CLI documentÃ©

### ğŸ” Review obligatoire avant validation

**Agent reviewer** :
1. Tester sync 1 match : `python scripts/sync.py --delta --player TestPlayer --max-matches 1`
2. VÃ©rifier INSERT citations : `SELECT COUNT(*) FROM match_citations`
3. Tester backfill : `python scripts/backfill_data.py --player TestPlayer --citations --max-matches 10`
4. VÃ©rifier force : `python scripts/backfill_data.py --player TestPlayer --citations --force-citations --max-matches 5`
5. ExÃ©cuter tests : `python -m pytest tests/test_backfill_citations.py -v`
6. **Marquer Sprint 3 comme** :
   - âœ… COMPLETED si sync + backfill OK + tests passent
   - âš ï¸ WARNING si problÃ¨mes mineurs (ex: progress bar manquante)
   - âŒ FAILED si INSERT fail ou tests fail

---

## âœ… Sprint 4 : Refactoring UI

**DurÃ©e** : 2-3h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-15  
**DÃ©pendances** : Sprint 3 âœ…  
**Owner** : Developer

### ğŸ“¦ TÃ¢ches

#### 4.1 Simplifier `src/ui/commendations.py`

**Fichier** : `src/ui/commendations.py`

- [ ] **TÃ¢che 4.1.1** : Supprimer code obsolÃ¨te
  - **Lignes ~59-103** : Supprimer `CUSTOM_CITATION_RULES` dict
  - **Lignes ~105-200** : Supprimer `_compute_custom_citation_value()` fonction
  - **Rechercher et supprimer** : `load_h5g_commendations_tracking_rules()` (si existe)

- [ ] **TÃ¢che 4.1.2** : Remplacer par `CitationEngine`
  - **Import** :
    ```python
    from src.analysis.citations.engine import CitationEngine
    ```
  
  - **Remplacer boucle de calcul** (lignes ~850) par :
    ```python
    # Charger engine
    engine = CitationEngine(db_path, xuid)
    
    # AgrÃ©ger citations (tous matchs)
    citation_names_all = [_normalize_name(it["name"]) for it in items]
    citations_totals_full = engine.aggregate_citations(
        citation_names=citation_names_all,
        match_ids=None  # Tous matchs
    )
    
    # AgrÃ©ger citations (matchs filtrÃ©s)
    if is_filtered:
        citations_totals_filtered = engine.aggregate_citations(
            citation_names=citation_names_all,
            match_ids=filtered_match_ids
        )
    else:
        citations_totals_filtered = citations_totals_full
    ```

- [ ] **TÃ¢che 4.1.3** : Remplacer calcul par citation
  - **Avant** (lignes ~850-890) :
    ```python
    # SUPPRIMER ceci
    if norm_name in CUSTOM_CITATION_RULES:
        current = _compute_custom_citation_value(...)
    elif isinstance(rule.get("medal_ids"), list):
        ...
    ```
  
  - **AprÃ¨s** :
    ```python
    # Simple lookup
    current_full = citations_totals_full.get(norm_name, 0)
    current_filtered = citations_totals_filtered.get(norm_name, 0)
    
    # Delta
    delta = current_filtered if is_filtered else 0
    ```

- [ ] **TÃ¢che 4.1.4** : Tester affichage
  - **Lancer app** : `streamlit run streamlit_app.py`
  - **VÃ©rifier** :
    - 47 citations affichÃ©es
    - Valeurs correctes (comparer avec ancien code)
    - Delta fonctionne avec filtres

#### 4.2 Support filtres & delta

- [ ] **TÃ¢che 4.2.1** : Calculer `filtered_match_ids`
  - **Source** : `df_filtered["match_id"].to_list()` (dÃ©jÃ  existant normalement)

- [ ] **TÃ¢che 4.2.2** : GÃ©rer cas "pas de filtres"
  - **Logique** :
    ```python
    is_filtered = (df_filtered.height != df_full.height)
    if is_filtered:
        filtered_match_ids = df_filtered["match_id"].to_list()
        citations_filtered = engine.aggregate_citations(..., filtered_match_ids)
    else:
        citations_filtered = citations_full  # Ã‰vite requÃªte inutile
    ```

- [ ] **TÃ¢che 4.2.3** : Afficher delta en badge
  - **DÃ©jÃ  existant** : Badge delta pour mÃ©dailles/stats
  - **RÃ©utiliser** : MÃªme logique pour citations

#### 4.3 Optimisation performance

- [ ] **TÃ¢che 4.3.1** : Cache Streamlit optionnel
  - **Ajouter** (si besoin) :
    ```python
    @st.cache_data(ttl=300)  # 5 min cache
    def _load_citations_totals(db_path: str, xuid: str) -> dict:
        engine = CitationEngine(db_path, xuid)
        return engine.aggregate_citations(citation_names=all_names)
    ```

- [ ] **TÃ¢che 4.3.2** : Benchmark temps affichage
  - **Avant refactoring** : ~500ms (mesurer avec `time.time()`)
  - **AprÃ¨s refactoring** : Doit Ãªtre < 100ms

#### 4.4 Tests UI

**Fichier** : `tests/test_commendations_ui.py`

- [ ] **TÃ¢che 4.4.1** : Test affichage 47 citations
  - `test_display_47_citations()` : VÃ©rifier nombre

- [ ] **TÃ¢che 4.4.2** : Test valeurs correctes
  - `test_citation_values_match_db()` : Comparer avec DB

- [ ] **TÃ¢che 4.4.3** : Test filtres
  - `test_citations_filtered_by_date()` : Filtrer par pÃ©riode
  - `test_citations_delta_displayed()` : Delta affichÃ©

- [ ] **TÃ¢che 4.4.4** : Test performance
  - `test_citations_load_time_under_100ms()` : Benchmark

### âœ… CritÃ¨res de validation Sprint 4

- [ ] Code obsolÃ¨te supprimÃ© (CUSTOM_CITATION_RULES, _compute_custom_citation_value)
- [ ] CitationEngine intÃ©grÃ© dans UI
- [ ] 47 citations affichÃ©es correctement
- [ ] Filtres + delta fonctionnels
- [ ] Temps affichage < 100ms
- [ ] Tests UI passent (âœ… 4/4)

### ğŸ” Review obligatoire avant validation

**Agent reviewer** :
1. VÃ©rifier code supprimÃ© (grep "CUSTOM_CITATION_RULES" doit Ãªtre vide)
2. Tester app : `streamlit run streamlit_app.py`
3. Compter citations affichÃ©es (doit Ãªtre 47)
4. Tester filtres (date, mode) et vÃ©rifier delta
5. Benchmark temps : Mesurer avec DevTools Network
6. ExÃ©cuter tests : `python -m pytest tests/test_commendations_ui.py -v`
7. **Marquer Sprint 4 comme** :
   - âœ… COMPLETED si affichage OK + perfs < 100ms + tests passent
   - âš ï¸ WARNING si perfs 100-200ms mais fonctionnel
   - âŒ FAILED si affichage cassÃ© ou tests fail

---

## âœ… Sprint 5 : Tests Finaux + Documentation

**DurÃ©e** : 2h  
**Statut** : âœ… COMPLETED  
**Date fin** : 2026-02-15  
**DÃ©pendances** : Sprint 4 âœ…  
**Owner** : Developer

### ğŸ“¦ TÃ¢ches

#### 5.1 Tests d'intÃ©gration

**Fichier** : `tests/integration/test_citations_integration.py`

- [ ] **TÃ¢che 5.1.1** : Test workflow complet
  - `test_sync_backfill_display_citations()` :
    1. Sync 10 matchs
    2. VÃ©rifier citations insÃ©rÃ©es
    3. Backfill 5 matchs anciens
    4. Charger UI et vÃ©rifier totaux

- [ ] **TÃ¢che 5.1.2** : Test migration donnÃ©es existantes
  - `test_migrate_from_old_system()` :
    1. Si ancien systÃ¨me existe, comparer valeurs
    2. VÃ©rifier cohÃ©rence

- [ ] **TÃ¢che 5.1.3** : Test performance end-to-end
  - `test_performance_1000_matches()` :
    1. Backfill 1000 matchs
    2. Mesurer temps agrÃ©gation
    3. VÃ©rifier < 50ms

#### 5.2 Documentation

**Fichier** : `docs/CITATIONS.md` (Ã  crÃ©er)

- [ ] **TÃ¢che 5.2.1** : Documenter architecture
  - **Sections** :
    - Tables DuckDB (citation_mappings, match_citations)
    - SchÃ©mas SQL
    - Workflow (sync â†’ calcul â†’ INSERT)

- [ ] **TÃ¢che 5.2.2** : Guide ajouter citation
  - **Ã‰tapes** :
    1. DÃ©finir rÃ¨gle dans `citation_mappings`
    2. Si custom, crÃ©er fonction dans `custom_rules.py`
    3. Backfill matchs existants
    4. Retirer de blacklist (si besoin)

- [ ] **TÃ¢che 5.2.3** : Guide backfill
  - **Exemples CLI** :
    ```bash
    # Backfill citations joueur
    python scripts/backfill_data.py --player JGtm --citations
    
    # Force recalcul tout
    python scripts/backfill_data.py --all --citations --force-citations
    ```

- [ ] **TÃ¢che 5.2.4** : FAQ
  - **Questions** :
    - Comment changer une rÃ¨gle de calcul ?
    - Quel impact espace disque ?
    - Comment voir Ã©volution temporelle ? (requÃªte SQL exemple)

**Fichier** : `.ai/thought_log.md`

- [ ] **TÃ¢che 5.2.5** : Documenter dÃ©cisions
  - **Section** : "2026-02-14 - Refactoring Citations"
  - **Contenu** :
    - DÃ©cisions architecture (match_citations)
    - Raisons (performance, graphiques temporels)
    - Trade-offs (espace disque vs performance)

**Fichier** : `CHANGELOG.md`

- [ ] **TÃ¢che 5.2.6** : Release notes
  - **Section** : `[Unreleased] - 2026-02-14`
  - **Added** :
    - 6 nouvelles citations objectives
    - Table `match_citations` pour stockage par match
    - Graphiques temporels d'Ã©volution (future)
  - **Changed** :
    - Performance affichage citations : -90%
    - Architecture DuckDB-first (vs fichiers JSON)
  - **Deprecated** :
    - Fichiers JSON tracking (out/*.json)
  - **Removed** :
    - Code hardcodÃ© `CUSTOM_CITATION_RULES`

#### 5.3 Monitoring & MÃ©triques

- [ ] **TÃ¢che 5.3.1** : Ajouter logs sync
  - **Message** : `f"âœ… {count} citations insÃ©rÃ©es pour {match_id}"`

- [ ] **TÃ¢che 5.3.2** : Ajouter stats backfill
  - **Afficher** : Temps moyen par match, nb lignes insÃ©rÃ©es

- [ ] **TÃ¢che 5.3.3** : Script de diagnostic
  - **Fichier** : `scripts/diagnose_citations.py`
  - **Fonctions** :
    - Compter lignes `match_citations` par joueur
    - Lister citations les plus progressÃ©es
    - VÃ©rifier cohÃ©rence (matchs sans citations)

#### 5.4 Nettoyage final

- [ ] **TÃ¢che 5.4.1** : Supprimer code mort
  - **Rechercher** : `grep -r "CUSTOM_CITATION_RULES" src/`
  - **Rechercher** : `grep -r "load_h5g_commendations_tracking_rules" src/`

- [ ] **TÃ¢che 5.4.2** : Formater code
  - **ExÃ©cuter** : `black src/ scripts/`
  - **ExÃ©cuter** : `isort src/ scripts/`
  - **ExÃ©cuter** : `ruff check src/ scripts/`

- [ ] **TÃ¢che 5.4.3** : VÃ©rifier tests couvrent tout
  - **Coverage globale** : `python -m pytest --cov=src/analysis/citations --cov=src/data/repositories`
  - **Objectif** : > 85%

### âœ… CritÃ¨res de validation Sprint 5

- [ ] Tests d'intÃ©gration passent (âœ… 3/3)
- [ ] Documentation `docs/CITATIONS.md` complÃ¨te
- [ ] CHANGELOG mis Ã  jour
- [ ] `.ai/thought_log.md` documentÃ©
- [ ] Coverage > 85%
- [ ] Code formatÃ© (black, isort, ruff)
- [ ] Aucun code mort restant

### ğŸ” Review obligatoire avant validation

**Agent reviewer** :
1. ExÃ©cuter suite tests complÃ¨te : `python -m pytest`
2. VÃ©rifier coverage : `python -m pytest --cov=src --cov-report=html`
3. Lire `docs/CITATIONS.md` et valider clartÃ©
4. VÃ©rifier CHANGELOG complet
5. Tester script diagnostic : `python scripts/diagnose_citations.py`
6. **Marquer Sprint 5 comme** :
   - âœ… COMPLETED si tests OK + doc complÃ¨te + coverage > 85%
   - âš ï¸ WARNING si doc incomplÃ¨te mais fonctionnel
   - âŒ FAILED si tests fail ou coverage < 70%

---

## ğŸ“Š Suivi Global des Sprints

| Sprint | Statut | DurÃ©e estimÃ©e | DurÃ©e rÃ©elle | Tests | Coverage | Bloqueurs |
|--------|--------|---------------|--------------|-------|----------|-----------|
| 0 - Analyse | âœ… COMPLETED | 2h | 2h | N/A | N/A | Aucun |
| 1 - Tables DB | ğŸ”µ TODO | 2-3h | - | 4/4 | N/A | - |
| 2 - Engine | ğŸ”µ TODO | 3-4h | - | 12/12 | >80% | Sprint 1 |
| 3 - Sync+Backfill | ğŸ”µ TODO | 3-4h | - | 4/4 | >70% | Sprint 2 |
| 4 - UI | ğŸ”µ TODO | 2-3h | - | 4/4 | >75% | Sprint 3 |
| 5 - Tests+Doc | ğŸ”µ TODO | 2h | - | 3/3 | >85% | Sprint 4 |
| **TOTAL** | **ğŸŸ¡ IN_PROGRESS** | **12-16h** | **-** | **27/27** | **>85%** | **-** |

### LÃ©gende statuts

- ğŸ”µ **TODO** : Pas commencÃ©
- ğŸŸ¡ **IN_PROGRESS** : En cours
- âœ… **COMPLETED** : TerminÃ© et validÃ©
- âš ï¸ **WARNING** : TerminÃ© avec rÃ©serves
- âŒ **FAILED** : Ã‰chec, nÃ©cessite reprise

---

## ğŸ¯ RÃ¨gles de Livraison (OBLIGATOIRES)

### Avant de marquer un sprint COMPLETED

1. **âœ… Toutes les tÃ¢ches terminÃ©es** : Checklist complÃ¨te
2. **âœ… Tests unitaires passent** : `pytest` vert pour le scope du sprint
3. **âœ… Review agent effectuÃ©e** : Agent validateur a vÃ©rifiÃ©
4. **âœ… Documentation Ã  jour** : Docstrings, CHANGELOG, docs/
5. **âœ… Pas de rÃ©gression** : Tests existants toujours verts
6. **âœ… Code formatÃ©** : black + isort + ruff OK

### Processus de review agent

**Pour chaque sprint, AVANT de marquer COMPLETED** :

1. **Agent lit les critÃ¨res de validation**
2. **Agent exÃ©cute les commandes de vÃ©rification**
3. **Agent teste manuellement (si applicable)**
4. **Agent dÃ©cide** :
   - âœ… COMPLETED : Tout OK, sprint validÃ©
   - âš ï¸ WARNING : Fonctionnel mais problÃ¨mes mineurs (documenter)
   - âŒ FAILED : Bloquant, nÃ©cessite correction

5. **Agent documente** :
   - RÃ©sultat validation dans section Review du sprint
   - Bloqueurs identifiÃ©s (si WARNING/FAILED)
   - Recommandations pour sprint suivant

### Workflow type

```bash
# Developer termine les tÃ¢ches
git commit -m "feat(citations): Sprint 1 - Tables DuckDB"

# Developer demande review
# Agent lance validation automatique
python -m pytest tests/test_match_citations_table.py -v
python scripts/validate_sprint.py --sprint 1

# Agent marque sprint
# Si OK : âœ… COMPLETED dans CITATIONS_SPRINTS.md
# Si KO : âš ï¸ WARNING ou âŒ FAILED avec dÃ©tails
```

---

## ğŸ“ Notes Techniques

### Architecture fichiers

```
scripts/
â”œâ”€â”€ backfill/
â”‚   â”œâ”€â”€ cli.py              # Arguments CLI (ajout --citations)
â”‚   â”œâ”€â”€ orchestrator.py     # Orchestration (ajout citations)
â”‚   â””â”€â”€ strategies.py       # Backfill citations spÃ©cifique
â”œâ”€â”€ backfill_data.py        # Point d'entrÃ©e
â”œâ”€â”€ create_citation_mappings_table.py  # âœ… Existe
â””â”€â”€ create_match_citations_table.py    # ğŸ”µ Ã€ crÃ©er

src/analysis/citations/
â”œâ”€â”€ __init__.py             # âœ… Existe
â”œâ”€â”€ custom_rules.py         # âœ… Existe (6 fonctions)
â””â”€â”€ engine.py               # ğŸ”µ Ã€ crÃ©er (CitationEngine)

tests/
â”œâ”€â”€ test_citation_engine.py           # ğŸ”µ Ã€ crÃ©er (12 tests)
â”œâ”€â”€ test_backfill_citations.py        # ğŸ”µ Ã€ crÃ©er (4 tests)
â”œâ”€â”€ test_commendations_ui.py          # ğŸ”µ Ã€ crÃ©er (4 tests)
â”œâ”€â”€ test_match_citations_table.py     # ğŸ”µ Ã€ crÃ©er (4 tests)
â””â”€â”€ integration/
    â””â”€â”€ test_citations_integration.py # ğŸ”µ Ã€ crÃ©er (3 tests)
```

### Commandes utiles

```bash
# CrÃ©er tables
python scripts/create_citation_mappings_table.py
python scripts/create_match_citations_table.py

# Sync avec citations
python scripts/sync.py --delta --player JGtm

# Backfill citations
python scripts/backfill_data.py --player JGtm --citations
python scripts/backfill_data.py --all --citations --force-citations

# Tests
python -m pytest tests/test_citation_engine.py -v
python -m pytest --cov=src/analysis/citations
python -m pytest  # Suite complÃ¨te

# Diagnostic
python scripts/diagnose_citations.py --player JGtm
```

---

**Document crÃ©Ã©** : 2026-02-14  
**Prochaine action** : Commencer Sprint 1 - CrÃ©er tables DuckDB
