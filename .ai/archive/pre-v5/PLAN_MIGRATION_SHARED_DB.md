# Plan de Migration : Base de Donn√©es Partag√©e Multi-Joueurs

> **R√©f√©rence** : [ANALYSE_OPTIMISATION_MATCHS_PARTAGES.md](ANALYSE_OPTIMISATION_MATCHS_PARTAGES.md)  
> **Date** : 2026-02-14  
> **Statut** : Proposition de refactoring majeur  

---

## üéØ Probl√®me Identifi√©

**Duplication massive des donn√©es de matchs partag√©s entre joueurs.**

### Exemples Concrets

- Madina97294 partage **95%** de ses matchs avec Chocoboflor
- xxdameongamerxx partage **100%** de ses matchs avec Chocoboflor
- JGtm partage **75%** de ses matchs avec Chocoboflor

**Cons√©quence** : Pour 1 match √† 8 joueurs tous track√©s, les donn√©es sont stock√©es **8 fois** !

---

## üí° Solution Propos√©e : DB Shared Centralis√©e

### Architecture Cible

```
data/
‚îú‚îÄ‚îÄ warehouse/
‚îÇ   ‚îú‚îÄ‚îÄ metadata.duckdb              # R√©f√©rentiels (existant)
‚îÇ   ‚îî‚îÄ‚îÄ shared_matches.duckdb        # ‚≠ê NOUVEAU
‚îÇ       ‚îú‚îÄ‚îÄ match_registry           # Registre central
‚îÇ       ‚îú‚îÄ‚îÄ match_participants       # Roster (1 seule fois)
‚îÇ       ‚îú‚îÄ‚îÄ highlight_events         # Events (1 seule fois)
‚îÇ       ‚îî‚îÄ‚îÄ xuid_aliases             # Aliases globaux
‚îÇ
‚îî‚îÄ‚îÄ players/
    ‚îú‚îÄ‚îÄ Chocoboflor/
    ‚îÇ   ‚îî‚îÄ‚îÄ stats.duckdb
    ‚îÇ       ‚îú‚îÄ‚îÄ player_match_stats   # Stats personnelles uniquement
    ‚îÇ       ‚îú‚îÄ‚îÄ medals_earned
    ‚îÇ       ‚îî‚îÄ‚îÄ teammates_aggregate
    ‚îî‚îÄ‚îÄ ...
```

### Principe

**Donn√©es Communes** (identiques pour tous les joueurs) ‚Üí `shared_matches.duckdb`
- Roster complet (`match_participants`)
- √âv√©nements film√©s (`highlight_events`)
- M√©tadonn√©es du match (map, playlist, scores des √©quipes, etc.)

**Donn√©es Sp√©cifiques** (vue subjective du joueur) ‚Üí `players/{gt}/stats.duckdb`
- Kills/deaths/assists **du joueur**
- M√©dailles gagn√©es
- Performance score
- Session ID

---

## üìä Gains Attendus

### Stockage

| M√©trique | Avant | Apr√®s | √âconomie |
|----------|-------|-------|----------|
| Taille totale (4 joueurs, 1000 matchs, 90% partag√©s) | ~800 MB | ~250 MB | **-69%** |
| `match_participants` | 40 000 lignes | 10 000 lignes | **-75%** |
| `highlight_events` | 400 000 lignes | 100 000 lignes | **-75%** |

### API & Performance

| Op√©ration | Avant | Apr√®s | Gain |
|-----------|-------|-------|------|
| Sync initiale 4 joueurs | 12 000 appels | 3 300 appels | **-72%** |
| Backfill 1 joueur (100 matchs, 90% partag√©s) | 300 appels | 30 appels | **-90%** |
| Temps de sync (estimation) | ~45 min | ~12 min | **-73%** |

---

## üîÑ Plan de Migration (5 Phases)

### Phase 1 : Infrastructure (Sprint 0) ‚≠ê PRIORIT√â HAUTE

**Objectif** : Cr√©er `shared_matches.duckdb` avec le sch√©ma complet.

**Actions** :
```sql
-- scripts/migration/create_shared_matches_db.sql
CREATE TABLE match_registry (
    match_id VARCHAR PRIMARY KEY,
    start_time TIMESTAMP NOT NULL,
    playlist_id VARCHAR,
    map_id VARCHAR,
    -- M√©tadonn√©es de backfill
    backfill_completed INTEGER DEFAULT 0,
    participants_loaded BOOLEAN DEFAULT FALSE,
    events_loaded BOOLEAN DEFAULT FALSE,
    -- Tracking
    first_sync_by VARCHAR,
    player_count SMALLINT,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

CREATE TABLE match_participants (...);
CREATE TABLE highlight_events (...);
CREATE TABLE xuid_aliases (...);
```

**Livrables** :
- ‚úÖ `data/warehouse/shared_matches.duckdb` cr√©√©
- ‚úÖ Scripts DDL valid√©s
- ‚úÖ Index cr√©√©s

---

### Phase 2 : Migration des Donn√©es (Sprint 1) ‚≠ê PRIORIT√â HAUTE

**Objectif** : Migrer les donn√©es existantes vers `shared_matches`.

**Script** : `scripts/migration/migrate_to_shared_matches.py`

**Ordre de migration** :
1. **Chocoboflor** (base de r√©f√©rence, le plus de matchs)
2. **Madina97294** (95% partag√©s ‚Üí peu d'ajouts)
3. **JGtm** (75% partag√©s)
4. **xxdameongamerxx** (100% partag√©s ‚Üí 0 ajout th√©orique)

**Logique** :
```python
for gamertag in ["Chocoboflor", "Madina97294", "JGtm", "xxdameongamerxx"]:
    for match in get_player_matches(gamertag):
        if match_id not in shared_registry:
            # Nouveau match ‚Üí ins√©rer tout
            insert_into_shared(match_id, participants, events)
            set_first_sync_by(gamertag)
        else:
            # Match d√©j√† connu ‚Üí juste incr√©menter player_count
            increment_player_count(match_id)
```

**Validation** :
```sql
SELECT 
    COUNT(*) as total_matches,
    AVG(player_count) as avg_players_per_match,
    SUM(CASE WHEN player_count > 1 THEN 1 ELSE 0 END) as shared_matches
FROM match_registry;

-- R√©sultat attendu :
-- total_matches: ~1050 (vs 4000 dupliqu√©s avant)
-- avg_players_per_match: ~3.8
-- shared_matches: ~950 (90%)
```

---

### Phase 3 : Refactoring Sync Engine (Sprint 2) ‚≠ê PRIORIT√â HAUTE

**Objectif** : Adapter `src/data/sync/engine.py` pour d√©tecter les matchs partag√©s.

**Modifications** :

```python
class DuckDBSyncEngine:
    def __init__(self, ..., shared_db_path: str = "data/warehouse/shared_matches.duckdb"):
        self._shared_connection = None
    
    async def _process_single_match(self, client, match_id, options):
        # 1. V√©rifier dans shared_matches
        registry = self._get_shared_connection().execute(
            "SELECT * FROM match_registry WHERE match_id = ?", 
            (match_id,)
        ).fetchone()
        
        if registry:
            # ‚úÖ Match connu ‚Üí sync all√©g√©e
            return await self._process_known_match(match_id, registry, options)
        else:
            # ‚≠ê Nouveau match ‚Üí sync compl√®te
            return await self._process_new_match(match_id, options)
    
    async def _process_known_match(self, match_id, registry, options):
        """Optimis√© : r√©cup√®re SEULEMENT les stats personnelles."""
        
        # 1. API call minimal (stats seulement)
        stats_json = await client.get_match_stats(match_id)
        
        # 2. Extraire donn√©es personnelles
        player_stats = extract_player_specific_stats(stats_json, self._xuid)
        
        # 3. Ins√©rer dans player DB
        self._insert_player_match_stats(player_stats)
        
        # 4. Backfill s√©lectif si n√©cessaire
        if not registry['participants_loaded']:
            participants = extract_participants(stats_json)
            self._insert_participants_to_shared(participants)
        
        if not registry['events_loaded'] and options.with_highlight_events:
            events = await client.get_highlight_events(match_id)
            self._insert_events_to_shared(events)
        
        # 5. Incr√©menter player_count
        self._shared_connection.execute(
            "UPDATE match_registry SET player_count = player_count + 1 WHERE match_id = ?",
            (match_id,)
        )
```

**Impact** :
- ‚úÖ √âconomie de 2 appels API par match partag√© (events + participants)
- ‚úÖ Pour Madina97294 (95% partag√©s) : **285 appels √©vit√©s** sur 300 matchs

---

### Phase 4 : Adaptation Repository (Sprint 3)

**Objectif** : Adapter `DuckDBRepository` pour lire depuis `shared_matches`.

**Modifications** :

```python
class DuckDBRepository:
    def _get_connection(self):
        if self._connection is None:
            self._connection = duckdb.connect(self._player_db_path)
            
            # ATTACH metadata (existant)
            self._connection.execute(
                f"ATTACH '{self._metadata_db_path}' AS meta (READ_ONLY)"
            )
            
            # ‚≠ê ATTACH shared_matches
            self._connection.execute(
                f"ATTACH '{self._shared_db_path}' AS shared (READ_ONLY)"
            )
        
        return self._connection
    
    def load_match_participants(self, match_id: str):
        """Lecture depuis shared.match_participants."""
        return self._connection.execute("""
            SELECT * FROM shared.match_participants
            WHERE match_id = ?
        """, (match_id,)).pl()
    
    def load_highlight_events(self, match_id: str):
        """Lecture depuis shared.highlight_events."""
        return self._connection.execute("""
            SELECT * FROM shared.highlight_events
            WHERE match_id = ?
        """, (match_id,)).pl()
```

**Impact** :
- ‚úÖ Transparence totale pour l'UI (aucune modification n√©cessaire)
- ‚úÖ Les queries existantes fonctionnent via ATTACH

---

### Phase 5 : Nettoyage (Sprint 4)

**Objectif** : Supprimer les tables redondantes des player DBs.

**Actions** :
```python
# scripts/migration/cleanup_player_tables.py
def cleanup_player_db(gamertag: str):
    # ‚ö†Ô∏è BACKUP avant suppression
    backup()
    
    # Supprimer les tables migr√©es
    conn.execute("DROP TABLE IF EXISTS match_participants")
    conn.execute("DROP TABLE IF EXISTS highlight_events")
    conn.execute("DROP TABLE IF EXISTS xuid_aliases")
    
    # Optionnel : Cr√©er des VIEWs de compatibilit√©
    conn.execute("""
        CREATE VIEW match_participants AS 
        SELECT * FROM shared.match_participants 
        WHERE match_id IN (SELECT match_id FROM player_match_stats)
    """)
```

**Impact** :
- ‚úÖ R√©duction de ~60-70% de la taille des player DBs
- ‚úÖ Simplification du sch√©ma

---

## ‚ö†Ô∏è Points d'Attention

### 1. Migration Progressive

**Risque** : Migrer tous les joueurs simultan√©ment peut causer des incoh√©rences.

**Solution** : Migrer 1 joueur √† la fois, valider, puis continuer.

### 2. Compatibilit√© Ascendante

**Probl√®me** : Le code existant cherche `match_participants` dans player DB.

**Solution** : Cr√©er des VIEWs de compatibilit√© :
```sql
CREATE VIEW match_participants AS 
SELECT * FROM shared.match_participants 
WHERE match_id IN (SELECT match_id FROM player_match_stats);
```

### 3. Concurrence

**Sc√©nario** : Sync simultan√©e de 2 joueurs sur le m√™me match.

**Solution** : Utiliser `INSERT OR IGNORE` et atomicit√© des `UPDATE`.

---

## üìã Checklist de Validation

Apr√®s chaque phase, v√©rifier :

### Phase 1 (Infrastructure)
- [ ] `shared_matches.duckdb` cr√©√© et accessible
- [ ] Toutes les tables existent
- [ ] Index cr√©√©s
- [ ] Permissions correctes

### Phase 2 (Migration)
- [ ] Tous les matchs de Chocoboflor migr√©s
- [ ] `player_count` correct dans `match_registry`
- [ ] Pas de duplications dans `match_participants`
- [ ] Pas de perte de donn√©es

### Phase 3 (Sync Engine)
- [ ] D√©tection des matchs partag√©s fonctionnelle
- [ ] Sync all√©g√©e pour matchs connus
- [ ] Sync compl√®te pour nouveaux matchs
- [ ] Bitmask `backfill_completed` mis √† jour

### Phase 4 (Repository)
- [ ] ATTACH fonctionne correctement
- [ ] Queries de lecture depuis shared OK
- [ ] Pas de r√©gression UI
- [ ] Performance acceptable

### Phase 5 (Nettoyage)
- [ ] Backups cr√©√©s avant suppression
- [ ] Tables supprim√©es
- [ ] VIEWs de compatibilit√© cr√©√©es
- [ ] UI fonctionne toujours

---

## üöÄ Recommandation Finale

**Impl√©menter en priorit√© Phases 1-3** pour b√©n√©ficier imm√©diatement :
- ‚úÖ **-72% d'appels API** sur les prochaines syncs
- ‚úÖ **-69% d'espace disque** pour les nouveaux matchs
- ‚úÖ D√©tection intelligente des matchs partag√©s

**Effort estim√©** : 
- Phase 1 : 1-2 jours (cr√©ation sch√©ma + scripts)
- Phase 2 : 2-3 jours (migration + validation)
- Phase 3 : 3-4 jours (refactoring + tests)
- **Total Phases 1-3 : ~1.5-2 semaines**

**ROI** : R√©cup√©ration de l'investissement d√®s la premi√®re sync compl√®te post-migration (√©conomie de 70% du temps et des appels API).

---

## üìö R√©f√©rences

- [Analyse Compl√®te](ANALYSE_OPTIMISATION_MATCHS_PARTAGES.md) : D√©tails techniques complets
- [DATA_ARCHITECTURE.md](../docs/DATA_ARCHITECTURE.md) : Architecture actuelle
- [SQL_SCHEMA.md](../docs/SQL_SCHEMA.md) : Sch√©mas DuckDB
- [SYNC_GUIDE.md](../docs/SYNC_GUIDE.md) : Guide de synchronisation
