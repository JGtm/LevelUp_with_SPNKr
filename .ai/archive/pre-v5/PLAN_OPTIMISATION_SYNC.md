# Plan d'Optimisation : Synchronisation DuckDB v4

**Contexte** : Performances actuelles ~16s/match lors d'un sync delta.  
**Objectif** : Atteindre ‚â§2-3s/match (gain 5-8x).

---

## üîç Diagnostic : Goulots d'√âtranglement Identifi√©s

### 1. **Appels API S√©quentiels par Match** ‚ö†Ô∏è CRITIQUE

**Localisation** : [src/data/sync/engine.py](src/data/sync/engine.py#L683-L691)

```python
# PROBL√àME : Appels s√©quentiels (pas de parall√©lisation)
if options.with_skill and xuids:
    skill_json = await client.get_skill_stats(match_id, xuids)

if options.with_highlight_events:
    highlight_events = await client.get_highlight_events(match_id)
```

**Impact** :
- Pour chaque match : 1 appel stats + 1 appel skill + 1 appel events = **3 appels s√©quentiels**
- Avec rate limit 5 req/s et latence r√©seau (~500ms-1s par appel), cela donne **~5-7s par match minimum**

**Solution Existante Non Utilis√©e** :
La m√©thode `SPNKrAPIClient.get_match_data()` existe d√©j√† et parall√©lise skill + events avec `asyncio.gather` ([api_client.py](src/data/sync/api_client.py#L492-L497)), mais elle n'est **PAS utilis√©e** dans le code de sync.

---

### 2. **Calcul de Performance Score en Temps R√©el** ‚ö†Ô∏è IMPORTANT

**Localisation** : [src/data/sync/engine.py](src/data/sync/engine.py#L768-L772)

```python
# PROBL√àME : Calcul lourd pour chaque match
self._compute_and_update_performance_score(match_id, match_row)
```

**Impact** :
- Pour chaque match ins√©r√©, requ√™te SELECT de tout l'historique avec `WHERE start_time < current_match`
- Calcul Polars sur cet historique
- UPDATE pour persister le score
- Complexit√© croissante avec le nombre de matchs (O(n¬≤) sur la session de sync)

**Estimation** : **~3-5s par match** pour 500+ matchs historiques

---

### 3. **Lock DB Global Bloquant la Parall√©lisation** üîí

**Localisation** : [src/data/sync/engine.py](src/data/sync/engine.py#L739)

```python
# PROBL√àME : Lock global emp√™che les √©critures concurrentes
async with self._db_lock:
    self._insert_match_row(match_row)
    # ... toutes les autres insertions
    self._compute_and_update_performance_score(match_id, match_row)
```

**Impact** :
- M√™me avec `parallel_matches=3`, les insertions DB sont **strictement s√©quentielles**
- Le calcul de score (lourd) se fait dans la section critique
- Aucun b√©n√©fice du semaphore pour les √©critures

---

### 4. **Pas de Commit Batch√©s**

**Constat** :
- Chaque match est committ√© individuellement via les insertions
- Pas de batching des INSERTs pour r√©duire les I/O
- Autocommit implicite sur chaque op√©ration

**Impact** : **~1-2s** de latence I/O cumul√©e

---

### 5. **Rate Limiting Conservateur**

**Configuration actuelle** :
```python
requests_per_second: int = 5  # SyncOptions par d√©faut
parallel_matches: int = 3     # Seulement 3 matchs en parall√®le
```

**Impact** :
- Avec 3 appels/match et 3 matchs en parall√®le : 9 requ√™tes/s th√©oriques
- Mais rate limit de 5 req/s bride √† ~1.67 match/s
- La parall√©lisation est sous-exploit√©e

---

## üéØ Plan d'Optimisation (par priorit√©)

### **Phase 1 : Quick Wins (impact imm√©diat)** üöÄ

#### 1.1 Parall√©liser les Appels API par Match
**Objectif** : R√©duire de 5-7s √† 2-3s par match

**Modifications** :
- Remplacer les appels s√©quentiels par `asyncio.gather` dans `_process_single_match`
- Fusionner `get_skill_stats` + `get_highlight_events` en un seul groupe parall√®le

**Fichiers** : [src/data/sync/engine.py](src/data/sync/engine.py#L683-L691)

```python
# AVANT (s√©quentiel)
skill_json = await client.get_skill_stats(match_id, xuids)
highlight_events = await client.get_highlight_events(match_id)

# APR√àS (parall√®le)
skill_json, highlight_events = await asyncio.gather(
    client.get_skill_stats(match_id, xuids) if xuids else asyncio.sleep(0),
    client.get_highlight_events(match_id),
    return_exceptions=True,
)
```

**Gain estim√©** : **-60%** du temps par match (5-7s ‚Üí 2-3s)

---

#### 1.2 Optimiser le Calcul des Scores de Performance
**Objectif** : Retirer le calcul du chemin critique tout en respectant la d√©pendance s√©quentielle

**‚ö†Ô∏è CONTRAINTE CRITIQUE** : Le score de chaque match d√©pend de l'historique **avant** lui.  
‚Üí On ne peut PAS recalculer en parall√®le ou dans le d√©sordre.

**Strat√©gies** :

**Option A : Calcul Post-Sync en Batch Ordonn√©** ‚≠ê RECOMMAND√â
- D√©sactiver pendant la sync (`compute_performance_scores=False`)
- Apr√®s insertion de tous les matchs, faire **UNE passe unique** ordonn√©e par `start_time`
- Charger l'historique une seule fois, puis ajouter chaque match au fur et √† mesure
```python
# Pseudo-code
history_df = load_all_matches(order_by="start_time ASC")
for match in new_matches_ordered:
    score = compute_score(match, history_df)
    update_score(match.id, score)
    history_df.append(match)  # Ajouter au contexte pour le suivant
```

**Option B : Cache In-Memory de l'Historique**
- Charger l'historique **une fois** au d√©but du sync
- Pour chaque nouveau match, calculer avec le cache + matchs d√©j√† ins√©r√©s
- √âvite les N requ√™tes SELECT sur la DB

**Option C : Sortir du Lock DB**
- Calculer le score **avant** l'acquisition du lock
- L'historique est stable √† ce moment (matchs d√©j√† en DB)
- R√©duire la dur√©e de la section critique

**Impl√©mentation** :
```python
# SyncOptions
compute_performance_scores: bool = False  # D√©sactiv√© par d√©faut

# Apr√®s sync
engine._batch_compute_performance_scores()  # Passe unique ordonn√©e
```

**Gain estim√©** : **-3-5s** par match si > 200 matchs historiques  
**Complexit√©** : Moyenne (refactoring de `_compute_and_update_performance_score`)

---

### **Phase 2 : Optimisations Structurelles** üèóÔ∏è

#### 2.1 Batching des Insertions DB
**Objectif** : R√©duire les I/O et permettre commits group√©s

**Modifications** :
- Accumuler les rows dans des buffers (par type : match, medals, events, etc.)
- Commit toutes les 10-20 matchs au lieu de chaque match
- Utiliser les fonctions `batch_insert_rows` existantes dans [src/data/sync/batch_insert.py](src/data/sync/batch_insert.py)

**Fichiers** : [src/data/sync/engine.py](src/data/sync/engine.py#L739-L780)

**Gain estim√©** : **-30%** des I/O (1-2s ‚Üí 0.5-1s par match)

---

#### 2.2 Lock Granulaire ou Queue d'√âcriture
**Objectif** : Permettre la parall√©lisation r√©elle des matchs

**Options** :
- **Option A** : Remplacer `self._db_lock` par une queue d'√©criture (1 writer thread/task)
- **Option B** : DuckDB multi-connexion (1 writer + N readers)
- **Option C** : Batching + lock uniquement sur le commit final

**Complexit√©** : Moyenne (refactoring async)

**Gain estim√©** : **+50%** de throughput avec `parallel_matches=5-10`

---

#### 2.3 Augmenter le Rate Limit
**Objectif** : Exploiter pleinement la bande passante API

**Tests recommand√©s** :
```python
# Tester progressivement
requests_per_second: int = 10  # Au lieu de 5
parallel_matches: int = 5      # Au lieu de 3
```

**Validation** : Surveiller les erreurs 429 (Too Many Requests)

**Gain estim√©** : **+50-100%** de throughput global

---

### **Phase 3 : Optimisations Avanc√©es** ‚ö°

#### 3.1 Cache Metadata In-Memory
**Constat** : Le `metadata_resolver` est recr√©√© pour chaque match
**Solution** : Cache LRU des r√©solutions (maps, modes, m√©dailles)

#### 3.2 Prefetch Match History
**Id√©e** : D√©marrer le fetch du batch suivant pendant le traitement du batch courant

#### 3.3 Worker Pool pour Transformations
**Strat√©gie** : Parall√©liser les transformations CPU-bound (Polars, extractions JSON)

---

## üìä Estimation des Gains Cumul√©s

| Phase | Temps/match actuel | Apr√®s optimisation | Gain |
|-------|-------------------|-------------------|------|
| **Baseline (actuel)** | 16s | - | - |
| **+ Phase 1.1 (API parall√®le)** | 16s | **6-8s** | 50-60% |
| **+ Phase 1.2 (scores diff√©r√©s)** | 6-8s | **2-4s** | 60-70% |
| **+ Phase 2.1 (batching DB)** | 2-4s | **1.5-3s** | 25-30% |
| **+ Phase 2.3 (rate limit)** | 1.5-3s | **1-2s** | 30-50% |

**Objectif final** : **‚â§2s par match** (8x plus rapide)

---

## üõ†Ô∏è Impl√©mentation Recommand√©e

### √âtape 1 : Parall√©lisation API (Impact Imm√©diat)
1. Modifier `_process_single_match` pour utiliser `asyncio.gather`
2. Tester sur un petit dataset (10 matchs)
3. Valider avec `python scripts/sync.py --delta --player JGtm`

### √âtape 2 : Scores de Performance (Optionnel)
1. Ajouter option `compute_performance_scores` √† `SyncOptions`
2. D√©sactiver par d√©faut
3. Cr√©er commande d√©di√©e `--compute-scores`

### √âtape 3 : Batching DB (Optimisation suivante)
1. Introduire buffers d'accumulation
2. Commit toutes les 10 matchs
3. Benchmarker avant/apr√®s

---

## üî¨ M√©triques √† Surveiller

### Avant chaque modification
```bash
# Benchmark baseline
python scripts/sync.py --delta --player JGtm
# Noter : temps total, temps/match, logs SQL
```

### Apr√®s chaque modification
```bash
# Re-benchmark
python scripts/sync.py --delta --player TestPlayer --max-matches 20
# Comparer : temps/match, taux d'erreur, coh√©rence donn√©es
```

### Outils
- `scripts/benchmark_pages.py` (s'il existe)
- Logs de temps dans le terminal
- DuckDB query profiling : `PRAGMA enable_profiling;`

---

## ‚ö†Ô∏è Points de Vigilance

1. **Ordre des op√©rations** : S'assurer que le calcul du score de performance a bien acc√®s √† l'historique complet
2. **Transactions DB** : V√©rifier que les rollbacks sont possibles en cas d'erreur
3. **Rate limiting API** : Tester prudemment les augmentations (risque de ban)
4. **Compatibilit√©** : Tester avec les 4 DB joueurs (JGtm, Madina97294, Chocoboflor, XxDaemonGamerxX)
5. **Tests de r√©gression** : Lancer `pytest tests/test_data_architecture.py` apr√®s chaque modif

---

## üìù Checklist de Validation

- [ ] Temps/match r√©duit √† ‚â§3s en delta
- [ ] Aucune r√©gression sur les donn√©es (medals, events, skill)
- [ ] Tests passent (`pytest --ignore=tests/integration`)
- [ ] Logs clairs et exploitables
- [ ] Documentation mise √† jour (SYNC_GUIDE.md)

---

**Prochaine √©tape sugg√©r√©e** : Impl√©menter Phase 1.1 (parall√©lisation API) en priorit√©.

---

## üö® NOTES IMPORTANTES

### D√©pendance S√©quentielle des Scores
Le calcul du score de performance **n'est PAS parall√©lisable** car chaque match d√©pend de l'historique pr√©c√©dent :
- Match N+1 n√©cessite les scores/stats des matchs 1..N
- Le calcul doit respecter l'ordre chronologique strict

**Implications** :
1. ‚ùå **INTERDIT** : Recalculer tous les scores en parall√®le
2. ‚úÖ **AUTORIS√â** : Batch post-sync en ordre chronologique
3. ‚úÖ **OPTIMAL** : Cache in-memory de l'historique pendant la sync
