# Super Plan Consolid√© ‚Äî LevelUp v4.1

> **Date** : 2026-02-09
> **Statut** : Plan consolid√© ‚Äî aucune modification de code
> **Sources** : 7 documents de planification compil√©s apr√®s analyse du projet

---

## Table des mati√®res

1. [Synth√®se des plans](#1-synth√®se-des-plans)
2. [Analyse des d√©pendances](#2-analyse-des-d√©pendances)
3. [Graphe de d√©pendances](#3-graphe-de-d√©pendances)
4. [√âtat des tests existants](#4-√©tat-des-tests-existants)
5. [Sprints](#5-sprints)
6. [R√©capitulatif des fichiers impact√©s](#6-r√©capitulatif-des-fichiers-impact√©s)
7. [Matrice de risques](#7-matrice-de-risques)
8. [Crit√®res de livraison](#8-crit√®res-de-livraison)
9. [M√©triques de succ√®s](#9-m√©triques-de-succ√®s)
10. [Prochaines √©tapes imm√©diates](#10-prochaines-√©tapes-imm√©diates)

---

## 1. Synth√®se des plans

| # | Plan | Source | Priorit√© | Complexit√© |
|---|------|--------|----------|------------|
| **P1** | Correction bug "Derni√®re session" | `DERNIERE_SESSION_BOUTON_BUG_ANALYSIS.md` | üî¥ Urgente (bug visible) | Faible |
| **P2** | Refactoring backfill_data.py | `BACKFILL_SCRIPT_REVIEW.md` | üî¥ Critique (donn√©es non persist√©es) | Haute |
| **P3** | Damage participants (match_participants) | `PARTICIPANTS_DAMAGE_PLAN.md` | üü† Haute (pr√©requis P5, P6) | Moyenne |
| **P4** | M√©dianes + renommage Frags + normalisation modes + M√©dias + Co√©quipiers | `DISTRIBUTIONS_MEDIAN_PLAN.md` | üü° Moyenne | Moyenne |
| **P5** | Score de performance v4 | `PERFORMANCE_SCORE_V4_PLAN.md` | üü° Moyenne | Haute |
| **P6** | Nouvelles visualisations statistiques | `PLAN_DETAIL_STATS_NOUVELLES.md` | üü¢ Normale | Tr√®s haute |
| **P7** | Section Carri√®re (progression H√©ros) | `CAREER_PROGRESS_HERO_PLAN.md` | üü¢ Normale (autonome) | Moyenne |
| **P8** | Persistance filtres par joueur / DB | `ANALYSE_PERSISTANCE_FILTRES_MULTI_JOUEURS.md` | üî¥ Urgente (bug UX) | Faible |

---

## 2. Analyse des d√©pendances

### 2.1 D√©pendances critiques identifi√©es

```
P2 (Backfill refactoring) ‚îÄ‚îÄ‚ñ∫ P3 (Participants damage)
       ‚îÇ                           ‚îÇ
       ‚îÇ                           ‚ñº
       ‚îÇ                      P5 (Perf Score v4)
       ‚îÇ                           ‚îÇ
       ‚ñº                           ‚ñº
  P3 utilise backfill         P6 (Nouvelles stats)
  pour --participants-damage  utilise damage_dealt, personal_score, rank
```

**D√©tail des d√©pendances** :

| Bloc | D√©pend de | Raison |
|------|-----------|--------|
| **P1** (Bug session) | Rien | Bug autonome, corrigeable imm√©diatement |
| **P2** (Backfill) | Rien | Infrastructure de base, pr√©requis pour tout backfill fiable |
| **P3** (Damage participants) | **P2** (partiel) | Ajoute `--participants-damage` au backfill ; le commit final (P2-A) doit √™tre fiable |
| **P4** (M√©dianes, Frags, etc.) | Rien | Touches UI ind√©pendantes des donn√©es backfill |
| **P5** (Perf Score v4) | **P2** (Pandas‚ÜíPolars), **P3** (damage_dealt dans history) | La v4 utilise `personal_score`, `damage_dealt`, `rank`, `team_mmr`, `enemy_mmr` ‚Äî colonnes d√©j√† en `match_stats` mais le calcul dans le backfill utilise Pandas (√† migrer P2). Le DPM damage n√©cessite que le champ soit rempli. |
| **P6** (Nouvelles stats) | **P3** (damage participants pour comparaison co√©quipiers), **P5** (score v4 pour distributions) | Les graphes de d√©g√¢ts comparatifs (co√©quipiers) n√©cessitent damage_dealt/taken dans `match_participants`. Le graphe "Distribution score de performance" utilise le score v4. |
| **P7** (Carri√®re H√©ros) | Rien | Section autonome (career_progression existe d√©j√† en BDD) |
| **P8** (Persistance filtres) | Rien | Bug UX autonome : nettoyage session_state au changement de joueur |

### 2.2 Conflits de fichiers identifi√©s

Plusieurs plans touchent les m√™mes fichiers. Ordre d'ex√©cution critique :

| Fichier | Plans concern√©s | Risque de conflit |
|---------|----------------|-------------------|
| `scripts/backfill_data.py` | P2, P3, P5 | üî¥ √âlev√© ‚Äî Refactoring P2 avant ajouts P3/P5 |
| `src/analysis/performance_score.py` | P2 (Pandas‚ÜíPolars), P5 (v4) | üî¥ √âlev√© ‚Äî Migration Pandas d'abord, puis v4 |
| `src/analysis/performance_config.py` | P5 | üü¢ Faible |
| `src/ui/pages/teammates.py` | P4, P6 | üü† Moyen ‚Äî P4 (Stats/min barres, radar participation, frags parfaits) puis P6 (nouvelles sections) |
| `src/ui/pages/timeseries.py` | P4, P6 | üü† Moyen ‚Äî P4 (m√©dianes, renommage) puis P6 (nouvelles sections) |
| `src/ui/pages/win_loss.py` | P4 (normalisation modes), P6 (personal score, streaks) | üü° Faible ‚Äî Sections diff√©rentes |
| `src/visualization/distributions.py` | P4 (m√©diane), P6 (nouveaux graphes) | üü° Faible ‚Äî Ajouts ind√©pendants |
| `src/data/sync/models.py` | P3 | üü¢ Faible |
| `src/data/sync/transformers.py` | P3 | üü¢ Faible |
| `src/data/sync/engine.py` | P3, P5 | üü° Faible ‚Äî Sections diff√©rentes |
| `src/ui/pages/media_tab.py` | P4 | üü¢ Faible |
| `src/ui/pages/teammates_charts.py` | P4, P6 | üü† Moyen ‚Äî P4 (frags parfaits) puis P6 (nouvelles comparaisons) |
| `src/app/filters_render.py` | P1, P8 | üü† Moyen ‚Äî P1 (tri session) puis P8 (sauvegarde/nettoyage) |
| `streamlit_app.py` | P8 | üü¢ Faible |
| `src/ui/filter_state.py` | P8 | üü¢ Faible |

### 2.3 Dette technique √† r√©soudre en pr√©requis

**Constat apr√®s analyse du code** :

1. **`performance_score.py`** (L.8-9) : `import pandas as pd` + `import polars as pl` ‚Äî violation r√®gle CLAUDE.md. Fonctions `_percentile_rank`, `_prepare_history_metrics`, `compute_relative_performance_score` utilisent toutes `pd.Series` / `pd.DataFrame`.
2. **`backfill_data.py`** (L.119) : `import pandas as pd` ‚Äî violation r√®gle. `_compute_performance_score` (L.698) cr√©e un `pd.Series`.
3. **`test_performance_score.py`** (L.3) : `import pandas as pd` ‚Äî les tests utilisent Pandas. Il faudra les migrer en parall√®le.
4. **`test_visualizations.py`** (L.18, 32) : `import pandas as pd`, fixtures en Pandas ‚Äî acceptable car fronti√®re Plotly (CLAUDE.md autorise `.to_pandas()` √† la fronti√®re).

---

## 3. Graphe de d√©pendances (ordre d'ex√©cution)

```
Semaine 1 (Sprint 0 + 1)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P1 (Bug session)          ‚îÄ‚îÄ‚îÄ Autonome, imm√©diat
  P2-A (Commit final)       ‚îÄ‚îÄ‚îÄ D√©j√† fait (‚úÖ)
  P2-B (Pandas ‚Üí Polars     ‚îÄ‚îÄ‚îÄ Pr√©requis P5
        dans perf_score.py
        et backfill_data.py)
  P2-C (Logs exceptions)    ‚îÄ‚îÄ‚îÄ Am√©lioration backfill

Semaine 2 (Sprint 2)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P3 (Damage participants)  ‚îÄ‚îÄ‚îÄ Pr√©requis P5 DPM, P6 comparaisons
  P7 (Carri√®re H√©ros)       ‚îÄ‚îÄ‚îÄ Autonome, parall√©lisable

Semaine 3 (Sprint 3)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P4 (M√©dianes, Frags,      ‚îÄ‚îÄ‚îÄ Autonome sur UI
      modes, M√©dias,
      Co√©quipiers refonte)

Semaine 4 (Sprint 4)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P5 (Perf Score v4)        ‚îÄ‚îÄ‚îÄ D√©pend de P2-B, P3

Semaines 5-7 (Sprints 5-7)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P6 (Nouvelles stats)      ‚îÄ‚îÄ‚îÄ D√©pend de P3, P5 (partiellement)
    Phase 1 : Timeseries
    Phase 2 : Victoires/D√©faites
    Phase 3 : Dernier match
    Phase 4 : Mes co√©quipiers

Semaine 8 (Sprint 8)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  P2-D (Refactoring          ‚îÄ‚îÄ‚îÄ D√©coupage fichier, table backfill_status
        structurel backfill)
```

---

## 4. √âtat des tests existants

### 4.1 Tests actuels (65 fichiers)

| Domaine | Fichiers de test | Couverture |
|---------|-----------------|------------|
| Performance score | `test_performance_score.py` (7 tests v2), `test_sync_performance_score.py` (7 tests), `test_backfill_performance_score.py` (8 tests), `test_timeseries_performance_score.py` | ‚úÖ Bonne pour v3 |
| Visualisations | `test_visualizations.py` (~60 tests : distributions, timeseries, radar, barres, etc.) | ‚úÖ Bonne |
| Sessions | `test_sessions_advanced.py`, `test_sessions_teammates.py`, `test_session_compare_hist_avg_category.py` | ‚úÖ Moyenne |
| Sync/Engine | `test_sync_engine.py`, `test_sync_cli_integration.py`, `test_sync_ui.py` | ‚úÖ Moyenne |
| Mod√®les | `test_models.py`, `test_parsers.py`, `test_transformers_*.py` | ‚úÖ Bonne |
| DuckDB | `test_duckdb_repository.py`, `test_duckdb_repo_regressions.py`, `test_connection_duckdb.py` | ‚úÖ Bonne |
| M√©dias | `test_media_*.py` (4 fichiers) | ‚úÖ Moyenne |
| Participation | `test_participation_radar.py`, `test_objective_participation.py` | ‚úÖ Moyenne |
| Polars migration | `test_polars_migration.py` | ‚úÖ Sp√©cifique |
| Killer/Victim | `test_killer_victim_*.py` (2 fichiers) | ‚úÖ Bonne |

### 4.2 Tests √† cr√©er ou modifier par plan

| Plan | Tests √† cr√©er | Tests √† modifier |
|------|---------------|------------------|
| **P1** | `test_session_last_button.py` (tri par max(start_time)) | ‚Äî |
| **P8** | √âtendre `test_filter_state.py` ou `scripts/test_filter_persistence_by_player.py` (nettoyage cl√©s, A‚ÜíB‚ÜíA) | ‚Äî |
| **P2** | `test_perf_score_polars_only.py` (v√©rifier que Pandas n'est plus requis) | `test_performance_score.py` (migrer fixtures Pandas‚ÜíPolars), `test_backfill_performance_score.py` (idem) |
| **P3** | `test_participants_damage.py` (extraction, insertion, backfill) | `test_models.py` (MatchParticipantRow avec damage) |
| **P4** | `test_distributions_median.py` (m√©diane sur 6 graphes), `test_mode_normalization.py` (graphe "Par mode") | `test_visualizations.py` (plot_histogram show_median, plot_kda_distribution m√©diane, plot_first_event m√©dianes) |
| **P5** | `test_performance_score_v4.py` (PSPM, DPM, rank_perf, graceful degradation) | `test_sync_performance_score.py` (nouvelles colonnes history), `test_backfill_performance_score.py` |
| **P6** | `test_win_streaks.py`, `test_new_visualizations.py` (personal score, correlations, damage distributions, shots accuracy) | `test_visualizations.py` (nouvelles fonctions) |
| **P7** | `test_career_progress_circle.py` (compute_percent, xp_remaining, format_xp, rang 272, fallback) | ‚Äî |

---

## 5. Sprints

### Sprint 0 ‚Äî Bug Fix Urgent (¬Ω jour)

**Objectif** : Corriger le bug visible pour les utilisateurs

| # | T√¢che | Fichier(s) | Tests |
|---|-------|-----------|-------|
| 0.1 | Corriger le tri du bouton "Derni√®re session" : remplacer le tri par `session_id` d√©croissant par `max(start_time)` par session (P1, ¬ß3.3) | `src/app/filters_render.py` : `_session_labels_ordered_by_last_match()` | Cr√©er `tests/test_session_last_button.py` |
| 0.2 | Appliquer la m√™me logique dans `filters.py` (si logique dupliqu√©e) | `src/app/filters.py` | Idem |
| 0.3 | Documenter le workaround pour la d√©tection OR/AND dans backfill sans refonte imm√©diate. Ajouter exemples dans docstring et `.ai/BACKFILL_SCRIPT_REVIEW.md` | `.ai/BACKFILL_SCRIPT_REVIEW.md`, `scripts/backfill_data.py` (docstring) | ‚Äî |

> **Workaround OR document√©** : Au lieu de `--all-data`, recommander l'ex√©cution par √©tapes :
> ```bash
> python scripts/backfill_data.py --all --medals --events --skill
> python scripts/backfill_data.py --all --performance-scores --sessions
> ```

**Gate de livraison** :
- [ ] `pytest tests/test_session_last_button.py -v` passe
- [ ] `pytest tests/ -v` (suite compl√®te) passe sans r√©gression
- [ ] Test manuel : cliquer "Derni√®re session" pour JGtm ‚Üí session la plus r√©cente s√©lectionn√©e

**Commandes de validation** :
```bash
pytest tests/test_session_last_button.py -v
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier bouton "Derni√®re session"
```

**Livrables** :
- Code corrig√© dans `src/app/filters_render.py` et `src/app/filters.py`
- Nouveau fichier `tests/test_session_last_button.py`
- Mise √† jour `.ai/BACKFILL_SCRIPT_REVIEW.md` (workaround OR document√©)
- Mise √† jour `.ai/thought_log.md`

---

### Sprint 0bis ‚Äî Persistance filtres multi-joueurs (P8) (¬Ω‚Äì1 jour)

**Objectif** : R√©tablir la conservation des filtres (s√©lectionn√©s/d√©s√©lectionn√©s) par joueur malgr√© les changements de DB. Source : `ANALYSE_PERSISTANCE_FILTRES_MULTI_JOUEURS.md`.

**Pr√©requis** : Aucun (parall√©lisable avec Sprint 0)

| # | T√¢che | Source | Fichier(s) | Tests |
|---|-------|--------|-----------|-------|
| 0bis.1 | Nettoyage exhaustif au changement de joueur : supprimer toutes les cl√©s dont le nom **commence par** `filter_playlists_`, `filter_modes_`, `filter_maps_` (widgets checkboxes) | P8 ¬ß5.1 | `streamlit_app.py` (bloc changement de joueur) | ‚Äî |
| 0bis.2 | Ajouter au nettoyage les cl√©s manquantes : `gap_minutes`, `_latest_session_label`, `_trio_latest_session_label`, `min_matches_maps`, `_min_matches_maps_auto`, `min_matches_maps_friends`, `_min_matches_maps_friends_auto` | P8 ¬ß5.1 | `streamlit_app.py` | ‚Äî |
| 0bis.3 | Centraliser la liste des cl√©s et pr√©fixes dans un module (ex. `src/ui/filter_state.py` ou `src/app/filter_keys.py`) : `FILTER_DATA_KEYS`, `FILTER_WIDGET_KEY_PREFIXES`, fonction `get_all_filter_keys_to_clear(session_state)` | P8 ¬ß5.2 | `src/ui/filter_state.py` ou nouveau `src/app/filter_keys.py`, `streamlit_app.py` | ‚Äî |
| 0bis.4 | Tests : sc√©nario A‚ÜíB‚ÜíA (isolation), coh√©rence checkboxes apr√®s switch, extension de `test_filter_state.py` ou `scripts/test_filter_persistence_by_player.py` | P8 ¬ß5.6 | `tests/test_filter_state.py` ou script existant | Cr√©er/√©tendre tests |

**Gate de livraison** :
- [ ] Apr√®s changement de joueur, aucune cl√© `session_state` ne commence par `filter_playlists_`, `filter_modes_`, `filter_maps_`
- [ ] Test manuel : joueur A (filtres X) ‚Üí joueur B (filtres Y) ‚Üí retour A ‚Üí les filtres de A sont identiques √† X
- [ ] `pytest tests/test_filter_state.py -v` passe (et nouveaux tests persistance multi-joueurs si ajout√©s)

**Commandes de validation** :
```bash
pytest tests/test_filter_state.py -v
streamlit run streamlit_app.py  # Switch A ‚Üí B ‚Üí A, v√©rifier filtres conserv√©s
```

**Livrables** :
- Code : `streamlit_app.py` (nettoyage exhaustif), `src/ui/filter_state.py` ou `src/app/filter_keys.py` (centralisation)
- Tests : extension tests persistance filtres
- Mise √† jour `docs/FILTER_PERSISTANCE.md` et `.ai/thought_log.md`

**Optionnel (phases ult√©rieures P8)** : Scopage des cl√©s des widgets par joueur (`checkbox_filter.py`) ; garde sur la sauvegarde automatique ; √©viter double chargement. Voir `.ai/ANALYSE_PERSISTANCE_FILTRES_MULTI_JOUEURS.md` ¬ß5.3‚Äì5.5.

---

### Sprint 1 ‚Äî Assainissement backfill & migration Pandas‚ÜíPolars (2 jours)

**Objectif** : Rendre le backfill fiable et conforme aux r√®gles du projet (Pandas interdit)

**Pr√©requis** : Sprint 0 livr√©

| # | T√¢che | Source | Fichier(s) | Tests |
|---|-------|--------|-----------|-------|
| 1.1 | Migrer `_percentile_rank()` et `_percentile_rank_inverse()` de `pd.Series` vers `pl.Series` (ou `np.ndarray`) | P2 ¬ß1 | `src/analysis/performance_score.py` L.50-77 | Modifier `tests/test_performance_score.py` (fixtures Polars) |
| 1.2 | Migrer `_prepare_history_metrics()` de `pd.DataFrame` vers `pl.DataFrame` | P2 ¬ß1 | `src/analysis/performance_score.py` L.80-135 | Idem |
| 1.3 | Migrer `compute_relative_performance_score()` : accepter `row: dict \| pl.Series`, `df_history: pl.DataFrame` ; supprimer `_normalize_df` | P2 ¬ß1 | `src/analysis/performance_score.py` L.138+ | Modifier `tests/test_sync_performance_score.py`, `tests/test_backfill_performance_score.py` |
| 1.4 | Supprimer `import pandas as pd` de `performance_score.py` | P2 ¬ß1 | `src/analysis/performance_score.py` L.8 | `test_polars_migration.py` (v√©rifier aucun import pandas) |
| 1.5 | Refactorer `_compute_performance_score()` dans backfill pour utiliser un dict au lieu de `pd.Series` ; supprimer `import pandas as pd` | P2 ¬ß1 | `scripts/backfill_data.py` L.119, 670-720 | `tests/test_backfill_performance_score.py` |
| 1.6 | Ajouter `logger.debug()`/`logger.warning()` aux 9 blocs `except Exception: pass` | P2 ¬ß2 | `scripts/backfill_data.py` L.347, 413, 450, 678, 834, 908, 930, 951, 976 | Test manuel (v√©rifier logs) |
| 1.7 | Cr√©er helper `_create_empty_result()` pour √©liminer les 7 dict dupliqu√©s | P2 ¬ß9 | `scripts/backfill_data.py` L.1153+ | ‚Äî |
| 1.8 | Remplacer `logger.info("[DEBUG]...")` par `logger.debug(...)` | P2 ¬ß7 | `scripts/backfill_data.py` L.481-531 | ‚Äî |

**Gate de livraison** :
- [ ] `pytest tests/test_performance_score.py -v` passe (avec fixtures Polars)
- [ ] `pytest tests/test_sync_performance_score.py -v` passe
- [ ] `pytest tests/test_backfill_performance_score.py -v` passe
- [ ] `grep -r "import pandas" src/analysis/performance_score.py` ‚Üí aucun r√©sultat
- [ ] `grep -r "import pandas" scripts/backfill_data.py` ‚Üí aucun r√©sultat
- [ ] `pytest tests/ -v` (suite compl√®te) passe sans r√©gression

**Commandes de validation** :
```bash
pytest tests/test_performance_score.py tests/test_sync_performance_score.py tests/test_backfill_performance_score.py -v
grep -r "import pandas" src/analysis/performance_score.py scripts/backfill_data.py
pytest tests/ -v
python scripts/backfill_data.py --player TestPlayer --medals --dry-run
```

**Livrables** :
- Code migr√© Polars dans `src/analysis/performance_score.py` et `scripts/backfill_data.py`
- Tests migr√©s dans `tests/test_performance_score.py`, `tests/test_sync_performance_score.py`, `tests/test_backfill_performance_score.py`
- Mise √† jour `.ai/thought_log.md`
- Mise √† jour `.ai/BACKFILL_SCRIPT_REVIEW.md` (statut des correctifs)

---

### Sprint 2 ‚Äî Damage participants + Carri√®re H√©ros (2.5 jours)

**Objectif** : Ajouter les donn√©es damage aux participants (pr√©requis P5/P6) + section Carri√®re autonome

**Pr√©requis** : Sprint 1 livr√© (backfill fiable)

#### 2A ‚Äî Damage participants (P3)

| # | T√¢che | Source | Fichier(s) |
|---|-------|--------|-----------|
| 2A.1 | Ajouter `damage_dealt: float \| None`, `damage_taken: float \| None` √† `MatchParticipantRow` | P3 ¬ß1 | `src/data/sync/models.py` L.302+ |
| 2A.2 | Extraire `DamageDealt`/`DamageTaken` dans `extract_participants()` | P3 ¬ß2 | `src/data/sync/transformers.py` L.1162+ |
| 2A.3 | Ajouter colonnes `damage_dealt FLOAT, damage_taken FLOAT` au DDL `match_participants` | P3 ¬ß3.1 | `src/data/sync/engine.py` L.146+ |
| 2A.4 | Ajouter migration colonnes dans `_ensure_match_participants_rank_score()` | P3 ¬ß3.2 | `src/data/sync/engine.py` L.425+ |
| 2A.5 | Ajouter `damage_dealt`, `damage_taken` dans `_insert_participant_rows()` (engine) | P3 ¬ß4 | `src/data/sync/engine.py` L.1101+ |
| 2A.6 | Ajouter `_ensure_match_participants_columns()` dans backfill pour damage | P3 ¬ß5.1 | `scripts/backfill_data.py` L.295+ |
| 2A.7 | Ajouter `_insert_participant_rows()` dans backfill pour damage | P3 ¬ß5.2 | `scripts/backfill_data.py` L.321+ |
| 2A.8 | Ajouter option `--participants-damage` et `--force-participants-damage` au CLI | P3 ¬ß5.6 | `scripts/backfill_data.py` (main, arguments) |
| 2A.9 | Ajouter `participants_damage = True` dans le bloc `if all_data:` | P3 ¬ß5.4 | `scripts/backfill_data.py` L.1080+ |
| 2A.10 | Ajouter param√®tres et logique dans `backfill_player_data()`, `backfill_all_players()`, `_find_matches_missing_data()` | P3 ¬ß5.3-5.5 | `scripts/backfill_data.py` |

**Tests Sprint 2A** :
- Cr√©er `tests/test_participants_damage.py` :
  - Test extraction `extract_participants()` retourne damage_dealt/taken
  - Test insertion avec colonnes damage
  - Test migration colonnes (DB existante sans damage ‚Üí ALTER TABLE)
  - Test backfill `--participants-damage`
- Modifier `tests/test_models.py` : validation MatchParticipantRow avec damage

#### 2B ‚Äî Section Carri√®re (P7)

| # | T√¢che | Source | Fichier(s) |
|---|-------|--------|-----------|
| 2B.1 | Cr√©er `src/ui/components/career_progress_circle.py` : constantes `XP_HERO_TOTAL = 9_319_350`, `RANK_MAX = 272` | P7 ¬ßS1.1 | Nouveau fichier |
| 2B.2 | Impl√©menter `compute_career_progress_percent()` (approche B : par XP, fallback par rang) | P7 ¬ßS1.2 | `career_progress_circle.py` |
| 2B.3 | Impl√©menter `compute_xp_remaining()`, `format_xp_number()` | P7 ¬ßS1.3-S1.4 | `career_progress_circle.py` |
| 2B.4 | Impl√©menter `render_career_progress_circle()` (Plotly gauge) | P7 ¬ßS1.5 | `career_progress_circle.py` |
| 2B.5 | Cr√©er ou compl√©ter le helper de chargement donn√©es carri√®re (BDD puis API) | P7 ¬ßS2.1-S2.4 | `src/app/career_section.py` (nouveau) ou helper existant |
| 2B.6 | Impl√©menter `render_career_section()` : rang√©e 5 cases (XP gagn√©e, XP restante, Total requis, Rang/272, Cercle) | P7 ¬ßS3 | `career_section.py` |
| 2B.7 | Int√©grer dans la partie Carri√®re de l'app | P7 ¬ßS4 | `streamlit_app.py` ou page d√©di√©e |

**Tests Sprint 2B** :
- Cr√©er `tests/test_career_progress_circle.py` :
  - Test rang 1 ‚Üí ~0 %
  - Test rang 135 ‚Üí ~50 % (approx)
  - Test rang 272 ‚Üí 100 %, xp_remaining = 0
  - Test sans donn√©es ‚Üí fallback ou message
  - Test format_xp_number (9319350 ‚Üí "9 319 350")
  - Test compute_xp_remaining (max(0, ...))

**Gate de livraison** :
- [ ] `pytest tests/test_participants_damage.py -v` passe
- [ ] `pytest tests/test_career_progress_circle.py -v` passe
- [ ] `pytest tests/test_models.py -v` passe (avec champs damage)
- [ ] `pytest tests/ -v` passe sans r√©gression
- [ ] Test d'int√©gration backfill : `python scripts/backfill_data.py --player JGtm --participants-damage --dry-run`

**Commandes de validation** :
```bash
pytest tests/test_participants_damage.py tests/test_career_progress_circle.py tests/test_models.py -v
python scripts/backfill_data.py --player TestPlayer --participants-damage --dry-run
python scripts/backfill_data.py --player TestPlayer --participants-damage --max-matches 10
python scripts/backfill_data.py --player TestPlayer --all-data --max-matches 5
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier section Carri√®re
```

**Livrables** :
- Code participants damage : `src/data/sync/models.py`, `transformers.py`, `engine.py`, `scripts/backfill_data.py`
- Code section Carri√®re : `src/ui/components/career_progress_circle.py`, `src/app/career_section.py`
- Tests : `tests/test_participants_damage.py`, `tests/test_career_progress_circle.py`
- Mise √† jour `.ai/thought_log.md`
- Mise √† jour `.ai/features/PARTICIPANTS_DAMAGE_PLAN.md` (statut : Impl√©ment√©)
- Mise √† jour `.ai/features/CAREER_PROGRESS_HERO_PLAN.md` (statut : Impl√©ment√©)

---

### Sprint 3 ‚Äî M√©dianes, Frags, Modes, M√©dias, Co√©quipiers refonte (3 jours)

**Objectif** : Am√©liorations UI (P4 complet)

**Pr√©requis** : Sprint 0 livr√© (pour filters). Pas de d√©pendance sur Sprint 1-2.

**Note** : Ce sprint est parall√©lisable avec Sprint 2 si 2 d√©veloppeurs.

#### 3A ‚Äî M√©dianes sur distributions (P4 ¬ß1-4)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 3A.1 | Ajouter param `show_median: bool = True` √† `plot_histogram()` ; si True : `fig.add_vline(x=median)` + annotation | `src/visualization/distributions.py` L.547+ |
| 3A.2 | Ajouter m√©diane √† `plot_kda_distribution()` : `np.median(x)` + vline + annotation | `src/visualization/distributions.py` L.28+ |
| 3A.3 | Ajouter m√©dianes √† `plot_first_event_distribution()` : 2 vlines (kill + mort), style diff√©rent des moyennes | `src/visualization/distributions.py` L.1135+ |

#### 3B ‚Äî Renommage "Kills" ‚Üí "Frags" (P4 ¬ß2.3)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 3B.1 | Remplacer titre "Distribution des Kills" ‚Üí "Distribution des frags" | `src/ui/pages/timeseries.py` |
| 3B.2 | Remplacer `x_label="Kills"` ‚Üí `x_label="Frags"` | `src/ui/pages/timeseries.py` |
| 3B.3 | Adapter messages `st.info` (donn√©es de frags) | `src/ui/pages/timeseries.py` |

#### 3C ‚Äî Normalisation noms de mode (P4 ¬ß5)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 3C.1 | Pour le graphe "Par mode" (Victoires/d√©faites) : appliquer `normalize_mode_label_fn` aux labels | `src/ui/pages/win_loss.py` L.137-149 |
| 3C.2 | Si n√©cessaire : passer `normalize_mode_label_fn` via `render_win_loss_page` depuis le routeur | `src/app/page_router.py`, `src/ui/pages/win_loss.py` |

#### 3D ‚Äî Onglet M√©dias (P4 ¬ß7)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 3D.1 | Lightbox adapt√© √† la fen√™tre (CSS max-width/max-height) | `src/ui/pages/media_tab.py` L.121-139 |
| 3D.2 | Bouton "Ouvrir le match" en pleine largeur (display:block; width:100%) | `src/ui/pages/media_tab.py` L.98-105 |
| 3D.3 | Message "Aucune capture d√©tect√©e" si `mine.is_empty()` | `src/ui/pages/media_tab.py` |
| 3D.4 | √âtudier et impl√©menter clic thumbnail ‚Üí lightbox (option A, B ou C) | `src/ui/pages/media_tab.py`, `src/ui/components/media_thumbnail.py`, `src/ui/components/media_lightbox.py` |

#### 3E ‚Äî Co√©quipiers : Stats/min en barres + Frags parfaits + Radar participation trio (P4 ¬ß8)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 3E.1 | Supprimer le tableau + radar de la section "Stats par minute" (vue trio) ; remplacer par un **graphe en barres group√©es** | `src/ui/pages/teammates.py` L.804-857 |
| 3E.2 | Ajouter graphe "Frags parfaits" apr√®s "Tirs √† la t√™te" dans `render_metric_bar_charts` | `src/ui/pages/teammates_charts.py`, `src/ui/pages/teammates.py` (enrichissement DataFrames avec `perfect_kills` via `DuckDBRepository.count_perfect_kills_by_match`) |
| 3E.3 | Ajouter section "Profil de participation" (radar 6 axes) en vue trio : participation moyenne des 3 joueurs sur les matchs filtr√©s | `src/ui/pages/teammates.py` (nouvelle fonction `_render_trio_participation_radar`) ; r√©utilisation de `create_participation_profile_radar`, `compute_participation_profile` |

**Tests Sprint 3** :
- Modifier `tests/test_visualizations.py` :
  - `test_plot_histogram_with_median` : v√©rifier que la figure a une shape (vline) quand `show_median=True`
  - `test_plot_histogram_without_median` : `show_median=False` ‚Üí pas de vline m√©diane
  - `test_plot_kda_distribution_has_median` : v√©rifier annotation m√©diane
  - `test_plot_first_event_distribution_has_median` : v√©rifier 2 annotations m√©dianes (kill + mort)
- Cr√©er `tests/test_mode_normalization_winloss.py` :
  - V√©rifier que les labels du graphe "Par mode" correspondent √† `normalize_mode_label`
- Cr√©er `tests/test_media_improvements.py` (ou ajouter dans `test_media_tab_sprint5.py`) :
  - Test message "Aucune capture" quand df vide
- Cr√©er `tests/test_teammates_refonte.py` :
  - Test graphe barres group√©es stats/min (3 joueurs √ó 3 m√©triques)
  - Test frags parfaits (colonne ajout√©e)
  - Test radar participation trio (3 profils)

**Gate de livraison** :
- [ ] `pytest tests/test_visualizations.py -v` passe (avec nouveaux tests m√©diane)
- [ ] `pytest tests/test_mode_normalization_winloss.py -v` passe
- [ ] `pytest tests/test_teammates_refonte.py -v` passe
- [ ] `pytest tests/ -v` passe sans r√©gression
- [ ] Test manuel UI : v√©rifier m√©dianes affich√©es, "Frags" au lieu de "Kills", modes normalis√©s, m√©dias, co√©quipiers

**Commandes de validation** :
```bash
pytest tests/test_visualizations.py tests/test_mode_normalization_winloss.py tests/test_teammates_refonte.py tests/test_media_improvements.py -v
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier m√©dianes, Frags, modes, m√©dias, co√©quipiers
```

**Livrables** :
- Code distributions/m√©diane : `src/visualization/distributions.py`, `src/ui/pages/timeseries.py`
- Code normalisation modes : `src/ui/pages/win_loss.py`
- Code M√©dias : `src/ui/pages/media_tab.py`
- Code Co√©quipiers : `src/ui/pages/teammates.py`, `src/ui/pages/teammates_charts.py`
- Tests : `tests/test_mode_normalization_winloss.py`, `tests/test_teammates_refonte.py`, `tests/test_media_improvements.py`
- Mise √† jour `.ai/thought_log.md`
- Mise √† jour `.ai/features/DISTRIBUTIONS_MEDIAN_PLAN.md` (statut : Impl√©ment√©)

---

### Sprint 4 ‚Äî Score de Performance v4 (2 jours)

**Objectif** : √âvoluer le score de v3 vers v4 avec nouvelles m√©triques

**Pr√©requis** : Sprint 1 (Pandas‚ÜíPolars dans perf_score), Sprint 2A (damage_dealt dans match_participants)

| # | T√¢che | Source | Fichier(s) |
|---|-------|--------|-----------|
| 4.1 | Mettre √† jour `PERFORMANCE_SCORE_VERSION` ‚Üí `"v4-relative"` et `RELATIVE_WEIGHTS` avec 8 m√©triques | P5 ¬ß1 | `src/analysis/performance_config.py` |
| 4.2 | Mettre √† jour `PERFORMANCE_SCORE_FULL_DESC` et `COMPACT_DESC` | P5 ¬ß1 | `src/analysis/performance_config.py` |
| 4.3 | Ajouter calcul `pspm` (Personal Score Per Minute) dans `_prepare_history_metrics()` | P5 ¬ß2.1 | `src/analysis/performance_score.py` |
| 4.4 | Ajouter calcul `dpm_damage` (Damage Per Minute) dans `_prepare_history_metrics()` | P5 ¬ß2.1 | `src/analysis/performance_score.py` |
| 4.5 | Ajouter calcul `rank_perf_diff` (rank performance) dans `_prepare_history_metrics()` | P5 ¬ß2.1 | `src/analysis/performance_score.py` |
| 4.6 | Cr√©er `_compute_rank_performance()` | P5 ¬ß2.3 | `src/analysis/performance_score.py` |
| 4.7 | Modifier `compute_relative_performance_score()` : extraire `personal_score`, `damage_dealt`, `rank`, `team_mmr`, `enemy_mmr` ; calculer percentiles pour PSPM, DPM, rank_perf ; int√©grer dans la moyenne pond√©r√©e | P5 ¬ß2.2 | `src/analysis/performance_score.py` |
| 4.8 | Mettre √† jour la requ√™te historique dans `_compute_and_update_performance_score()` (engine.py) pour inclure `personal_score`, `damage_dealt`, `rank`, `team_mmr`, `enemy_mmr` | P5 ¬ß4 | `src/data/sync/engine.py` L.914+ |
| 4.9 | Mettre √† jour `_compute_performance_score()` dans backfill pour passer les nouvelles colonnes | P5 ¬ß5 | `scripts/backfill_data.py` L.640-720 |
| 4.10 | Cr√©er script `scripts/recompute_performance_scores_duckdb.py` (migration v3‚Üív4) avec `--dry-run`, `--force`, `--player`, `--batch-size` | P5 ¬ß3 | Nouveau script (exception √† la r√®gle "tout dans backfill_data.py" car c'est une migration ponctuelle) |

**Tests Sprint 4** :
- Cr√©er `tests/test_performance_score_v4.py` :
  - Test calcul PSPM avec historique suffisant
  - Test calcul DPM damage avec historique
  - Test calcul Rank Performance avec MMR (delta positif, n√©gatif, nul)
  - Test graceful degradation : personal_score=None ‚Üí PSPM ignor√©, poids renormalis√©s
  - Test graceful degradation : damage_dealt=None ‚Üí DPM ignor√©
  - Test graceful degradation : rank/mmr=None ‚Üí rank_perf ignor√©
  - Test compatibilit√© : donn√©es v3 (sans personal_score etc.) ‚Üí score calcul√© avec m√©triques disponibles
  - Test total des poids = 1.0
- Modifier `tests/test_sync_performance_score.py` : adapter les colonnes history
- Modifier `tests/test_backfill_performance_score.py` : nouvelles colonnes

**Gate de livraison** :
- [ ] `pytest tests/test_performance_score_v4.py -v` passe
- [ ] `pytest tests/test_sync_performance_score.py -v` passe
- [ ] `pytest tests/test_backfill_performance_score.py -v` passe
- [ ] `pytest tests/ -v` passe sans r√©gression
- [ ] Test dry-run migration : `python scripts/recompute_performance_scores_duckdb.py --player JGtm --dry-run`
- [ ] V√©rifier que nouveaux matchs utilisent v4 automatiquement

**Migration des donn√©es existantes (v3 ‚Üí v4)** :

Processus :
1. D√©ployer le code v4
2. `python scripts/recompute_performance_scores_duckdb.py --all --dry-run` (v√©rification)
3. Ex√©cuter le script r√©el pour tous les joueurs
4. V√©rifier statistiques (nombre recalcul√©s, erreurs)

Estimation temps de recalcul :
- 10 joueurs x 1000 matchs : ~20-40 secondes
- 50 joueurs x 2000 matchs : ~2-4 minutes

**Commandes de validation** :
```bash
pytest tests/test_performance_score_v4.py tests/test_sync_performance_score.py tests/test_backfill_performance_score.py -v
python scripts/recompute_performance_scores_duckdb.py --player JGtm --dry-run
python scripts/recompute_performance_scores_duckdb.py --player JGtm
pytest tests/ -v
```

**Livrables** :
- Code v4 : `src/analysis/performance_score.py`, `src/analysis/performance_config.py`
- Script migration : `scripts/recompute_performance_scores_duckdb.py`
- Mises √† jour sync/backfill : `src/data/sync/engine.py`, `scripts/backfill_data.py`
- Tests : `tests/test_performance_score_v4.py`
- Mise √† jour `.ai/thought_log.md`
- Mise √† jour `.ai/features/PERFORMANCE_SCORE_V4_PLAN.md` (statut : Impl√©ment√©)

---

### Sprint 5 ‚Äî Nouvelles stats : Timeseries + Corr√©lations (2 jours)

**Objectif** : Premi√®res nouvelles visualisations (P6 Phase 1-2)

**Pr√©requis** : Sprint 3 (m√©dianes en place), Sprint 2A (damage disponible)

#### 5A ‚Äî Corr√©lations (P6 ¬ß2.1-2.3)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 5A.1 | Ajouter scatter "Dur√©e de vie moyenne vs Morts" color√© par outcome | `src/ui/pages/timeseries.py` (section Corr√©lations) ; r√©utiliser `plot_correlation_scatter()` |
| 5A.2 | Ajouter scatter "Kills vs Deaths" color√© par outcome | Idem |
| 5A.3 | Ajouter scatter "Team MMR vs Enemy MMR" avec ligne y=x | `src/ui/pages/timeseries.py` ; adapter `plot_correlation_scatter()` ou ajouter param `reference_line` |

#### 5B ‚Äî Distributions (P6 ¬ß2.4-2.5)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 5B.1 | Ajouter histogramme "Score personnel par minute" (personal_score / time_played * 60) | `src/ui/pages/timeseries.py` ; r√©utiliser `plot_histogram()` |
| 5B.2 | Ajouter histogramme "Distribution du taux de victoire" (fen√™tre glissante 10 matchs) | `src/ui/pages/timeseries.py` ; cr√©er `plot_win_ratio_distribution()` dans `distributions.py` |

#### 5C ‚Äî Performance cumul√©e am√©lior√©e (P6 ¬ß2.6)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 5C.1 | Ajouter lignes verticales pointill√©es tous les ~8 min dans `plot_cumulative_net_score()` | `src/visualization/performance.py` L.53+ (param `show_match_markers`) |

**Tests Sprint 5** :
- Ajouter dans `tests/test_visualizations.py` :
  - `test_plot_correlation_scatter_with_reference_line`
  - `test_plot_win_ratio_distribution_valid` / `_empty`
- Cr√©er `tests/test_new_timeseries_sections.py` :
  - Test que les nouvelles sections g√®rent les donn√©es vides gracieusement
  - Test que le calcul score_per_minute est correct
  - Test que la fen√™tre glissante win_ratio est correcte

**Gate de livraison** :
- [ ] `pytest tests/test_visualizations.py -v` passe
- [ ] `pytest tests/test_new_timeseries_sections.py -v` passe
- [ ] `pytest tests/ -v` passe sans r√©gression

**Commandes de validation** :
```bash
pytest tests/test_visualizations.py tests/test_new_timeseries_sections.py -v
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier corr√©lations, distributions, performance cumul√©e
```

**Livrables** :
- Code corr√©lations et distributions : `src/ui/pages/timeseries.py`, `src/visualization/distributions.py`, `src/visualization/performance.py`
- Tests : `tests/test_new_timeseries_sections.py`
- Mise √† jour `.ai/thought_log.md`

---

### Sprint 6 ‚Äî Nouvelles stats : Victoires/D√©faites + Dernier match (2 jours)

**Objectif** : P6 Phase 2-3

**Pr√©requis** : Sprint 5 livr√©

#### 6A ‚Äî Page Victoires/D√©faites (P6 ¬ß1)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 6A.1 | Ajouter section "Score personnel par match" (barres color√©es par outcome) | `src/ui/pages/win_loss.py` ; cr√©er `plot_personal_score_by_match()` dans `distributions.py` |
| 6A.2 | Cr√©er `src/analysis/win_streaks.py` : `compute_weekly_longest_streak()`, `compute_win_streak_distribution()` | Nouveau fichier |
| 6A.3 | Ajouter section "S√©rie de victoires hebdomadaire" (barres par semaine) | `src/ui/pages/win_loss.py` ; cr√©er `plot_weekly_longest_streak()` dans `distributions.py` |
| 6A.4 | Ajouter section "Distribution des s√©ries de victoires" (histogramme) | `src/ui/pages/win_loss.py` ; cr√©er `plot_win_streak_distribution()` dans `distributions.py` |
| 6A.5 | Ajouter section "Rang et score personnel" (scatter ou barres group√©es) | `src/ui/pages/win_loss.py` ; cr√©er `plot_rank_and_personal_score()` dans `distributions.py` |

#### 6B ‚Äî Page Dernier match (P6 ¬ß3-4)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 6B.1 | Ajouter section "D√©g√¢ts" (histogramme superpos√© damage_dealt/taken) | `src/ui/pages/match_view.py` ; cr√©er `plot_damage_distribution_combined()` dans `distributions.py` |
| 6B.2 | Ajouter section "Tirs et pr√©cision" (barres shots_fired/hit + courbe accuracy) | `src/ui/pages/match_view.py` (ou `timeseries.py`) ; cr√©er `plot_shots_fired_hit_accuracy()` dans `src/visualization/timeseries.py` |
| 6B.3 | Ajouter section "D√©g√¢ts avec moyenne liss√©e" (barres + rolling average) | `src/ui/pages/timeseries.py` ; cr√©er `plot_damage_timeseries_with_smooth()` dans `src/visualization/timeseries.py` |
| 6B.4 | Retirer la pr√©cision du graphe "Folie meurtri√®re / Tirs √† la t√™te / Pr√©cision / Frags parfaits" (supprimer trace + axe Y secondaire) | `src/visualization/timeseries.py` L.508+ (`plot_spree_headshots_accuracy`) |

#### 6C ‚Äî Adapter Matchs Top pour p√©riodes < semaine (P6 ¬ß6.1)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 6C.1 | Cr√©er `plot_matches_at_top_by_period()` (ou modifier `plot_matches_at_top_by_week()`) avec d√©tection auto p√©riode (day/week/month) | `src/visualization/distributions.py` L.956+ |
| 6C.2 | Mettre √† jour l'appel dans `win_loss.py` | `src/ui/pages/win_loss.py` L.197+ |

**Tests Sprint 6** :
- Cr√©er `tests/test_win_streaks.py` :
  - Test `compute_weekly_longest_streak` avec donn√©es connues (s√©ries de 3, 5, 2)
  - Test `compute_win_streak_distribution` (distribution correcte)
  - Test avec donn√©es vides
- Ajouter dans `tests/test_visualizations.py` :
  - `test_plot_personal_score_by_match_valid` / `_empty`
  - `test_plot_win_streak_distribution_valid` / `_empty`
  - `test_plot_weekly_longest_streak_valid` / `_empty`
  - `test_plot_rank_and_personal_score_valid` / `_empty`
  - `test_plot_damage_distribution_combined_valid` / `_empty`
  - `test_plot_shots_fired_hit_accuracy_valid` / `_empty`
  - `test_plot_damage_timeseries_with_smooth_valid` / `_empty`
  - `test_plot_spree_headshots_no_accuracy` (v√©rifier suppression trace)
  - `test_plot_matches_at_top_by_period_day` / `_week` / `_month` / `_auto`

**Gate de livraison** :
- [ ] `pytest tests/test_win_streaks.py -v` passe
- [ ] `pytest tests/test_visualizations.py -v` passe (avec nouveaux tests)
- [ ] `pytest tests/ -v` passe sans r√©gression

**Commandes de validation** :
```bash
pytest tests/test_win_streaks.py tests/test_visualizations.py -v
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier Victoires/D√©faites, Dernier match, tirs, d√©g√¢ts
```

**Livrables** :
- Code : `src/analysis/win_streaks.py` (nouveau), `src/ui/pages/win_loss.py`, `src/ui/pages/match_view.py`
- Visualisations : `src/visualization/distributions.py`, `src/visualization/timeseries.py`
- Tests : `tests/test_win_streaks.py`
- Mise √† jour `.ai/thought_log.md`

---

### Sprint 7 ‚Äî Nouvelles stats : Mes Co√©quipiers (3 jours)

**Objectif** : P6 Phase 4 ‚Äî Toutes les comparaisons co√©quipiers

**Pr√©requis** : Sprint 2A (damage participants), Sprint 3E (refonte co√©quipiers), Sprint 5-6 (fonctions de visualisation)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 7.1 | Ajouter comparaison "Score personnel" (moi vs co√©quipier) sur matchs communs | `src/ui/pages/teammates.py`, `teammates_charts.py` |
| 7.2 | Ajouter comparaison "S√©ries de victoires" (moi vs co√©quipier) | `src/ui/pages/teammates.py`, `teammates_charts.py` |
| 7.3 | Ajouter comparaison "Rang et score" (moi vs co√©quipier) | `src/ui/pages/teammates.py`, `teammates_charts.py` |
| 7.4 | Ajouter corr√©lations c√¥te √† c√¥te (dur√©e vie vs morts, kills vs deaths, MMR) | `src/ui/pages/teammates.py`, `teammates_charts.py` |
| 7.5 | Ajouter comparaison distributions (score/min, win ratio, d√©g√¢ts dealt/taken) | `src/ui/pages/teammates.py`, `teammates_charts.py` |
| 7.6 | Ajouter visualisations tirs (barres group√©es, scatter, heatmap pr√©cision) | `src/ui/pages/teammates_charts.py` : `render_shots_comparison_bars()`, `render_shots_scatter_comparison()`, `render_shots_heatmap_comparison()` |
| 7.7 | Ajouter visualisations d√©g√¢ts (barres group√©es, scatter efficacit√©, ratio dealt/taken) | `src/ui/pages/teammates_charts.py` : `render_damage_comparison_bars()`, `render_damage_efficiency_scatter()`, `render_damage_ratio_bars()` |
| 7.8 | Ajouter heatmap Win Ratio par jour/heure (moi vs co√©quipier) | `src/ui/pages/teammates.py`, `teammates_charts.py` : `render_win_ratio_heatmap_comparison()` |
| 7.9 | Ajouter "Matchs Top vs Total par p√©riode" comparatif | `src/ui/pages/teammates.py`, `teammates_charts.py` : `render_top_matches_comparison()` |

**Tests Sprint 7** :
- Cr√©er `tests/test_teammates_new_comparisons.py` :
  - Test chaque nouvelle fonction de comparaison avec donn√©es fixtures
  - Test avec donn√©es vides (pas de matchs communs)
  - Test avec un seul match commun
  - Test avec donn√©es manquantes (damage_dealt NULL)

**Gate de livraison** :
- [ ] `pytest tests/test_teammates_new_comparisons.py -v` passe
- [ ] `pytest tests/ -v` passe sans r√©gression
- [ ] Test manuel UI : v√©rifier chaque graphe comparatif

**Commandes de validation** :
```bash
pytest tests/test_teammates_new_comparisons.py -v
pytest tests/ -v
streamlit run streamlit_app.py  # V√©rifier toutes les comparaisons co√©quipiers
```

**Livrables** :
- Code : `src/ui/pages/teammates.py`, `src/ui/pages/teammates_charts.py`
- Tests : `tests/test_teammates_new_comparisons.py`
- Mise √† jour `.ai/thought_log.md`
- Mise √† jour `.ai/PLAN_DETAIL_STATS_NOUVELLES.md` (statut : Impl√©ment√©)

---

### Sprint 8 ‚Äî Refactoring structurel backfill (optionnel, 3 jours)

**Objectif** : P2 ¬ß3-6 ‚Äî Am√©lioration √† long terme de la maintenabilit√©

**Pr√©requis** : Tous les sprints pr√©c√©dents livr√©s

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 8.1 | Cr√©er `scripts/backfill/__init__.py`, `core.py` (fonctions d'insertion) | Nouveaux fichiers |
| 8.2 | Extraire `detection.py` (`_find_matches_missing_data`) | Nouveau fichier |
| 8.3 | Extraire `strategies.py` (backfill sp√©cifiques : killer_victim, end_time, sessions, etc.) | Nouveau fichier |
| 8.4 | Extraire `orchestrator.py` (`backfill_player_data`, `backfill_all_players`) | Nouveau fichier |
| 8.5 | Extraire `cli.py` (arguments CLI) | Nouveau fichier |
| 8.6 | Refactorer `backfill_data.py` en point d'entr√©e l√©ger (~200 lignes) | `scripts/backfill_data.py` |
| 8.7 | Impl√©menter d√©tection AND/OR configurable (`--strict-detection`) | `scripts/backfill/detection.py` |
| 8.8 | Optimiser SQL : remplacer `IN` par `EXISTS` / CTEs | `scripts/backfill/detection.py` |
| 8.9 | Centraliser migrations : cr√©er `src/db/migrations.py` (DRY engine.py + backfill) | Nouveau fichier |
| 8.10 | (Optionnel) Table `backfill_status` pour tracking par type de donn√©e | `scripts/backfill/detection.py` |

**Tests Sprint 8** :
- Adapter tous les tests backfill existants aux nouveaux imports
- Cr√©er `tests/test_backfill_detection.py` :
  - Test mode OR vs AND
  - Test CTEs vs sous-requ√™tes (m√™me r√©sultat)
- Cr√©er `tests/test_migrations.py` :
  - Test `ensure_match_participants_columns` sur DB vierge
  - Test sur DB existante (idempotence)
  - Test `run_all_migrations`

**Gate de livraison** :
- [ ] `pytest tests/ -v` passe (tous les tests, y compris refactoris√©s)
- [ ] `python scripts/backfill_data.py --player JGtm --all-data --dry-run` fonctionne
- [ ] `wc -l scripts/backfill_data.py` < 300 lignes

**Commandes de validation** :
```bash
pytest tests/test_backfill_detection.py tests/test_migrations.py -v
python scripts/backfill_data.py --player JGtm --all-data --dry-run
wc -l scripts/backfill_data.py
pytest tests/ -v
```

**Livrables** :
- Modules : `scripts/backfill/__init__.py`, `core.py`, `detection.py`, `strategies.py`, `orchestrator.py`, `cli.py`
- Migrations : `src/db/migrations.py`
- `scripts/backfill_data.py` r√©duit √† ~200 lignes (point d'entr√©e l√©ger)
- Tests : `tests/test_backfill_detection.py`, `tests/test_migrations.py`
- Mise √† jour `.ai/thought_log.md`

---

### Sprint 9 ‚Äî Finalisation, tests d'int√©gration et documentation (3 jours)

**Objectif** : Tests d'int√©gration complets, tests de charge, couverture, release notes, guide utilisateur

**Pr√©requis** : Tous les sprints S0-S7 livr√©s (S8 optionnel)

#### 9A ‚Äî Tests d'int√©gration (1 jour)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 9A.1 | Cr√©er `tests/test_integration_stats_nouvelles.py` : toutes les nouvelles visualisations accessibles | Nouveau fichier |
| 9A.2 | V√©rifier pas de r√©gression sur pages existantes | Tests existants |
| 9A.3 | V√©rifier performance acceptable (temps de chargement < 5s par page) | Test manuel + m√©trique |
| 9A.4 | V√©rifier pas d'erreurs dans les logs Streamlit | Test manuel |

#### 9B ‚Äî Tests de charge (¬Ω jour)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 9B.1 | Test avec joueur ayant 1000+ matchs | Test manuel |
| 9B.2 | Test avec joueur ayant 5000+ matchs | Test manuel |
| 9B.3 | V√©rifier que les temps de chargement restent acceptables, impl√©menter lazy loading si n√©cessaire | UI pages |

#### 9C ‚Äî Couverture de tests (¬Ω jour)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 9C.1 | Ex√©cuter `pytest tests/ -v --cov=src --cov-report=html` et v√©rifier > 95% | ‚Äî |
| 9C.2 | Identifier et combler les trous de couverture critiques | Tests existants |

#### 9D ‚Äî Documentation et release (1 jour)

| # | T√¢che | Fichier(s) |
|---|-------|-----------|
| 9D.1 | Mettre √† jour tous les plans `.ai/features/` avec statut final | Fichiers `.ai/` |
| 9D.2 | Cr√©er `.ai/RELEASE_NOTES_2026_Q1.md` (changelog de toutes les nouvelles fonctionnalit√©s) | Nouveau fichier |
| 9D.3 | Cr√©er `docs/USER_GUIDE_NEW_FEATURES.md` (guide utilisateur avec screenshots) | Nouveau fichier |
| 9D.4 | Mettre √† jour `CLAUDE.md` si n√©cessaire (nouvelles commandes, tables) | `CLAUDE.md` |
| 9D.5 | Synth√®se finale dans `.ai/thought_log.md` | `.ai/thought_log.md` |

**Gate de livraison** :
- [ ] `pytest tests/ -v --cov=src --cov-report=html` ‚Üí > 95% couverture
- [ ] `pytest tests/ -v` ‚Üí 0 failure, 0 error
- [ ] Tous les plans `.ai/features/` marqu√©s Impl√©ment√©
- [ ] Release notes et guide utilisateur r√©dig√©s
- [ ] Performance valid√©e sur plusieurs profils (1000+, 5000+ matchs)

**Commandes de validation** :
```bash
pytest tests/ -v --cov=src --cov-report=html
streamlit run streamlit_app.py  # Navigation compl√®te toutes pages
grep -r "import pandas" src/  # V√©rifier conformit√©
grep -r "import sqlite3" src/  # V√©rifier conformit√©
```

**Livrables** :
- Tests : `tests/test_integration_stats_nouvelles.py`
- Documentation : `.ai/RELEASE_NOTES_2026_Q1.md`, `docs/USER_GUIDE_NEW_FEATURES.md`
- Mise √† jour tous les fichiers `.ai/` avec statut final
- App pr√™te pour release

---

## 6. R√©capitulatif des fichiers impact√©s

### Fichiers √† cr√©er

| Fichier | Sprint | Plan |
|---------|--------|------|
| `src/ui/components/career_progress_circle.py` | S2 | P7 |
| `src/app/career_section.py` | S2 | P7 |
| `src/analysis/win_streaks.py` | S6 | P6 |
| `scripts/recompute_performance_scores_duckdb.py` | S4 | P5 |
| `scripts/backfill/__init__.py` | S8 | P2 |
| `scripts/backfill/core.py` | S8 | P2 |
| `scripts/backfill/detection.py` | S8 | P2 |
| `scripts/backfill/strategies.py` | S8 | P2 |
| `scripts/backfill/orchestrator.py` | S8 | P2 |
| `scripts/backfill/cli.py` | S8 | P2 |
| `src/db/migrations.py` | S8 | P2 |

### Fichiers de tests √† cr√©er

| Fichier | Sprint |
|---------|--------|
| `tests/test_session_last_button.py` | S0 |
| `tests/test_participants_damage.py` | S2 |
| `tests/test_career_progress_circle.py` | S2 |
| `tests/test_mode_normalization_winloss.py` | S3 |
| `tests/test_teammates_refonte.py` | S3 |
| `tests/test_performance_score_v4.py` | S4 |
| `tests/test_new_timeseries_sections.py` | S5 |
| `tests/test_win_streaks.py` | S6 |
| `tests/test_teammates_new_comparisons.py` | S7 |
| `tests/test_backfill_detection.py` | S8 |
| `tests/test_migrations.py` | S8 |
| `tests/test_media_improvements.py` | S3 |
| `tests/test_integration_stats_nouvelles.py` | S9 |

### Fichiers de documentation √† cr√©er

| Fichier | Sprint |
|---------|--------|
| `.ai/RELEASE_NOTES_2026_Q1.md` | S9 |
| `docs/USER_GUIDE_NEW_FEATURES.md` | S9 |

### Fichiers existants √† modifier

| Fichier | Sprints |
|---------|---------|
| `src/app/filters_render.py` | S0 |
| `src/app/filters.py` | S0 |
| `streamlit_app.py` | S0bis |
| `src/ui/filter_state.py` | S0bis |
| `src/analysis/performance_score.py` | S1, S4 |
| `src/analysis/performance_config.py` | S4 |
| `scripts/backfill_data.py` | S1, S2, S4, (S8) |
| `src/data/sync/models.py` | S2 |
| `src/data/sync/transformers.py` | S2 |
| `src/data/sync/engine.py` | S2, S4 |
| `src/visualization/distributions.py` | S3, S5, S6 |
| `src/visualization/timeseries.py` | S6 |
| `src/visualization/performance.py` | S5 |
| `src/ui/pages/timeseries.py` | S3, S5 |
| `src/ui/pages/win_loss.py` | S3, S6 |
| `src/ui/pages/teammates.py` | S3, S7 |
| `src/ui/pages/teammates_charts.py` | S3, S7 |
| `src/ui/pages/match_view.py` | S6 |
| `src/ui/pages/media_tab.py` | S3 |
| `src/ui/components/media_thumbnail.py` | S3 |
| `src/ui/components/media_lightbox.py` | S3 |
| `src/app/page_router.py` | S3 |
| `tests/test_performance_score.py` | S1 |
| `tests/test_sync_performance_score.py` | S1, S4 |
| `tests/test_backfill_performance_score.py` | S1, S4 |
| `tests/test_visualizations.py` | S3, S5, S6 |
| `tests/test_models.py` | S2 |

---

## 7. Matrice de risques

| Risque | Probabilit√© | Impact | Mitigation | Sprint |
|--------|-------------|--------|------------|--------|
| R√©gression performance_score apr√®s migration Polars | Moyenne | üî¥ √âlev√© | Tests exhaustifs avant/apr√®s ; comparer scores v3 sur √©chantillon | S1 |
| Perte de donn√©es backfill (probl√®me B non r√©solu) | Haute | üü† Moyen | Workaround document√© (traiter par √©tapes) ; r√©solu en S8 | S1-S8 |
| API ne fournit pas DamageDealt/DamageTaken pour tous les joueurs | Faible | üü† Moyen | `getattr(row, "damage_dealt", None)` + graceful degradation | S2 |
| Conflits de merge entre sprints parall√®les (S2 + S3) | Moyenne | üü° Faible | Fichiers diff√©rents ; seul `teammates.py` touch√© par les deux | S2-S3 |
| XP_HERO_TOTAL incorrect (9 319 350) | Faible | üü° Faible | V√©rifier via m√©tadonn√©es cache ; ajouter fallback par rang | S2 |
| Recalcul v4 trop long pour joueurs avec 2000+ matchs | Faible | üü° Faible | Batching + `--batch-size` ; parall√©lisation par joueur | S4 |
| Complexit√© excessive Sprint 7 (9 sous-t√¢ches co√©quipiers) | Haute | üü† Moyen | D√©couper S7 en 2 sous-sprints (7a : stats individuelles, 7b : comparaisons) | S7 |
| Performance d√©grad√©e (trop de graphiques par page) | Moyenne | üü† Moyen | Tests de charge S9 ; lazy loading si n√©cessaire ; limiter le nombre de graphiques visibles simultan√©ment | S5-S9 |
| D√©passement de budget temps | Moyenne | üü° Faible | Priorisation stricte (S0-S4 non n√©gociables) ; possibilit√© de reporter S6-S7 | S0-S9 |
| R√©gression affichage filtres (nettoyage trop large) | Faible | üü° Faible | Ne supprimer que les cl√©s list√©es + pr√©fixes widgets ; tests A‚ÜíB‚ÜíA | S0bis |

---

## 8. Crit√®res de livraison

### Par sprint

Chaque sprint est consid√©r√© livr√© quand :

1. **Tests automatis√©s** : `pytest tests/ -v` passe √† 100 % (0 failure, 0 error)
2. **Nouveaux tests** : Les tests sp√©cifiques du sprint passent
3. **Pas de r√©gression** : Les tests existants ne sont pas cass√©s
4. **Conformit√© r√®gles** :
   - `grep -r "import pandas" src/` ‚Üí uniquement dans les fichiers autoris√©s (fronti√®re Plotly/Streamlit)
   - `grep -r "import sqlite3" src/` ‚Üí aucun r√©sultat
5. **Commit propre** : Un commit par sprint avec message descriptif

### Globale (fin de tous les sprints)

- [ ] Toutes les gates de livraison des sprints S0-S9 valid√©es
- [ ] Au moins **12 nouveaux fichiers de tests** cr√©√©s
- [ ] Plus de **50 nouveaux tests** ajout√©s
- [ ] `scripts/backfill_data.py` : aucun `import pandas`
- [ ] `src/analysis/performance_score.py` : aucun `import pandas`
- [ ] Score de performance v4 fonctionnel avec graceful degradation
- [ ] Toutes les nouvelles visualisations visibles dans l'UI
- [ ] Section Carri√®re avec cercle de progression
- [ ] Donn√©es damage_dealt/taken disponibles dans match_participants
- [ ] Documentation `.ai/thought_log.md` et `.ai/project_map.md` mises √† jour
- [ ] Release notes et guide utilisateur r√©dig√©s (S9)
- [ ] Couverture de tests > 95% (S9)

---

## Calendrier r√©capitulatif

| Sprint | Dur√©e | Plans | Parall√©lisable |
|--------|-------|-------|---------------|
| **S0** | ¬Ω j | P1 | ‚Äî |
| **S0bis** | ¬Ω‚Äì1 j | P8 | ‚úÖ avec S0 |
| **S1** | 2 j | P2 (partiel) | ‚Äî |
| **S2** | 2.5 j | P3 + P7 | ‚úÖ avec S3 |
| **S3** | 3 j | P4 | ‚úÖ avec S2 |
| **S4** | 2 j | P5 | Apr√®s S1 + S2A |
| **S5** | 2 j | P6 (Phase 1) | Apr√®s S3 |
| **S6** | 2 j | P6 (Phase 2-3) | Apr√®s S5 |
| **S7** | 3 j | P6 (Phase 4) | Apr√®s S6 + S3E |
| **S8** | 3 j | P2 (structurel) | Optionnel |
| **S9** | 3 j | Finalisation | Apr√®s S0-S7 |
| **Total** | **~23 j** | 7 plans + finalisation | |

> En parall√©lisant S2 et S3, le chemin critique est d'environ **19 jours ouvr√©s** (S8 optionnel).

---

---

## 9. M√©triques de succ√®s

| Domaine | M√©trique | Cible |
|---------|----------|-------|
| **Code Quality** | Violations Pandas dans `src/` | 0 (uniquement `.to_pandas()` √† la fronti√®re Plotly/Streamlit) |
| **Code Quality** | Violations SQLite dans `src/` | 0 |
| **Code Quality** | Architecture DuckDB v4 | 100% |
| **Tests** | Couverture de code | > 95% |
| **Tests** | Nombre de fichiers de tests cr√©√©s | >= 12 |
| **Tests** | Nombre de nouveaux tests | >= 50 |
| **Performance** | Temps de chargement par page | < 5 secondes |
| **Performance** | Backfill par match | < 2 secondes |
| **UX** | Bugs bloquants | 0 |
| **UX** | Navigation | Intuitive, labels clairs, graphiques lisibles |
| **Donn√©es** | Nouvelles m√©triques disponibles et correctes | PSPM, DPM damage, Rank Performance, damage participants |
| **Documentation** | Plans `.ai/features/` marqu√©s Impl√©ment√© | 100% |
| **Documentation** | Guide utilisateur | Complet avec exemples |

---

## 10. Prochaines √©tapes imm√©diates

### 10.1 V√©rification de l'environnement

```bash
# V√©rifier versions requises
python --version        # 3.11+
streamlit --version     # >= 1.30
pytest --version        # >= 7.0
duckdb --version        # >= 0.10 (v4)

# V√©rifier que l'app d√©marre
streamlit run streamlit_app.py
```

### 10.2 Pr√©paration git

```bash
# Cr√©er branche de d√©veloppement
git checkout -b feature/consolidated-roadmap-2026-q1

# Ou utiliser la branche existante si applicable
git checkout feature/hybrid-data-architecture
```

### 10.3 D√©marrer Sprint 0 / Sprint 0bis

Sprint 0 est le point d'entr√©e imm√©diat : correction du bug "Derni√®re session" (¬Ω jour). Sprint 0bis (persistance filtres multi-joueurs, P8) peut √™tre fait en parall√®le ou juste apr√®s : conservation des filtres par joueur au switch de DB.

### 10.4 Ordre de priorit√© si contrainte de temps

Si le budget temps est limit√©, prioriser strictement :
1. **S0** (bug fix visible "Derni√®re session") ‚Äî non n√©gociable
2. **S0bis** (persistance filtres par joueur) ‚Äî fort impact UX, rapide
3. **S1** (backfill fiable + Pandas) ‚Äî non n√©gociable (dette technique critique)
3. **S2** (damage participants + carri√®re) ‚Äî haut impact utilisateur
4. **S4** (perf score v4) ‚Äî forte valeur ajout√©e
5. **S3** (m√©dianes, UI) ‚Äî qualit√© de vie
6. **S5-S7** (nouvelles stats) ‚Äî am√©liorations progressives, reportables
7. **S8** (refactoring structurel) ‚Äî optionnel, maintenabilit√© long terme
8. **S9** (finalisation) ‚Äî √† adapter selon sprints effectivement livr√©s

---

**Document g√©n√©r√© le** : 2026-02-09
**Derni√®re mise √† jour** : 2026-02-09 (int√©gration P8 ‚Äî Persistance filtres multi-joueurs)
**Auteur** : Claude Code (analyse et compilation)
**Mis √† jour avec** : √âl√©ments du premier jet (`nouveau 1.txt`)
