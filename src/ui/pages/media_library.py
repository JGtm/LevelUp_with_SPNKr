"""Page Biblioth√®que m√©dias.

**Note** : L‚Äôonglet principal est d√©sormais ¬´ M√©dias ¬ª (media_tab.py), qui charge
les donn√©es depuis la BDD (media_files, media_match_associations) et affiche
les sections Mes captures / Captures de XXX / Sans correspondance. Ce module
reste disponible pour compatibilit√© (dispatch ¬´ Biblioth√®que m√©dias ¬ª ‚Üí render_media_tab)
et pour options avanc√©es (re-scan manuel, etc.) si besoin.

Objectif: proposer une vue "biblioth√®que" qui scanne les dossiers de m√©dias
(configur√©s dans les param√®tres) et permet d'ouvrir rapidement le match associ√©.

L'association m√©dia ‚Üí match se fait par proximit√© temporelle:
- on indexe les fichiers (mtime)
- on calcule pour chaque match une fen√™tre [start - tol ; end + tol]
- on associe un m√©dia au match dont la fen√™tre contient son mtime

Note: cette page ne d√©pend pas de m√©tadonn√©es dans les noms de fichiers.
"""

from __future__ import annotations

import contextlib
import hashlib
import html
import os
import urllib.parse
from dataclasses import dataclass
from datetime import datetime, timedelta

import polars as pl
import streamlit as st

from src.ui.formatting import PARIS_TZ, format_datetime_fr_hm
from src.ui.pages.match_view_helpers import index_media_dir
from src.ui.settings import AppSettings
from src.visualization._compat import DataFrameLike, ensure_polars


@dataclass(frozen=True)
class _MediaDirs:
    screens_dir: str
    videos_dir: str


def _coerce_dirs(settings: AppSettings) -> _MediaDirs:
    screens_dir = str(getattr(settings, "media_screens_dir", "") or "").strip()
    videos_dir = str(getattr(settings, "media_videos_dir", "") or "").strip()
    return _MediaDirs(screens_dir=screens_dir, videos_dir=videos_dir)


def _build_app_url(page: str, **params: str) -> str:
    qp: dict[str, str] = {"page": str(page)}
    for k, v in params.items():
        s = str(v or "").strip()
        if s:
            qp[str(k)] = s
    return "?" + urllib.parse.urlencode(qp)


def _open_match_button(match_id: str, *, unique_suffix: str | None = None) -> None:
    """Affiche un bouton pour ouvrir la page Match.

    Args:
        match_id: ID du match √† ouvrir
        unique_suffix: Suffixe optionnel pour rendre la cl√© unique (ex: path_hash ou stable_id)
    """
    mid = str(match_id or "").strip()
    if not mid:
        st.caption("Match inconnu")
        return

    # Rendre la cl√© unique en incluant le suffixe si fourni
    # Cela √©vite les cl√©s dupliqu√©es quand plusieurs m√©dias ont le m√™me match_id
    button_key = f"open_match_{mid}_{unique_suffix}" if unique_suffix else f"open_match_{mid}"

    # Utiliser _pending_page au lieu de modifier directement "page"
    # car le widget segmented_control avec key="page" est d√©j√† instanci√©
    # consume_pending_page() s'occupera de mettre √† jour "page" au prochain rendu
    if st.button("Ouvrir le match", key=button_key, width="stretch"):
        st.session_state["_pending_page"] = "Match"
        st.session_state["_pending_match_id"] = mid
        st.rerun()


def _epoch_seconds_paris(dt_value: datetime | None) -> float | None:
    if dt_value is None:
        return None
    try:
        aware = (
            PARIS_TZ.localize(dt_value)
            if dt_value.tzinfo is None
            else dt_value.astimezone(PARIS_TZ)
        )
        return float(aware.timestamp())
    except Exception:
        return None


def _to_paris_naive(dt_value: object) -> datetime | None:
    """Convertit une valeur datetime en datetime na√Øve (fuseau Paris)."""
    try:
        if dt_value is None:
            return None
        if isinstance(dt_value, datetime):
            ts = dt_value
        elif isinstance(dt_value, str):
            s = str(dt_value).strip()
            if not s:
                return None
            if s.endswith("Z"):
                s = s[:-1] + "+00:00"
            ts = datetime.fromisoformat(s)
        else:
            return None
        if ts.tzinfo is None:
            return ts
        return ts.astimezone(PARIS_TZ).replace(tzinfo=None)
    except Exception:
        return None


def _compute_match_windows(df_full: DataFrameLike, settings: AppSettings) -> pl.DataFrame:
    """Construit les fen√™tres temporelles des matchs (epoch seconds) pour l'association m√©dia.

    Am√©liorations:
    - G√®re les start_time NULL avec un diagnostic
    - Utilise une dur√©e par d√©faut de 12 minutes si time_played_seconds est NULL
    """
    _empty = pl.DataFrame(
        schema={
            "match_id": pl.Utf8,
            "start_epoch": pl.Float64,
            "end_epoch": pl.Float64,
            "start_time": pl.Datetime,
        }
    )
    if df_full is None:
        return _empty
    df_full = ensure_polars(df_full)
    if df_full.is_empty():
        return _empty

    tol_min = int(getattr(settings, "media_tolerance_minutes", 0) or 0)
    tol = timedelta(minutes=max(0, tol_min))

    needed = {"match_id", "start_time"}
    if not needed.issubset(set(df_full.columns)):
        return _empty

    cols = [c for c in ["match_id", "start_time", "time_played_seconds"] if c in df_full.columns]
    base = df_full.select(cols)

    # Calculer les fen√™tres via Python (struct temporel complexe)
    rows: list[dict[str, object]] = []
    for rec in base.iter_rows(named=True):
        start = _to_paris_naive(rec.get("start_time"))
        if not isinstance(start, datetime):
            continue
        dur_s = rec.get("time_played_seconds")
        try:
            dur = float(dur_s) if dur_s is not None else None
        except Exception:
            dur = None
        if dur is None or dur <= 0:
            end = start + timedelta(minutes=12)
        else:
            end = start + timedelta(seconds=dur)
        t0 = start - tol
        t1 = end + tol
        se = _epoch_seconds_paris(t0)
        ee = _epoch_seconds_paris(t1)
        mid = rec.get("match_id")
        if mid is None or se is None or ee is None:
            continue
        rows.append(
            {
                "match_id": str(mid),
                "start_epoch": se,
                "end_epoch": ee,
                "start_time": start,
            }
        )

    if not rows:
        return _empty

    return pl.DataFrame(rows).sort("start_epoch")


def _index_all_media(settings: AppSettings) -> pl.DataFrame:
    """Indexe les m√©dias configur√©s (captures + vid√©os)."""
    dirs = _coerce_dirs(settings)
    frames: list[pl.DataFrame] = []

    if dirs.screens_dir and os.path.isdir(dirs.screens_dir):
        img_df = index_media_dir(dirs.screens_dir, ("png", "jpg", "jpeg", "webp"))
        if not img_df.is_empty():
            img_df = img_df.with_columns(pl.lit("image").alias("kind"))
            frames.append(img_df)

    if dirs.videos_dir and os.path.isdir(dirs.videos_dir):
        vid_df = index_media_dir(dirs.videos_dir, ("mp4", "webm", "mkv", "mov"))
        if not vid_df.is_empty():
            vid_df = vid_df.with_columns(pl.lit("video").alias("kind"))
            frames.append(vid_df)

    if not frames:
        return pl.DataFrame(
            schema={"path": pl.Utf8, "mtime": pl.Float64, "ext": pl.Utf8, "kind": pl.Utf8}
        )

    df = pl.concat(frames)
    if df.is_empty():
        return df

    df = df.with_columns(
        [
            pl.col("path").cast(pl.Utf8),
            pl.col("path")
            .map_elements(lambda p: os.path.basename(str(p)), return_dtype=pl.Utf8)
            .alias("basename"),
        ]
    ).drop_nulls(subset=["mtime"])
    return df.sort("mtime", descending=True)


def _associate_media_to_matches(media_df: pl.DataFrame, windows_df: pl.DataFrame) -> pl.DataFrame:
    """Associe chaque m√©dia √† un match (best-effort) via join_asof + check de fen√™tre.

    Am√©lioration: utilise strategy="nearest" pour capturer les m√©dias pris
    l√©g√®rement AVANT le match (ex: pendant le chargement) ou APR√àS.
    V√©rifie ensuite que le m√©dia est bien dans la fen√™tre [start_epoch, end_epoch].
    """
    if media_df is None or media_df.is_empty():
        extra_cols = {"match_id": pl.Utf8, "match_start_time": pl.Datetime}
        if media_df is not None:
            schema = {
                **{c: media_df.dtypes[i] for i, c in enumerate(media_df.columns)},
                **extra_cols,
            }
            return pl.DataFrame(schema=schema)
        return pl.DataFrame()

    if windows_df is None or windows_df.is_empty():
        return media_df.with_columns(
            [
                pl.lit(None).cast(pl.Utf8).alias("match_id"),
                pl.lit(None).cast(pl.Datetime).alias("match_start_time"),
            ]
        )

    # S'assurer que mtime est num√©rique et non-null
    m = media_df.drop_nulls(subset=["mtime"]).sort("mtime")
    w = windows_df.sort("start_epoch")

    # join_asof : strategy="nearest" pour trouver le match le plus proche
    joined = m.join_asof(
        w,
        left_on="mtime",
        right_on="start_epoch",
        strategy="nearest",
    )

    # V√©rifier que le m√©dia est dans la fen√™tre [start_epoch, end_epoch]
    joined = joined.with_columns(
        [
            pl.when(
                pl.col("start_epoch").is_not_null()
                & pl.col("end_epoch").is_not_null()
                & (pl.col("mtime") >= pl.col("start_epoch"))
                & (pl.col("mtime") <= pl.col("end_epoch"))
            )
            .then(pl.col("match_id"))
            .otherwise(pl.lit(None))
            .alias("match_id"),
            pl.when(
                pl.col("start_epoch").is_not_null()
                & pl.col("end_epoch").is_not_null()
                & (pl.col("mtime") >= pl.col("start_epoch"))
                & (pl.col("mtime") <= pl.col("end_epoch"))
            )
            .then(pl.col("start_time"))
            .otherwise(pl.lit(None))
            .alias("start_time"),
        ]
    )

    # Renommer et nettoyer
    drop_cols = [c for c in ["start_epoch", "end_epoch"] if c in joined.columns]
    joined = joined.drop(drop_cols)
    if "start_time" in joined.columns:
        joined = joined.rename({"start_time": "match_start_time"})

    return joined.sort("mtime", descending=True)


def _placeholder_html(base: str, hint: str = "Cliquer pour afficher la miniature") -> str:
    """HTML du placeholder vid√©o (sans charger la miniature)."""
    return (
        "<div style='padding:18px;border-radius:12px;border:1px solid rgba(255,255,255,0.12);'>"
        "<div style='font-size:34px;line-height:1'>üé¨</div>"
        "<div style='opacity:0.85;margin-top:6px'>" + html.escape(base) + "</div>"
        "<div style='font-size:11px;opacity:0.6;margin-top:4px'>" + html.escape(hint) + "</div>"
        "</div>"
    )


def _render_media_grid(
    items: DataFrameLike, *, cols_per_row: int, render_context: str = "default"
) -> None:
    """Affiche une grille de m√©dias Streamlit."""
    if items is None:
        st.info("Aucun m√©dia √† afficher avec ces filtres.")
        return
    items = ensure_polars(items)
    if items.is_empty():
        st.info("Aucun m√©dia √† afficher avec ces filtres.")
        return

    cols_per_row = int(cols_per_row)
    if cols_per_row < 2:
        cols_per_row = 2
    if cols_per_row > 8:
        cols_per_row = 8

    # Ajouter un identifiant stable au DataFrame AVANT le rendu
    # pour √©viter que les cl√©s session_state changent √† chaque rendu
    items = items.with_row_index("_stable_id")

    rows = items.to_dicts()
    for i in range(0, len(rows), cols_per_row):
        chunk = rows[i : i + cols_per_row]
        # TOUJOURS cr√©er cols_per_row colonnes, m√™me si len(chunk) < cols_per_row
        # pour √©viter que les images prennent toute la largeur
        cols = st.columns(cols_per_row)
        for col_idx in range(cols_per_row):
            with cols[col_idx]:
                if col_idx < len(chunk):
                    rec = chunk[col_idx]
                    path = str(rec.get("path") or "").strip()
                    kind = str(rec.get("kind") or "")
                    base = str(rec.get("basename") or os.path.basename(path))
                    mid = rec.get("match_id")

                    if kind == "image" and path:
                        try:
                            st.image(path, width="stretch")
                        except Exception:
                            st.caption(base)
                    else:
                        # Vid√©o : afficher la miniature seulement au clic (√©vite tout charger √† l'ouverture)
                        # Cl√© stable : hash du path + match_id + contexte + identifiant stable du m√©dia
                        # (pas de position dans la grille pour √©viter l'instabilit√©)
                        thumb_path = str(rec.get("thumbnail_path") or "").strip()
                        path_hash = hashlib.md5(path.encode()).hexdigest()
                        match_id_part = (
                            str(mid).strip() if isinstance(mid, str) and mid.strip() else "no_match"
                        )
                        # Utiliser l'ID stable au lieu de i et col_idx
                        stable_id = rec.get("_stable_id", 0)
                        thumb_key = f"thumb_show::{path_hash}::{match_id_part}::{render_context}::{stable_id}"
                        show_thumb = st.session_state.get(thumb_key, False)

                        if show_thumb and thumb_path and os.path.exists(thumb_path):
                            try:
                                st.image(thumb_path, width="stretch")
                            except Exception:
                                st.markdown(_placeholder_html(base), unsafe_allow_html=True)
                            if st.button("Masquer miniature", key=thumb_key + "::btn"):
                                st.session_state[thumb_key] = False
                                st.rerun()
                        else:
                            st.markdown(
                                _placeholder_html(base, "Cliquer pour afficher la miniature"),
                                unsafe_allow_html=True,
                            )
                            if thumb_path and os.path.exists(thumb_path):
                                if st.button("Afficher miniature", key=thumb_key + "::btn"):
                                    st.session_state[thumb_key] = True
                                    st.rerun()
                            else:
                                st.caption("(pas de miniature g√©n√©r√©e)")
                        if path:
                            preview_key = f"media_preview::{path_hash}::{match_id_part}::{render_context}::{stable_id}"
                            if st.button("Aper√ßu", key=preview_key, width="stretch"):
                                st.session_state[preview_key + "::open"] = True
                            if st.session_state.get(preview_key + "::open"):
                                try:
                                    st.video(path)
                                except Exception:
                                    st.caption(path)

                    st.caption(base)
                    # Ne pas afficher le bouton "Ouvrir le match" si on est dans un contexte de groupe
                    # (le bouton est d√©j√† affich√© avant la grille dans l'expander)
                    if (
                        isinstance(mid, str)
                        and mid.strip()
                        and not render_context.startswith("match_")
                    ):
                        # Utiliser le stable_id pour rendre la cl√© unique m√™me si plusieurs m√©dias ont le m√™me match_id
                        stable_id = rec.get("_stable_id", 0)
                        _open_match_button(mid, unique_suffix=str(stable_id))
                    elif isinstance(mid, str) and mid.strip():
                        # Dans un groupe de match, le bouton est d√©j√† affich√© avant la grille
                        pass
                    else:
                        st.caption("Match: non associ√©")


def _load_match_windows_from_db(db_path: str) -> pl.DataFrame:
    """Charge les fen√™tres temporelles des matchs depuis la DB pour le diagnostic.

    Note: Cette fonction charge depuis toutes les DBs joueurs disponibles,
    pas seulement celle du joueur actuel, car l'association se fait multi-joueurs.
    """
    _empty = pl.DataFrame(
        schema={
            "match_id": pl.Utf8,
            "start_epoch": pl.Float64,
            "end_epoch": pl.Float64,
            "start_time": pl.Datetime,
        }
    )
    try:
        import duckdb

        from src.utils.paths import PLAYER_DB_FILENAME, PLAYERS_DIR

        all_windows: list[dict[str, object]] = []

        # Parcourir toutes les DBs joueurs
        if PLAYERS_DIR.exists():
            for player_dir in PLAYERS_DIR.iterdir():
                if not player_dir.is_dir():
                    continue

                player_db = player_dir / PLAYER_DB_FILENAME
                if not player_db.exists():
                    continue

                try:
                    conn = duckdb.connect(str(player_db), read_only=True)
                    try:
                        # V√©rifier si la table existe
                        tables = conn.execute(
                            """
                            SELECT table_name
                            FROM information_schema.tables
                            WHERE table_schema = 'main'
                            AND table_name = 'match_stats'
                            """
                        ).fetchall()

                        if not tables:
                            continue

                        # Charger les matchs avec start_time
                        matches = conn.execute(
                            """
                            SELECT match_id, start_time, time_played_seconds
                            FROM match_stats
                            WHERE start_time IS NOT NULL
                            """
                        ).fetchall()

                        if matches:
                            for match_id, start_time, time_played in matches:
                                try:
                                    # Convertir start_time
                                    if isinstance(start_time, datetime):
                                        dt_start = start_time
                                    elif isinstance(start_time, str):
                                        if start_time.endswith("Z"):
                                            dt_start = datetime.fromisoformat(
                                                start_time[:-1] + "+00:00"
                                            )
                                        elif "+" in start_time or start_time.count("-") > 2:
                                            dt_start = datetime.fromisoformat(start_time)
                                        else:
                                            dt_start = datetime.fromisoformat(start_time + "+00:00")
                                    else:
                                        continue

                                    # Convertir en epoch Paris
                                    start_epoch = _epoch_seconds_paris(dt_start)
                                    if start_epoch is None:
                                        continue

                                    # Calculer fin
                                    duration = float(time_played or 0) if time_played else 12 * 60
                                    end_epoch = start_epoch + duration

                                    all_windows.append(
                                        {
                                            "match_id": str(match_id),
                                            "start_epoch": start_epoch,
                                            "end_epoch": end_epoch,
                                            "start_time": dt_start,
                                        }
                                    )
                                except Exception:
                                    continue
                    finally:
                        conn.close()
                except Exception:
                    continue

        if not all_windows:
            return _empty

        return pl.DataFrame(all_windows).sort("start_epoch")

    except Exception:
        return _empty


def _gamertag_from_db_path(db_path: str) -> str | None:
    """Extrait le gamertag (nom du dossier joueur) depuis le chemin de la DB."""
    if not db_path:
        return None
    try:
        from pathlib import Path

        p = Path(db_path)
        # data/players/JGtm/stats.duckdb -> JGtm
        if p.name and p.name.endswith(".duckdb"):
            return p.parent.name or None
        return None
    except Exception:
        return None


def _load_media_from_db(
    db_path: str,
    xuid: str | None = None,
    gamertag: str | None = None,
) -> pl.DataFrame:
    """Charge les m√©dias depuis la BDD DuckDB.

    Args:
        db_path: Chemin vers la DB DuckDB.
        xuid: XUID du joueur pour filtrer les associations (optionnel).
        gamertag: Gamertag (nom du dossier) pour inclure les associations stock√©es
                  avec le nom du dossier quand sync_meta n'a pas de xuid.

    Returns:
        DataFrame avec colonnes: path, mtime, ext, kind, basename, match_id, match_start_time, xuid
    """
    _col_names = [
        "path",
        "mtime",
        "mtime_paris_epoch",
        "ext",
        "kind",
        "basename",
        "thumbnail_path",
        "match_id",
        "match_start_time",
        "association_confidence",
        "xuid",
    ]
    try:
        import duckdb

        conn = duckdb.connect(db_path, read_only=True)
        try:
            # V√©rifier si les tables existent
            tables = conn.execute(
                """
                SELECT table_name
                FROM information_schema.tables
                WHERE table_schema = 'main'
                AND table_name = 'media_files'
                """
            ).fetchall()

            if not tables:
                return pl.DataFrame()

            # Charger les m√©dias avec leurs associations.
            # Si xuid est fourni, on accepte mma.xuid = xuid OU mma.xuid = gamertag
            # (l'indexeur peut stocker le gamertag en fallback quand sync_meta n'a pas de xuid).
            if xuid or gamertag:
                # Inclure les associations que l'indexeur a stock√©es avec xuid OU gamertag (fallback).
                uids = [u for u in (xuid, gamertag) if u]
                uids = list(dict.fromkeys(uids))  # d√©dupliquer
                if not uids:
                    uid_filter = "1=0"
                    params: list[str] = []
                elif len(uids) == 1:
                    uid_filter = "mma.xuid = ?"
                    params = [uids[0]]
                else:
                    uid_filter = "(mma.xuid = ? OR mma.xuid = ?)"
                    params = list(uids[:2])
                result = conn.execute(
                    f"""
                    SELECT DISTINCT
                        mf.file_path AS path,
                        mf.mtime,
                        mf.mtime_paris_epoch,
                        mf.file_ext AS ext,
                        mf.kind,
                        mf.file_name AS basename,
                        mf.thumbnail_path,
                        mma.match_id,
                        mma.match_start_time,
                        mma.association_confidence,
                        mma.xuid
                    FROM media_files mf
                    LEFT JOIN media_match_associations mma
                        ON mf.file_path = mma.media_path
                        AND ({uid_filter})
                    ORDER BY mf.mtime_paris_epoch DESC
                    """,
                    params,
                ).fetchall()
            else:
                # Charger tous les m√©dias avec toutes leurs associations
                result = conn.execute(
                    """
                    SELECT DISTINCT
                        mf.file_path AS path,
                        mf.mtime,
                        mf.mtime_paris_epoch,
                        mf.file_ext AS ext,
                        mf.kind,
                        mf.file_name AS basename,
                        mf.thumbnail_path,
                        mma.match_id,
                        mma.match_start_time,
                        mma.association_confidence,
                        mma.xuid
                    FROM media_files mf
                    LEFT JOIN media_match_associations mma
                        ON mf.file_path = mma.media_path
                    ORDER BY mf.mtime_paris_epoch DESC
                    """
                ).fetchall()

            if not result:
                return pl.DataFrame()

            # Construire un pl.DataFrame √† partir des tuples
            rows = [dict(zip(_col_names, row, strict=False)) for row in result]
            return pl.DataFrame(rows)

        finally:
            conn.close()

    except Exception:
        return pl.DataFrame()


def render_media_library_page(*, df_full: DataFrameLike, settings: AppSettings) -> None:
    """Rend la page Biblioth√®que m√©dias."""
    st.subheader("Biblioth√®que m√©dias")

    if not bool(getattr(settings, "media_enabled", True)):
        st.info("Les m√©dias sont d√©sactiv√©s dans Param√®tres ‚Üí M√©dias.")
        return

    dirs = _coerce_dirs(settings)
    if not dirs.screens_dir and not dirs.videos_dir:
        st.info("Configure au moins un dossier dans Param√®tres ‚Üí M√©dias (captures et/ou vid√©os).")
        return

    # R√©cup√©rer le XUID du joueur actuel
    db_path = st.session_state.get("db_path", "")
    xuid_input = st.session_state.get("xuid_input", "")

    # R√©soudre le XUID
    from src.app.profile import resolve_xuid
    from src.app.state import get_default_identity

    identity = get_default_identity()
    xuid = (
        resolve_xuid(xuid_input or "JGtm", db_path, identity)
        or identity.xuid
        or identity.xuid_fallback
    )

    with st.expander("Options", expanded=True):
        c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
        group_by_match = c1.toggle("Grouper par match", value=True)
        show_unassigned = c2.toggle("Afficher non associ√©s", value=True)
        cols_per_row = c3.slider("Colonnes", min_value=2, max_value=6, value=4, step=1)
        max_items = c4.slider("Max m√©dias", min_value=50, max_value=2000, value=400, step=50)

        kinds = st.multiselect(
            "Types",
            options=["image", "video"],
            default=["image", "video"],
        )
        name_filter = st.text_input("Filtre nom de fichier", value="", placeholder="ex: 2026-01")

        col_scan, col_thumbs = st.columns(2)
        with col_scan:
            if st.button("Re-scanner les dossiers", width="stretch"):
                with contextlib.suppress(Exception):
                    index_media_dir.clear()
                # Forcer re-indexation en BDD
                if "_media_indexing_started" in st.session_state:
                    del st.session_state["_media_indexing_started"]

                # Lancer l'indexation manuellement si DB DuckDB disponible
                if db_path and db_path.endswith(".duckdb"):
                    try:
                        from pathlib import Path

                        from src.data.media_indexer import MediaIndexer

                        videos_path = (
                            Path(dirs.videos_dir)
                            if dirs.videos_dir and os.path.exists(dirs.videos_dir)
                            else None
                        )
                        screens_path = (
                            Path(dirs.screens_dir)
                            if dirs.screens_dir and os.path.exists(dirs.screens_dir)
                            else None
                        )

                        if videos_path or screens_path:
                            with st.spinner("Indexation en cours..."):
                                indexer = MediaIndexer(Path(db_path))
                                result = indexer.scan_and_index(
                                    videos_dir=videos_path,
                                    screens_dir=screens_path,
                                    force_rescan=True,
                                )
                                tolerance = int(
                                    getattr(settings, "media_tolerance_minutes", 5) or 5
                                )
                                n_associated = indexer.associate_with_matches(
                                    tolerance_minutes=tolerance
                                )
                                n_thumb_gen, n_thumb_err = 0, 0
                                if videos_path:
                                    n_thumb_gen, n_thumb_err = indexer.generate_thumbnails_for_new(
                                        videos_path
                                    )
                                msg = (
                                    f"Indexation termin√©e: {result.n_new} nouveaux, "
                                    f"{result.n_updated} mis √† jour, {n_associated} association(s)"
                                )
                                if n_thumb_gen or n_thumb_err:
                                    msg += f" ‚Äî {n_thumb_gen} thumbnail(s), {n_thumb_err} erreur(s)"
                                st.success(msg)
                    except Exception as e:
                        st.error(f"Erreur lors de l'indexation: {e}")

                st.rerun()

        with col_thumbs:
            if st.button(
                "G√©n√©rer les thumbnails",
                width="stretch",
                help="G√©n√®re les miniatures pour les vid√©os sans thumbnail (ind√©pendant des associations)",
            ):
                if (
                    db_path
                    and db_path.endswith(".duckdb")
                    and dirs.videos_dir
                    and os.path.exists(dirs.videos_dir)
                ):
                    try:
                        from pathlib import Path

                        from src.data.media_indexer import MediaIndexer

                        with st.spinner("G√©n√©ration des thumbnails..."):
                            indexer = MediaIndexer(Path(db_path))
                            n_gen, n_err = indexer.generate_thumbnails_for_new(
                                Path(dirs.videos_dir)
                            )
                            st.success(
                                f"{n_gen} thumbnail(s) g√©n√©r√©(s)"
                                + (f", {n_err} erreur(s)" if n_err else "")
                            )
                    except Exception as e:
                        st.error(f"Erreur: {e}")
                    st.rerun()
                else:
                    st.warning("Configure un dossier vid√©os dans Param√®tres ‚Üí M√©dias.")

    # Charger depuis BDD si disponible
    media_df = pl.DataFrame()
    using_db = False
    windows_df = pl.DataFrame()  # Initialiser pour le diagnostic
    if db_path and db_path.endswith(".duckdb"):
        # Charger les m√©dias avec associations pour le joueur actuel (ou tous si xuid=None)
        gamertag = _gamertag_from_db_path(db_path)
        media_df = _load_media_from_db(db_path, xuid=xuid, gamertag=gamertag)
        using_db = not media_df.is_empty()

    # Fallback sur scan disque si BDD vide
    if media_df.is_empty():
        media_df = _index_all_media(settings)
        # Si on a scann√© depuis disque, on peut essayer d'associer avec les matchs
        if not media_df.is_empty():
            windows_df = _compute_match_windows(df_full, settings)
            assoc_df = _associate_media_to_matches(media_df, windows_df)
        else:
            assoc_df = pl.DataFrame()
    else:
        # Les associations sont d√©j√† dans la BDD
        assoc_df = media_df.clone()
        # S'assurer que match_id est bien pr√©sent m√™me si NULL
        if "match_id" not in assoc_df.columns:
            assoc_df = assoc_df.with_columns(pl.lit(None).alias("match_id"))
        if "match_start_time" not in assoc_df.columns:
            assoc_df = assoc_df.with_columns(pl.lit(None).alias("match_start_time"))
        # Calculer windows_df pour le diagnostic depuis la DB des m√©dias (pas df_full)
        # car l'association se fait depuis toutes les DBs joueurs, pas seulement celle du joueur actuel
        windows_df = _load_match_windows_from_db(db_path) if db_path else pl.DataFrame()

    # Diagnostic : afficher info si m√©dias non associ√©s depuis BDD
    if using_db and not assoc_df.is_empty():
        unassigned_count = assoc_df["match_id"].is_null().sum()
        if unassigned_count > 0:
            st.info(
                f"‚ÑπÔ∏è {unassigned_count} m√©dia(s) non associ√©(s) depuis la BDD. "
                "Cliquez sur 'Re-scanner les dossiers' pour forcer l'indexation et l'association."
            )

    if assoc_df.is_empty():
        st.info("Aucun m√©dia trouv√©.")
        return

    assoc_df = assoc_df.head(int(max_items))

    if kinds:
        assoc_df = assoc_df.filter(pl.col("kind").is_in([str(k) for k in kinds]))

    if name_filter.strip():
        nf = name_filter.strip().lower()
        assoc_df = assoc_df.filter(
            pl.col("basename").cast(pl.Utf8).str.to_lowercase().str.contains(nf, literal=True)
        )

    assigned = assoc_df.filter(pl.col("match_id").is_not_null())
    unassigned = assoc_df.filter(pl.col("match_id").is_null())

    # D√âDUPLIQUER : Un m√©dia peut avoir plusieurs associations (multi-joueurs)
    # On garde une seule ligne par m√©dia/match pour l'affichage
    if not assigned.is_empty():
        assigned = assigned.unique(subset=["path", "match_id"], keep="first")
    if not unassigned.is_empty():
        unassigned = unassigned.unique(subset=["path"], keep="first")

    # Diagnostic unifi√© : afficher un seul message informatif
    if not using_db:
        # Si on utilise le scan disque (fallback), informer l'utilisateur
        st.info(
            "‚ÑπÔ∏è Les m√©dias sont charg√©s depuis le scan disque (pas encore index√©s en BDD). "
            "Cliquez sur 'Re-scanner les dossiers' pour indexer en BDD et associer automatiquement."
        )
    elif windows_df.is_empty() and assigned.is_empty():
        # Afficher le warning seulement si on n'a AUCUNE association ET que windows_df est vide
        # (si on a d√©j√† des associations, pas besoin d'afficher ce message)
        st.warning(
            "‚ö†Ô∏è Aucune fen√™tre temporelle de match disponible pour l'association.\n\n"
            "**Causes possibles :**\n"
            "- Aucun match avec `start_time` valide dans les DBs joueurs\n"
            "- Les matchs n'ont pas √©t√© synchronis√©s correctement\n"
            "- Probl√®me de conversion de dates/timezone\n\n"
            "**Solution :**\n"
            "1. V√©rifier que les matchs ont bien des dates de d√©part (`start_time`)\n"
            "2. Cliquer sur 'Re-scanner les dossiers' pour forcer l'association\n"
            "3. V√©rifier les logs pour plus de d√©tails"
        )
    elif assigned.is_empty() and not unassigned.is_empty() and using_db:
        # Seulement afficher ce message si windows_df n'est pas vide et qu'on utilise la BDD
        tolerance = int(getattr(settings, "media_tolerance_minutes", 5) or 5)
        st.warning(
            f"‚ö†Ô∏è Aucun m√©dia n'a pu √™tre associ√© √† un match depuis la BDD. "
            f"Tol√©rance actuelle: {tolerance} min. "
            "Essayez d'augmenter la tol√©rance dans Param√®tres ‚Üí M√©dias ou v√©rifiez que les dates des matchs correspondent."
        )

    # Affichage
    if not group_by_match:
        _render_media_grid(assoc_df, cols_per_row=int(cols_per_row), render_context="all")
        return

    if not assigned.is_empty():
        # Tri: match le plus r√©cent d'abord, puis m√©dias par ordre chronologique (mtime asc)
        assigned = assigned.with_columns(
            pl.col("match_start_time").cast(pl.Datetime, strict=False).alias("_match_sort")
        )
        assigned = assigned.sort(["_match_sort", "mtime"], descending=[True, False])

        for match_id, g in assigned.group_by("match_id", maintain_order=True):
            match_id_val = match_id[0] if isinstance(match_id, tuple) else match_id
            title_dt = None
            try:
                dt0 = g["match_start_time"][0]
                title_dt = format_datetime_fr_hm(dt0) if dt0 is not None else None
            except Exception:
                title_dt = None

            label = f"Match {match_id_val}" + (" ‚Äî " + str(title_dt) if title_dt else "")
            with st.expander(label, expanded=False):
                _open_match_button(str(match_id_val))
                g2 = g.sort("mtime", descending=False)
                # D√©dupliquer une derni√®re fois par s√©curit√© (au cas o√π plusieurs xuid pour m√™me m√©dia/match)
                g2 = g2.unique(subset=["path"], keep="first")
                _render_media_grid(
                    g2, cols_per_row=int(cols_per_row), render_context=f"match_{match_id_val}"
                )

    if show_unassigned and not unassigned.is_empty():
        st.divider()
        st.subheader("Non associ√©s")
        _render_media_grid(unassigned, cols_per_row=int(cols_per_row), render_context="unassigned")
