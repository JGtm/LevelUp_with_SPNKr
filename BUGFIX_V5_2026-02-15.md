# Corrections V5 - 15 f√©vrier 2026

## Bugs critiques corrig√©s ‚úÖ

### 1. Crash antagonistes (AttributeError: 'dict' object has no attribute 'rank')

**Fichier** : `src/analysis/killer_victim.py`

**Erreur** :
```python
# Ligne 383 - Acc√®s incorrect √† un TypedDict
rank_by_xuid[s.xuid] = s.rank  # ‚ùå CRASH
```

**Cause** : `MatchPlayerStats` est un `TypedDict`, pas une classe. L'acc√®s aux attributs avec `.` ne fonctionne pas.

**Solution** :
```python
# Utiliser la notation dict
rank_by_xuid[s["xuid"]] = s["rank"]  # ‚úÖ
```

**Lignes modifi√©es** :
- Ligne 166 : `{s["xuid"]: s for s in official_stats}`
- Ligne 217-218 : `s["xuid"] == xuid` et `return s["rank"]`
- Ligne 383 : `rank_by_xuid[s["xuid"]] = s["rank"]`
- Ligne 612 : `s["xuid"] == me`
- Ligne 616-617 : `my_official["kills"]` et `my_official["deaths"]`

---

### 2. Crash path_picker m√©dias (StreamlitAPIException)

**Fichier** : `src/ui/path_picker.py`

**Erreur** :
```
StreamlitAPIException: `st.session_state.settings_media_captures_base_dir__text` 
cannot be modified after the widget is instantiated.
```

**Cause** : Le path_picker avait un navigateur de fichiers ultra-complexe (5 boutons, 4 champs, s√©lecteurs de lecteurs, etc.) qui cr√©ait des conflits de session_state.

**Solution** : Simplification drastique - suppression du navigateur, champ simple :
```python
def directory_input(...) -> str:
    text_key = f"{key}__text"
    if text_key not in st.session_state:
        st.session_state[text_key] = str(value or "")
    
    path_value = st.text_input(
        label,
        value=st.session_state[text_key],
        key=text_key,
        help="Collez le chemin absolu du dossier",
        placeholder="C:\\Users\\...\\Videos",
    )
    return str(path_value or "").strip()
```

**M√™me simplification pour** : `file_input()`

---

### 3. Graphe "Rang et score personnel" avec titre "undefined"

**Fichier** : `src/ui/pages/timeseries.py`

**Erreur** :
```python
fig_rank = plot_rank_score(dff, title=None)  # ‚ùå Pas de titre
```

**Solution** :
```python
fig_rank = plot_rank_score(dff, title="Rang et score personnel")  # ‚úÖ
```

**Ligne** : 521

---

### 4. Colonne `rank` manquante dans les DataFrames

**Fichier** : `src/data/repositories/_match_queries.py`

**Probl√®me** : La colonne `rank` (classement du joueur dans le match) n'√©tait pas r√©cup√©r√©e depuis `match_participants`, donc `undefined` dans les graphes.

**Solution** : Ajout d'un JOIN avec `match_participants` dans `load_matches_as_polars()` :

```python
# JOIN pour r√©cup√©rer le rank du joueur principal
my_xuid = str(self.xuid or "").strip()
rank_join = ""
rank_select = "NULL as rank"
if my_xuid:
    rank_join = f"""
        LEFT JOIN match_participants mp_rank
        ON match_stats.match_id = mp_rank.match_id
        AND mp_rank.xuid = '{my_xuid}'
    """
    rank_select = "mp_rank.rank"

# Dans le SELECT
all_select_exprs = f"""
    ...
    {personal_score_select},
    {rank_select}
"""

# Dans le FROM
sql = f"""
    SELECT {all_select_exprs}
    FROM {source_sql}{metadata_joins}{pms_join}{rank_join}
    WHERE {where_sql}
    ORDER BY match_stats.start_time ASC
"""
```

**Lignes modifi√©es** : 908-960, 970, 980

---

### 5. Citations manquantes (48 attendues ‚Üí ~20 affich√©es) ‚ö†Ô∏è R√âGRESSION MAJEURE vs V3

**Fichiers** : 
- `src/ui/commendations.py`
- `src/analysis/citations/engine.py`
- `src/ui/pages/citations.py`

**Probl√®me** : 
1. Deux filtres restrictifs cachaient les citations
2. **Le compteur delta "+XXX" (comme v3) a √©t√© RETIR√â** ‚ùå
3. **L'utilisateur devrait avoir exactement 48 citations, pas ~20**
4. **R√âGRESSION CRITIQUE** : Les modifications ont cass√© l'affichage de la v3

**D√©couvertes** :
- JSON source (`halo5_commendations_fr.json`) : **159 citations**
- Table `citation_mappings` : **14 entr√©es seulement**
- Nombre attendu par l'utilisateur : **48 citations**

**Fixes appliqu√©s (mais aggravation de la situation !)** :

1. **Dans commendations.py (ligne 416)** : Filtrage par mappings
```python
# ‚ùå AVANT - Ne gardait que les citations avec mapping
mapped_norms = set(citation_mappings.keys())
items = [it for it in items if _has_mapping(it)]
```

**Solution appliqu√©e** : Suppression du filtre
```python
# ‚úÖ APR√àS - Affiche toutes les citations du JSON
# SUPPRIM√â : filtrage par mapping
```

2. **Dans engine.py (ligne 164)** : Filtrage par `enabled`
```python
# ‚ùå AVANT
WHERE enabled IS NOT FALSE  # Cachait les citations d√©sactiv√©es
```

**Solution appliqu√©e** :
```python
# ‚úÖ APR√àS - Charge TOUTES les citations
# SUPPRIM√â : WHERE enabled IS NOT FALSE
```

**MAIS : R√©sultat catastrophique apr√®s les "corrections" !!** üò°

### Comportement apr√®s "corrections" (v5 actuelle) vs V3

| Aspect | V3 (fonctionnel) | V5 (cass√©) |
|--------|------------------|------------|
| **Section affich√©e** | Citations avec progression r√©elle | "Citations (Commendations Halo 5)" - **Section inutile que l'utilisateur ne veut PAS** |
| **Metrics affich√©es** | Delta visible (+XXX) | "Citations obtenues" et "Matchs analys√©s" - **M√©triques inutiles** |
| **Progression** | Affichait les citations avec progression OK (ex: 5/10, 8/25) | **TOUTES √† 0/XXXX** - Progression compl√®tement perdue |
| **Filtrage** | Affichait uniquement les citations pertinentes | Affiche 159 citations dont la plupart non pertinentes |
| **Compteur delta** | Pr√©sent et visible | **RETIR√â** ‚ùå |
| **Total citations** | 48 citations pertinentes | 0 progression sur toutes |

### Probl√®mes critiques post-correction

1. ‚ùå **Toutes les progressions affichent 0/XXXX** : Plus aucune donn√©e de progression r√©elle
2. ‚ùå **Compteur delta RETIR√â** : Le "+XXX" qui indiquait le nombre de nouvelles citations a disparu
3. ‚ùå **Mauvaise section affich√©e** : La section "Citations (Commendations Halo 5)" n'est PAS celle que l'utilisateur veut
4. ‚ùå **Metrics inutiles** : "Citations obtenues" et "Matchs analys√©s" ne servent √† rien
5. ‚ùå **Perte de donn√©es** : Les progressions r√©elles (5/10, 8/25, etc.) ont compl√®tement disparu
6. ‚ùå **Affichage pollution** : 159 citations affich√©es au lieu des 48 pertinentes avec progression

### Cause racine identifi√©e

**Les "corrections" ont supprim√© les filtres SANS restaurer les donn√©es de progression** :
- En v3 : `citation_mappings` contenait 48 entr√©es avec progression r√©elle
- En v5 : `citation_mappings` ne contient que 14 entr√©es (donn√©es perdues ?)
- La suppression du filtre affiche maintenant 159 items du JSON **mais sans aucune progression**

### Ce qui doit √™tre fait (pas encore impl√©ment√©)

1. **Restaurer la section correcte** : Pas "Citations (Commendations Halo 5)" mais la section qui affiche les progressions r√©elles
2. **Re-remplir `citation_mappings`** : Passer de 14 √† 48 entr√©es avec les vraies progressions
3. **Restaurer le compteur delta** : Afficher "+XXX" comme en v3
4. **Afficher les progressions r√©elles** : 5/10, 8/25, etc. au lieu de 0/XXXX
5. **Filtrer intelligemment** : Afficher les 48 citations pertinentes, pas les 159 du JSON

**Conclusion** : **PUTAIN DE R√âGRESSION PAR RAPPORT √Ä LA V3** üò°
- Les "corrections" ont empir√© la situation au lieu de la r√©soudre
- L'utilisateur a perdu toutes ses progressions de citations
- Section inutile affich√©e, metrics inutiles, plus aucune donn√©e pertinente

---

### 6. Compteurs totaux manquants (Citations & M√©dailles)

**Fichier** : `src/ui/pages/citations.py`

**Probl√®me** : Pas de metrics affichant les totaux.

**Solution** : Ajout de metrics `st.metric()` :

```python
# Citations
total_citations_count = sum(citations_full.values())
cols_metrics = st.columns(3)
with cols_metrics[0]:
    st.metric("Citations obtenues", f"{total_citations_count:,}")
with cols_metrics[1]:
    st.metric("Matchs analys√©s", len(dff))

# M√©dailles
total_medals_distinct = len(counts_by_medal)
total_medals_count = sum(counts_by_medal.values())
cols_medals = st.columns(3)
with cols_medals[0]:
    st.metric("M√©dailles distinctes", total_medals_distinct)
with cols_medals[1]:
    st.metric("Total m√©dailles", f"{total_medals_count:,}")
with cols_medals[2]:
    st.metric("Matchs analys√©s", len(dff))
```

---

## Probl√®mes identifi√©s (non r√©solus)

### ‚ö†Ô∏è Performance - Graphes lents

**Sympt√¥me** : Les graphes mettent une √©ternit√© √† charger.

**Causes probables** :
1. Requ√™tes SQL avec trop de jointures
2. Pas de cache des DataFrames enrichis
3. Conversions Polars ‚Üî Python r√©p√©t√©es
4. Pas d'index sur les colonnes fr√©quemment join√©es

**Action recommand√©e** :
```bash
# Profiler les requ√™tes lentes
python -c "
import duckdb
conn = duckdb.connect('data/players/Chocoboflor/stats.duckdb')
# Activer le profiling
conn.execute('PRAGMA enable_profiling')
# Ex√©cuter une requ√™te lente
conn.execute('EXPLAIN ANALYZE SELECT ...')
"
```

---

### ‚ö†Ô∏è DB passe √† "0 matchs" au d√©marrage et al√©atoirement

**Sympt√¥mes observ√©s** :
1. **Au lancement de l'app** :
   - Se positionne sur "Chocoboflor"
   - Affiche le message **"aucune DB n'est s√©lectionn√©e"**
   - La liste d√©roulante indique **"0"** (au lieu du nombre de matchs)
2. **Al√©atoirement pendant l'utilisation** :
   - Le s√©lecteur passe de "XXX matchs" √† "0 matchs"

**Fichiers concern√©s** :
- `src/ui/multiplayer.py` (ligne 217) : `list_duckdb_v4_players()`
- Sidebar de l'app principale

**Causes probables** : 
- Cache Streamlit `@st.cache_data` non invalid√© correctement
- Race condition entre `db_key` (mtime) et `cache_buster`
- Chargement asynchrone de la liste des joueurs qui √©choue silencieusement

**Workaround actuel** : Rerun manuel de l'app (F5 ou bouton "Rerun")

**Solution √† investiguer** :
1. Forcer `st.cache_data.clear()` apr√®s sync
2. V√©rifier `list_duckdb_v4_players()` dans `src/ui/multiplayer.py:217`
3. Ajouter des logs de debug pour tracer le chargement des profils
4. V√©rifier que `db_profiles.json` est bien lu au d√©marrage
5. Tracer l'√©tat de `st.session_state.player_profile` au lancement

---

### ‚ö†Ô∏è Crash antagonistes - Ligne 625 non corrig√©e (TypedDict)

**Fichier** : `src/analysis/killer_victim.py` (ligne 625)

**Sympt√¥me** : 
- Onglet "Dernier match" ‚Üí Section antagonistes crash
- Message d'erreur : **`AttributeError: 'dict' object has no attribute 'kills'`**

**Stack trace** :
```python
File "C:\Users\Guillaume\Downloads\Scripts\LevelUp\src\analysis\killer_victim.py", line 625, in compute_personal_antagonists
    f"kills: {my_kills_assigned_total} vs {my_official.kills} ({kills_diff:+d})"
                                           ^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'kills'
```

**Cause** : 
- **Ligne 625 non corrig√©e** : `my_official.kills` au lieu de `my_official["kills"]`
- **Ligne 628 probablement aussi** : `my_official.deaths` au lieu de `my_official["deaths"]`
- M√™me probl√®me que les lignes 166, 217-218, 383, 612, 616-617 (d√©j√† corrig√©es)

**Code incorrect (lignes 625-628)** :
```python
# ‚ùå Acc√®s TypedDict avec notation objet
f"kills: {my_kills_assigned_total} vs {my_official.kills} ({kills_diff:+d})"
...
f"deaths: {my_deaths_assigned_total} vs {my_official.deaths} ({deaths_diff:+d})"
```

**Correction n√©cessaire** :
```python
# ‚úÖ Utiliser la notation dict
f"kills: {my_kills_assigned_total} vs {my_official['kills']} ({kills_diff:+d})"
...
f"deaths: {my_deaths_assigned_total} vs {my_official['deaths']} ({deaths_diff:+d})"
```

**Impact** : **Onglet "Dernier match" inutilisable** - crash syst√©matique lors de l'affichage des antagonistes.

---

### ‚ö†Ô∏è Stats d√©taill√©es indisponibles dans "Dernier match"

**Fichier** : Probablement `src/ui/pages/last_match.py` ou `match_view.py`

**Sympt√¥me** : 
- Onglet "Dernier match"
- Message affich√© : **"Stats d√©taill√©es indisponibles pour ce match (PlayerMatchStats manquant ou format inattendu)."**

**Cause probable** :
- Donn√©es `PlayerMatchStats` non charg√©es depuis la DB
- Probl√®me de jointure avec `match_participants` ou table enrichissement
- Format de donn√©es incompatible entre v4 et v5

**Action recommand√©e** :
```sql
-- V√©rifier que les stats existent pour le dernier match
SELECT match_id, COUNT(*) as nb_players
FROM match_participants
WHERE match_id = (SELECT match_id FROM match_stats ORDER BY start_time DESC LIMIT 1)
GROUP BY match_id;
```

---

### ‚ö†Ô∏è M√©dias sans correspondance pour le joueur "JGtm"

**Sympt√¥me** : 
- M√©dias (captures/films) sans correspondance avec les matchs de JGtm
- Probablement affich√©s dans l'onglet m√©dias ou dernier match

**Causes probables** :
1. **Fichiers m√©dias orphelins** : pr√©sents sur disque mais pas de `match_id` correspondant en DB
2. **Probl√®me de mapping XUID** : JGtm a chang√© de gamertag ou XUID non r√©solu
3. **Sync incomplet** : m√©dias t√©l√©charg√©s mais matchs non synchronis√©s
4. **Format de nom de fichier incorrect** : parsing du `match_id` depuis le nom √©choue

**Fichiers concern√©s** :
- `scripts/index_media.py` : Indexation des m√©dias
- `src/ui/pages/media.py` : Affichage des m√©dias
- Table `xuid_aliases` : Mapping gamertag ‚Üî XUID

**Action recommand√©e** :
```bash
# V√©rifier les m√©dias orphelins pour JGtm
python scripts/index_media.py --check-orphans --gamertag JGtm

# V√©rifier le mapping XUID
python -c "
import duckdb
conn = duckdb.connect('data/warehouse/metadata.duckdb')
result = conn.execute(\"SELECT * FROM xuid_aliases WHERE gamertag = 'JGtm'\").fetchall()
print(result)
"
```

---

### ‚ö†Ô∏è Onglet "Co√©quipiers" - Multiples probl√®mes de donn√©es

**Fichier** : `src/ui/pages/teammates.py`

#### 1. Section "‚ö° Impact & Taquinerie" - Crash SQL

**Sympt√¥me** :
- Section "‚ö° Impact & Taquinerie" n'affiche rien
- Texte : "Qui fait le premier sang üü¢, finit les victoires (Finisseur) üü°, ou meurt en dernier lors des d√©faites (Boulet) üî¥ ?"
- Message d'erreur : **"Impossible de charger les donn√©es d'impact"**

**Erreur SQL** :
```
Catalog Error: Table with name highlight_events does not exist! 
Did you mean "shared.highlight_events"?
LINE 3: FROM highlight_events ^
```

**Cause** : 
- Requ√™te SQL r√©f√©rence `highlight_events` au lieu de `shared.highlight_events`
- Probl√®me de nom de table depuis migration v5 (tables partag√©es dans `shared_matches.duckdb`)

**Correction n√©cessaire** :
```sql
-- ‚ùå AVANT
FROM highlight_events

-- ‚úÖ APR√àS
FROM shared.highlight_events
-- OU si pas d'ATTACH :
FROM 'data/warehouse/shared_matches.duckdb'.highlight_events
```

**Fichiers concern√©s** :
- Probablement dans `src/ui/pages/teammates.py` ou un module d'analyse
- V√©rifier toutes les requ√™tes SQL qui utilisent `highlight_events`, `match_participants`, `medals_earned` sans pr√©fixe `shared.`

---

#### 2. Graphes avec donn√©es incorrectes - Lignes plates

**Sympt√¥me** :
- Graphes **"Folies meurtri√®res (max)"**, **"Tirs √† la t√™te"**, **"Frag parfaits"** 
- N'ont pas l'air de r√©cup√©rer les bonnes donn√©es
- Affichage : **lignes plates avec seulement un ou deux barres** (au lieu de variations normales)

**Causes probables** :
1. **Donn√©es NULL ou 0** : Colonnes non remplies (backfill manquant)
2. **Agr√©gation incorrecte** : Calcul de MAX() ou AVG() sur mauvaise colonne
3. **Filtre trop restrictif** : Ne garde que quelques matchs au lieu de tous
4. **Jointure √©chou√©e** : Donn√©es de co√©quipiers non r√©cup√©r√©es depuis leurs DBs

**Colonnes concern√©es** :
- `killing_spree_max` ou `max_killing_spree` (folies meurtri√®res)
- `headshots` (tirs √† la t√™te)
- `perfect_kills` (frag parfaits)

**Action recommand√©e** :
```sql
-- V√©rifier que les colonnes sont remplies
SELECT 
    COUNT(*) as total,
    COUNT(max_killing_spree) as with_spree,
    COUNT(headshots) as with_headshots,
    COUNT(perfect_kills) as with_perfect
FROM match_stats
WHERE xuid = '<xuid_coequipier>';

-- V√©rifier les valeurs pour un co√©quipier
SELECT gamertag, match_id, max_killing_spree, headshots, perfect_kills
FROM match_stats
WHERE xuid = '<xuid_coequipier>'
ORDER BY start_time DESC
LIMIT 20;
```

---

#### 3. Profils de participation trop similaires - Donn√©es suspectes

**Sympt√¥me** :
- Section "Profils de participation" affiche des graphes **affreusement similaires** entre co√©quipiers
- Ce n'est probablement **pas correct**
- Normalement : co√©quipiers ont vraiment des **niveaux et comp√©tences diff√©rents**
- Observation : graphes radar quasi identiques, pas de variance

**Causes probables** :
1. **Donn√©es moyenn√©es** : Affiche la moyenne globale au lieu des stats individuelles de chaque co√©quipier
2. **Mauvaise source de donn√©es** : Charge les stats du joueur principal au lieu de celles du co√©quipier
3. **Normalisation excessive** : Toutes les valeurs normalis√©es sur la m√™me √©chelle ‚Üí perd les diff√©rences
4. **Agr√©gation incorrecte** : GROUP BY mal construit, m√©lange les xuids

**Exemple attendu vs observ√©** :

| Co√©quipier | KD attendu | Pr√©cision attendue | Observ√© (suspicieux) |
|------------|------------|-------------------|---------------------|
| Joueur A (bon) | 1.5 | 55% | 1.2, 50% (aplati) |
| Joueur B (moyen) | 0.8 | 45% | 1.2, 50% (aplati) |
| Joueur C (d√©butant) | 0.5 | 35% | 1.2, 50% (aplati) |

**Action recommand√©e** :
```python
# Dans teammates.py - V√©rifier la source des donn√©es
# Probablement un code du type :
stats_coequipier = load_df_optimized(MY_DB_PATH, my_xuid)  # ‚ùå Mauvais xuid
# Au lieu de :
stats_coequipier = load_df_optimized(TEAMMATE_DB_PATH, teammate_xuid)  # ‚úÖ
```

**Impact** : 
- **Graphes inutiles** : Ne donnent aucune information pertinente sur les diff√©rences de style/niveau
- **Perte de valeur analytique** : Impossible de voir qui est meilleur/pire dans quels domaines

---

### ‚ö†Ô∏è Filtre par sessions ne fonctionne pas

**Sympt√¥me** : 
- Lors de la s√©lection d'une ou plusieurs sessions dans les filtres
- Affiche le message : **"Aucun match √† afficher. V√©rifiez vos filtres ou synchronisez les donn√©es."**
- Alors que des matchs existent pour cette session

**Fichiers concern√©s** :
- `src/ui/filters.py` : Logique de filtrage par session
- `src/data/repositories/_match_queries.py` : Requ√™tes SQL avec filtres
- Tables : `player_match_enrichment` (contient `session_id` et `session_label`)

**Causes probables** :
1. **Colonne `session_id` manquante** dans les DataFrames retourn√©s
2. **Jointure incorrecte** entre `match_stats` et `player_match_enrichment` 
3. **Filtre SQL mal construit** pour les sessions (WHERE IN avec liste vide ?)
4. **Backfill sessions non effectu√©** : donn√©es `session_id` NULL ou absentes

**Action recommand√©e** :
```sql
-- V√©rifier que les sessions sont bien remplies
SELECT 
    COUNT(*) as total_matches,
    COUNT(session_id) as matches_with_session,
    COUNT(DISTINCT session_id) as unique_sessions
FROM player_match_enrichment;

-- Voir quelques exemples
SELECT match_id, session_id, session_label 
FROM player_match_enrichment 
LIMIT 10;
```

**Debug dans le code** :
```python
# Dans src/ui/filters.py - Ajouter logging
if selected_sessions:
    logger.info(f"Filtrage par sessions: {selected_sessions}")
    logger.info(f"DataFrame avant filtre: {len(df)} matchs")
    df_filtered = df.filter(pl.col("session_id").is_in(selected_sessions))
    logger.info(f"DataFrame apr√®s filtre: {len(df_filtered)} matchs")
```

---

### ‚ö†Ô∏è Modes et cartes automatiquement d√©s√©lectionn√©s lors du changement de p√©riode

**Sympt√¥me** : 
- Lors de la s√©lection d'une p√©riode pr√©cise (ex: 27/11/2025 - 12/02/2026)
- **Certains modes et cartes sont automatiquement d√©s√©lectionn√©s** sans intervention de l'utilisateur
- Exemple observ√© :
  - Modes : **19/22** (3 modes d√©s√©lectionn√©s automatiquement)
  - Cartes : **48/54** (6 cartes d√©s√©lectionn√©es automatiquement)
- L'utilisateur n'a rien touch√© aux filtres Modes/Cartes

**Fichiers concern√©s** :
- `src/ui/filters.py` : Logique de construction des filtres
- Composants Streamlit expander pour Playlists/Modes/Cartes

**Causes probables** :
1. **Filtrage automatique des options vides** : Le code filtre les modes/cartes qui n'ont aucun match dans la p√©riode s√©lectionn√©e
2. **R√©initialisation de session_state** : Changement de p√©riode d√©clenche un reset des s√©lections
3. **Logique de "smart filtering"** mal con√ßue qui d√©s√©lectionne automatiquement
4. **√âtat des checkboxes non persist√©** lors du rerender

**Comportement attendu** :
- Quand on change la p√©riode, les filtres Modes/Cartes **doivent rester "Tous" s√©lectionn√©s** par d√©faut
- Si l'utilisateur a explicitement d√©s√©lectionn√© certains items, **conserver son choix**
- Ne **jamais** d√©s√©lectionner automatiquement sans action de l'utilisateur

**Action recommand√©e** :
```python
# Dans src/ui/filters.py - V√©rifier la logique de s√©lection
# Probablement un code du type:
available_modes = df.select("mode").unique()  # ‚ùå Ne garde que les modes pr√©sents
# Au lieu de:
all_modes = get_all_modes_from_metadata()  # ‚úÖ Tous les modes, m√™me si 0 match
```

**Impact utilisateur** : **Comportement d√©routant et frustrant** - l'utilisateur doit recliquer sur "Tous" √† chaque changement de p√©riode.

---

### ‚ö†Ô∏è Donn√©es carri√®re absentes

**Sympt√¥me** : Pas de donn√©es de carri√®re affich√©es.

**Tables concern√©es** : `career_progression`

**Action recommand√©e** :
```sql
-- V√©rifier que la table existe et contient des donn√©es
SELECT COUNT(*) FROM career_progression;
SELECT * FROM career_progression ORDER BY recorded_at DESC LIMIT 5;
```

---

## Recommandations

### Court terme (fixes urgents)

1. ‚úÖ **Tester l'app** pour v√©rifier que les crashs sont r√©solus
2. ‚ö†Ô∏è **Activer les logs de debug** pour les graphes qui ne s'affichent pas
3. ‚ö†Ô∏è **V√©rifier le remplissage** des tables avec un script de diagnostic

### Moyen terme (performance)

1. **Ajouter des index** sur les colonnes fr√©quemment join√©es :
```sql
CREATE INDEX IF NOT EXISTS idx_match_participants_xuid ON match_participants(xuid);
CREATE INDEX IF NOT EXISTS idx_match_participants_match ON match_participants(match_id, xuid);
```

2. **Cacher les DataFrames enrichis** au niveau de `load_df_optimized()`

3. **Profiler les requ√™tes lentes** avec `EXPLAIN ANALYZE`

### Long terme (architecture)

1. **Pr√©-calculer les agr√©gations** dans des tables d√©di√©es
2. **Lazy loading** : charger les donn√©es √† la demande
3. **Pagination** : ne charger que les donn√©es visibles

---

## Fichiers modifi√©s

| Fichier | Lignes | Description |
|---------|--------|-------------|
| `src/analysis/killer_victim.py` | 166, 217-218, 383, 612, 616-617 | Correction acc√®s TypedDict |
| `src/ui/path_picker.py` | 78-113, 117-150 | Simplification path picker |
| `src/ui/pages/timeseries.py` | 521 | Ajout titre graphe rang |
| `src/data/repositories/_match_queries.py` | 908-960, 970, 980 | Ajout colonne rank |
| `src/ui/commendations.py` | 408-416 | Suppression filtre mappings |
| `src/analysis/citations/engine.py` | 164-168 | Suppression filtre enabled |
| `src/ui/pages/citations.py` | 68-91, 103-121 | Ajout compteurs metrics |

---

## Tests √† effectuer

- [ ] Lancer l'app et v√©rifier qu'elle ne crash plus
- [ ] Onglet "Dernier match" ‚Üí Antagonistes et Roster s'affichent
- [ ] Onglet "S√©ries temporelles" ‚Üí Graphe "Rang et score personnel" a un titre
- [ ] Onglet "Citations" ‚Üí 41 citations visibles (pas 20)
- [ ] Onglet "Citations" ‚Üí Compteurs "Citations obtenues" et "M√©dailles distinctes" affich√©s
- [ ] Param√®tres ‚Üí M√©dias ‚Üí Le champ de saisie fonctionne sans crash
- [ ] Sidebar ‚Üí Le nombre de matchs est correct (pas "0 matchs")
- [ ] Onglet "Mes co√©quipiers" ‚Üí Les graphes s'affichent
- [ ] Onglet "Carri√®re" ‚Üí Les donn√©es sont visibles

---

## Analyse : Pourquoi les tests n'ont pas d√©tect√© ces bugs ? üîç

### Bugs qui auraient d√ª √™tre d√©tect√©s

| Bug | Type de test manquant | Raison de l'√©chec |
|-----|----------------------|-------------------|
| **Crash antagonistes** (TypedDict) | Tests unitaires `test_killer_victim.py` | Tests probablement absents ou utilisant des mocks incorrects |
| **Crash path_picker** (session_state) | Tests UI/Integration | Pas de tests Streamlit avec simulation de session_state |
| **Titre "undefined"** | Tests UI/Integration | Pas d'assertions sur les titres de graphes |
| **Colonne rank manquante** | Tests d'int√©gration data | Pas de validation de sch√©ma DataFrame complet |
| **Citations manquantes** | Tests fonctionnels | Pas d'assertions sur le nombre exact de citations attendu |
| **Compteurs manquants** | Tests UI snapshot | Pas de validation de la pr√©sence des metrics |

### Hypoth√®ses sur les lacunes de la suite de tests

#### 1. Tests unitaires incomplets
- `test_killer_victim.py` n'utilise probablement pas de donn√©es r√©alistes (TypedDict vs dict)
- Mocks trop simplistes qui ne reproduisent pas le comportement r√©el

#### 2. Tests UI/Integration absents ou superficiels
- Pas de tests End-to-End couvrant les workflows complets
- Pas de validation des widgets Streamlit (metrics, titres)
- Session_state non simul√© dans les tests

#### 3. Tests de non-r√©gression manquants
- Pas de snapshots de donn√©es attendues (ex: "48 citations")
- Pas de golden values pour les compteurs
- Pas de comparaison v3 vs v4 vs v5

#### 4. Coverage probablement trompeur
- Code coverage ‚â† test coverage
- Lignes ex√©cut√©es mais assertions insuffisantes
- Chemins d'erreur non test√©s

### Actions recommand√©es pour am√©liorer la suite de tests

#### Court terme

1. **Ajouter tests de r√©gression pour chaque bug corrig√©** :

```python
# tests/test_citations_regression.py
def test_citation_count_v5():
    """V√©rifie qu'on a bien 48 citations visibles."""
    engine = CitationEngine(...)
    citations = engine.load_all()
    assert len(citations) == 48, f"Attendu 48 citations, obtenu {len(citations)}"

# tests/integration/test_ui_metrics.py
def test_citations_page_has_delta_counter():
    """V√©rifie que le compteur +XXX est affich√©."""
    # Utiliser streamlit-testing ou pytest-selenium
    ...
```

2. **Valider les sch√©mas de donn√©es** :

```python
# tests/test_data_schema.py
def test_match_dataframe_has_rank_column():
    repo = DuckDBRepository(...)
    df = repo.load_matches(limit=10)
    assert "rank" in df.columns, "Colonne rank manquante"
    assert df["rank"].dtype == pl.Int64
```

3. **Tester les erreurs TypedDict** :

```python
# tests/test_killer_victim.py
def test_match_player_stats_dict_access():
    """V√©rifie que MatchPlayerStats utilise bien dict access."""
    stats: MatchPlayerStats = {"xuid": "123", "rank": 1, ...}
    # Devrait fonctionner
    assert killer_victim._get_rank(stats) == 1
```

#### Moyen terme

1. **Impl√©menter des tests E2E Streamlit** avec `streamlit-testing` ou Selenium
2. **Ajouter des fixtures de donn√©es r√©alistes** (exports v3/v4 r√©els)
3. **Cr√©er un test de migration v3‚Üív4‚Üív5** pour d√©tecter les r√©gressions
4. **Mettre en place des golden tests** (snapshots de r√©sultats attendus)

#### Long terme

1. **CI/CD avec tests visuels** (Percy, Chromatic)
2. **Monitoring de r√©gression automatique** (comparaison m√©triques avant/apr√®s)
3. **Property-based testing** avec Hypothesis pour g√©n√©rer des cas edge

### Conclusion

Ces bugs n'ont pas √©t√© d√©tect√©s car :
- ‚úÖ **Coverage insuffisant** : Tests unitaires pr√©sents mais incomplets
- ‚úÖ **Pas de tests UI/Integration** : Aucune validation Streamlit End-to-End
- ‚úÖ **Pas de golden values** : Aucune assertion sur les valeurs exactes (48 citations, etc.)
- ‚úÖ **Mocks trop simplistes** : Ne reproduisent pas les vrais TypedDict/session_state

**Action imm√©diate** : Ajouter des tests de r√©gression pour chaque bug corrig√© dans ce document.

---

## √âtude pr√©alable ‚Äî Root causes et instructions de correction

> Ajout√© le 15 f√©vrier 2026 ‚Äî Analyse approfondie du code source r√©el.

---

### RC-1. Crash antagonistes L192 + L625-628 (TypedDict restant)

**Root cause** : `MatchPlayerStats` est un `TypedDict` d√©clar√© sous `TYPE_CHECKING` uniquement (`src/analysis/killer_victim.py:31`). √Ä l'ex√©cution, les objets sont de simples `dict`. Mais **3 lignes suppl√©mentaires** utilisent encore la notation `.attribut` au lieu de `["attribut"]`.

**Lignes encore cass√©es** :
- **L192** : `official.kills` et `official.deaths` dans `validate_reconstituted_kd()`
- **L625** : `my_official.kills` dans `compute_personal_antagonists()`
- **L628** : `my_official.deaths` idem

**Pourquoi les tests ne d√©tectent pas** : Le `TypedDict` sous `TYPE_CHECKING` fait que mypy analyse le code comme correct (acc√®s `.kills` sur un TypedDict est valide pour le type checker). Mais √† l'ex√©cution, `TYPE_CHECKING` est `False` ‚Üí `MatchPlayerStats` n'est jamais import√© ‚Üí les objets sont des `dict` bruts.

#### Instructions de correction

1. **Dans `src/analysis/killer_victim.py`** :
   - L192 : Remplacer `official.kills` par `official["kills"]` et `official.deaths` par `official["deaths"]`
   - L625 : Remplacer `my_official.kills` par `my_official["kills"]`
   - L628 : Remplacer `my_official.deaths` par `my_official["deaths"]`

2. **Scan syst√©matique** : Rechercher `official\.kills|official\.deaths|official\.rank|official\.xuid|official\.assists|\.kills|\.deaths` dans tout le fichier et corriger TOUTE notation objet sur un `MatchPlayerStats`.

#### Tests √† ajouter

```python
# tests/test_killer_victim_typeddict.py

def test_validate_reconstituted_kd_uses_dict_access():
    """V√©rifie que validate_reconstituted_kd() fonctionne avec de vrais dicts."""
    from src.analysis.killer_victim import validate_reconstituted_kd, KVPair
    stats = [
        {"xuid": "AAA", "gamertag": "Player1", "kills": 10, "deaths": 5, "assists": 3, "rank": 1, "team_id": 0},
        {"xuid": "BBB", "gamertag": "Player2", "kills": 7, "deaths": 8, "assists": 2, "rank": 2, "team_id": 1},
    ]
    pairs = [KVPair(killer_xuid="AAA", killer_gamertag="Player1", victim_xuid="BBB", victim_gamertag="Player2", time_ms=1000)]
    results, _ = validate_reconstituted_kd(pairs, stats)
    # Doit NE PAS lever d'AttributeError
    assert len(results) >= 2

def test_compute_personal_antagonists_validation_notes():
    """V√©rifie que compute_personal_antagonists() ne crash pas en validation."""
    from src.analysis.killer_victim import compute_personal_antagonists
    # Construire des donn√©es minimales avec official_stats en dict (pas en objet)
    # La fonction doit traiter official_stats sans AttributeError
    # ‚Ä¶ (adapter les fixtures au cas r√©el)
```

**R√®gle de test** : Ne jamais passer un `NamedTuple` ou une classe √† la place d'un `dict`. Toujours utiliser des `dict` bruts comme le runtime le fait.

---

### RC-2. Citations ‚Äî 3 causes racines distinctes (R√âGRESSION v3‚Üív5)

**Root cause A** : `citation_mappings` ne contient que **14 entr√©es** au lieu de 48.
- Le script `scripts/create_citation_mappings_table.py` ins√®re intentionnellement 8+6=14 citations "valid√©es manuellement" (L353-354). Les 34 autres de la V3 n'ont jamais √©t√© migr√©es.

**Root cause B** : Les 5 mappings `award` utilisent des noms **anglais** (`Flag Defense`, `Flag Return`‚Ä¶) alors que `personal_score_awards` contient des noms **fran√ßais** (`Zone s√©curis√©e`, `Drapeau ramen√©`‚Ä¶).
- Fichier : `scripts/create_citation_mappings_table.py` L210-262
- Fichier : `src/analysis/citations/engine.py` L235 ‚Äî `match_awards.get(award_name, 0)` retourne toujours 0

**Root cause C** : `load_match_df()` dans `src/analysis/citations/engine.py` L489-491 r√©f√©rence des colonnes **inexistantes** en V5 : `r.playlist`, `r.game_variant`, `r.match_start_date` au lieu de `r.playlist_name`, `r.game_variant_name`, `r.start_time`. La requ√™te √©choue silencieusement (catch Exception ‚Üí DataFrame vide).

**R√©sultat combin√©** : Seuls 2 mappings sur 14 fonctionnent (`assistant`=stat, `ecrasement`=medal). 12/14 retournent 0. Les 145 items JSON non mapp√©s retournent 0 aussi. Le delta `+XXX` existe dans le code (`commendations.py` L519-522) mais n'appara√Æt jamais car quasi tout est √† 0.

#### Instructions de correction

1. **`scripts/create_citation_mappings_table.py`** ‚Äî Compl√©ter les 34 mappings manquants :
   - Auditer les 159 citations du JSON (`data/wiki/halo5_commendations_fr.json`)
   - Identifier pour chaque citation quel signal est disponible en V5 : `medal_name_id`, `stat_name` (colonne de `match_stats`/`match_participants`), `award_name` (dans `personal_score_awards`), ou `custom` (fonction Python)
   - Corriger le nom des 5 awards EN‚ÜíFR (`Flag Defense`‚Üínom FR r√©el dans personal_score_awards)
   - Viser au moins 48 mappings actifs

2. **`src/analysis/citations/engine.py`** L489-491 ‚Äî Corriger les noms de colonnes V5 :
   - `r.playlist` ‚Üí `r.playlist_name`
   - `r.game_variant` ‚Üí `r.game_variant_name`
   - `r.match_start_date` ‚Üí `r.start_time`

3. **Backfill** : Apr√®s correction des mappings, relancer `python scripts/backfill_data.py --player <GT> --citations` pour recalculer `match_citations` avec les bonnes r√®gles.

#### Tests √† ajouter

```python
# tests/test_citation_mappings.py

def test_citation_engine_load_match_df_v5_columns():
    """V√©rifie que load_match_df() utilise les bons noms de colonnes V5."""
    # Cr√©er une DB temporaire avec match_registry et match_participants V5
    # Appeler engine.load_match_df(match_id)
    # V√©rifier que le r√©sultat N'EST PAS un DataFrame vide
    # V√©rifier que les colonnes playlist_name, game_variant_name existent

def test_citation_award_names_match_personal_score_awards():
    """V√©rifie que les award_name des mappings correspondent aux valeurs r√©elles."""
    # Charger citation_mappings WHERE source_type = 'award'
    # Charger les DISTINCT award_name depuis personal_score_awards
    # V√©rifier l'intersection : chaque award_name de citation_mappings doit exister dans personal_score_awards

def test_citation_mappings_count_minimum():
    """V√©rifie qu'on a au moins 48 mappings actifs."""
    # Charger citation_mappings
    # assert len(mappings) >= 48, f"Attendu ‚â•48 mappings, obtenu {len(mappings)}"

def test_citation_engine_computes_nonzero_for_known_match():
    """V√©rifie qu'au moins quelques citations retournent des valeurs > 0."""
    # Prendre un match r√©el connu
    # Appeler engine.compute_all_for_match()
    # V√©rifier que le r√©sultat contient des valeurs > 0 (pas tout √† 0)
```

---

### RC-3. DB affiche "0 matchs" au d√©marrage et al√©atoirement

**Root cause principale** : Race condition DuckDB / file lock Windows.

`list_duckdb_v4_players()` (`src/ui/multiplayer.py` L217) :
1. N'est **PAS cach√©e** par `@st.cache_data` ‚Üí ex√©cut√©e √† chaque rerun Streamlit
2. Ouvre N connexions DuckDB (une par joueur) pour COUNT(*)
3. Exception silencieusement aval√©e par `except Exception: pass` ‚Üí `total_matches = 0`

Le **media indexer** (`src/data/media_indexer.py`) lanc√© en arri√®re-plan ouvre les m√™mes fichiers `stats.duckdb` en **√©criture**. Sur Windows, DuckDB utilise des file locks exclusifs ‚Üí quand les deux acc√®dent en m√™me temps ‚Üí exception ‚Üí 0 matchs.

**Root cause secondaire** : `_pick_best_duckdb_v4_player()` (`src/app/data_loader.py` L161) interroge `match_stats` (table V4) au lieu de la cha√Æne de fallback V5 (`player_match_enrichment` ‚Üí `match_stats`).

#### Instructions de correction

1. **`src/ui/multiplayer.py`** ‚Äî `list_duckdb_v4_players()` :
   - Ajouter `@st.cache_data(ttl=60)` pour √©viter N connexions par rerun
   - Remplacer `except Exception: pass` par un log + retry (1 tentative avec d√©lai 200ms si erreur de verrouillage)
   - Ouvrir les connexions en `read_only=True`

2. **`src/app/data_loader.py`** ‚Äî `_pick_best_duckdb_v4_player()` :
   - Appliquer la m√™me cha√Æne de fallback que `list_duckdb_v4_players` :
     `player_match_enrichment` ‚Üí `match_stats` ‚Üí `player_match_stats`

#### Tests √† ajouter

```python
# tests/test_multiplayer.py

def test_list_duckdb_v4_players_returns_nonzero_matches(tmp_path):
    """V√©rifie que list_duckdb_v4_players retourne un count > 0 pour une DB valide."""
    # Cr√©er une DB temporaire avec quelques lignes dans player_match_enrichment
    # Appeler list_duckdb_v4_players() (avec monkeypatch du chemin)
    # V√©rifier total_matches > 0

def test_list_duckdb_v4_players_read_only_no_lock(tmp_path):
    """V√©rifie que la lecture n'interf√®re pas avec une √©criture concurrente."""
    # Cr√©er une DB temporaire
    # Ouvrir une connexion en √©criture (simuler media_indexer)
    # Appeler list_duckdb_v4_players en read_only
    # Doit retourner un r√©sultat valide (pas 0)

def test_pick_best_player_uses_v5_tables(tmp_path):
    """V√©rifie que _pick_best_duckdb_v4_player utilise player_match_enrichment en priorit√©."""
    # Cr√©er une DB temporaire avec player_match_enrichment rempli et match_stats VIDE
    # Appeler _pick_best_duckdb_v4_player
    # V√©rifier que le joueur est trouv√© (pas 0 matchs)
```

---

### RC-4. Crash "Impact & Taquinerie" (highlight_events non qualifi√©)

**Root cause** : Dans `src/ui/pages/teammates_impact.py`, la m√©thode `load_impact_data()` de `TeammatesService` :
- **Ligne 35-37** : `WHERE table_schema = 'main' AND table_name = 'highlight_events'` ‚Üí cherche dans la DB locale du joueur. En V5, la table est dans `shared_matches.duckdb` attach√©e sous l'alias `shared`.
- **Ligne 44** : `FROM highlight_events` (non qualifi√©) ‚Üí r√©sout vers `main.highlight_events` qui n'existe pas.

**Fichier r√©el** : `src/data/services/teammates_service.py` L340-350 dans `load_impact_data()`.

#### Instructions de correction

1. **`src/data/services/teammates_service.py`** ‚Äî `load_impact_data()` :
   - L340 : Remplacer `WHERE table_schema = 'main' AND table_name = 'highlight_events'` par une v√©rification via `self._has_shared_table("highlight_events")` ou `WHERE table_catalog = 'shared' AND table_name = 'highlight_events'`
   - L350 : Remplacer `FROM highlight_events` par `FROM shared.highlight_events`

2. **Scan syst√©matique** : Rechercher tout `FROM highlight_events` non qualifi√© dans `src/` (hors tests) et pr√©fixer `shared.` partout.

#### Tests √† ajouter

```python
# tests/test_teammates_impact_v5.py

def test_load_impact_data_uses_shared_highlight_events(tmp_path):
    """V√©rifie que load_impact_data() utilise shared.highlight_events, pas main.highlight_events."""
    # Cr√©er un tuple (stats.duckdb + shared_matches.duckdb) temporaire
    # Ins√©rer des highlight_events dans shared uniquement (pas dans main)
    # Appeler TeammatesService.load_impact_data()
    # V√©rifier available=True et des r√©sultats non vides

def test_load_impact_data_survives_no_shared_db(tmp_path):
    """V√©rifie que load_impact_data() retourne available=False si shared DB absente."""
    # Cr√©er uniquement stats.duckdb sans shared
    # Appeler TeammatesService.load_impact_data()
    # V√©rifier available=False sans crash
```

---

### RC-5. Filtre par sessions ne fonctionne pas

**Root cause** : `cached_compute_sessions_db()` retourne un DataFrame **Pandas** (utilise `.empty`, `.groupby()`, `.reset_index()` ‚Äî `src/app/filters.py` L370-376), alors que `apply_filters()` dans `src/app/filters_render.py` L649-660 travaille en **Polars**.

La conversion implicite Pandas‚ÜíPolars via `_to_polars()` peut provoquer un mismatch de types sur la colonne `match_id` : Pandas `int64` vs Polars `Utf8`. Le `.is_in()` avec cast `pl.Utf8` sur `dff["match_id"]` peut ne pas matcher si `session_subset["match_id"]` reste en `int64` avant cast.

De plus, `render_session_filters()` dans `src/app/filters.py` L372 utilise `base_s_ui.empty` (Pandas) et `base_s_ui.groupby()` (Pandas), marquant clairement un module non migr√© vers Polars.

#### Instructions de correction

1. **`src/app/filters.py`** ‚Äî `render_session_filters()` L370-390 :
   - Migrer `cached_compute_sessions_db` vers un retour Polars natif, OU
   - Convertir explicitement avec `_to_polars(base_s_ui)` **avant** tout usage
   - Remplacer `.empty` par `.is_empty()`, `.groupby()` par `.group_by()`, `.reset_index()` par les √©quivalents Polars

2. **`src/app/filters_render.py`** ‚Äî `apply_filters()` L649-660 :
   - S'assurer que `session_subset["match_id"]` est cast√© en `Utf8` avant le `.is_in()`

#### Tests √† ajouter

```python
# tests/test_session_filter.py

def test_session_filter_produces_nonempty_result(tmp_path):
    """V√©rifie que le filtre session retourne des matchs quand la session existe."""
    # Cr√©er un DataFrame Polars de matchs avec match_id
    # Cr√©er un DataFrame Polars de sessions avec match_id + session_label
    # Simuler le filtrage (reproduire la logique de apply_filters mode Sessions)
    # V√©rifier que le r√©sultat est non vide

def test_session_filter_match_id_type_consistency():
    """V√©rifie que les match_id sont du m√™me type (Utf8) dans les deux DataFrames."""
    # Cr√©er un df_matches avec match_id en Utf8
    # Cr√©er un df_sessions avec match_id en Int64 (simule le retour Pandas)
    # Appliquer le filtre
    # V√©rifier que la jointure fonctionne (pas de perte de lignes √† cause du type)

def test_cached_compute_sessions_returns_polars():
    """V√©rifie que cached_compute_sessions_db retourne un DataFrame Polars (pas Pandas)."""
    # Appeler cached_compute_sessions_db avec des donn√©es de test
    # V√©rifier isinstance(result, pl.DataFrame)
```

---

### RC-6. Modes/cartes d√©s√©lectionn√©s au changement de p√©riode

**Root cause** : Dans `src/ui/components/checkbox_filter.py` L170-172 :

```python
current_selection: set[str] = st.session_state[session_key]
current_selection = current_selection & set(options)  # ‚Üê supprime les modes hors p√©riode
st.session_state[session_key] = current_selection
```

Combin√© avec `src/app/filters.py` L500-558 (filtrage en cascade) :
```python
dropdown_base = add_ui_columns(_to_polars(dropdown_base))  # ‚Üê filtr√© par date
mode_values = sorted({...scope1["mode_ui"]...})            # ‚Üê seulement les modes PR√âSENTS dans la p√©riode
```

**M√©canisme** : Quand l'utilisateur change la p√©riode, `dropdown_base` est filtr√© par date ‚Üí les modes/cartes sans matchs dans la nouvelle p√©riode disparaissent de `options` ‚Üí le nettoyage `& set(options)` les supprime de la s√©lection permanente. Quand la p√©riode est r√©-√©largie, ces modes ne sont plus coch√©s.

#### Instructions de correction

1. **`src/ui/components/checkbox_filter.py`** L170-172 :
   - Ne **plus supprimer** les s√©lections absentes des options courantes. Les conserver dans `session_state` m√™me si elles ne sont pas dans `options` du moment.
   - Afficher la checkbox seulement pour les options disponibles, mais **ne pas vider** la s√©lection.
   - Alternative : s√©parer `session_state[session_key]` (choix utilisateur) de `options_actuelles` (d√©pendant de la p√©riode).

2. **`src/app/filters.py`** L500-558 ‚Äî `render_cascade_filters()` :
   - `dropdown_base` devrait √™tre le DataFrame **complet** (toutes dates) pour d√©terminer les options disponibles
   - OU bien construire les options depuis les m√©tadonn√©es (tous les modes/cartes connus) plut√¥t que depuis le DataFrame filtr√©

#### Tests √† ajouter

```python
# tests/test_checkbox_filter.py

def test_checkbox_filter_preserves_selection_when_options_shrink():
    """V√©rifie que les s√©lections sont conserv√©es m√™me quand les options r√©tr√©cissent."""
    # Simuler session_state avec {"Assassin", "CTF", "Oddball"}
    # Appeler render_checkbox_filter avec options=["Assassin", "CTF"] (Oddball disparu)
    # V√©rifier que la s√©lection retourn√©e ne contient que les options valides
    # MAIS que session_state conserve "Oddball" pour quand il reviendra
    # OU bien que ce n'est pas supprim√© de la s√©lection du tout

def test_checkbox_filter_readds_selection_when_options_expand():
    """V√©rifie que les s√©lections reviennent quand les options r√©apparaissent."""
    # Session_state avait "Assassin" + "CTF" + "Oddball"
    # Options r√©duit √† ["Assassin", "CTF"] ‚Üí Oddball dispara√Æt
    # Options r√©-√©largi √† ["Assassin", "CTF", "Oddball"]
    # V√©rifier que "Oddball" est de nouveau s√©lectionn√©

def test_cascade_filter_options_independent_of_date_filter():
    """V√©rifie que les options Modes/Cartes ne d√©pendent pas de la p√©riode."""
    # Cr√©er un DataFrame avec Assassin (dates anciennes) et CTF (dates r√©centes)
    # Filtrer par p√©riode ‚Üí seulement CTF
    # V√©rifier que render_cascade_filters propose TOUJOURS Assassin + CTF comme options
```

---

### RC-7. Stats d√©taill√©es indisponibles "Dernier match"

**Root cause** : `cached_load_player_match_result()` dans `src/ui/cache_loaders.py` L293 retourne un `dict` avec `kills: {"count": None}`. Normalement `match_view.py` L240-252 enrichit depuis `row`. Le message "indisponibles" n'appara√Æt QUE si l'appel l√®ve une exception et retourne `None` (L318 : `except Exception: return None`).

Causes de l'exception :
1. **Race condition DuckDB** : m√™me file lock que RC-3 (media indexer en √©criture)
2. **`DuckDBRepository.__init__()`** √©choue si la DB est verrouill√©e
3. **`load_match_mmr_batch()`** √©choue si la table MMR n'existe pas ou a un sch√©ma V5 incompatible

#### Instructions de correction

1. **`src/ui/cache_loaders.py`** L317-318 :
   - Ne **jamais** retourner `None` ‚Äî toujours retourner le dict de base m√™me en cas d'exception
   - Changer `except Exception: return None` en `except Exception: return {"kills": {"count": None}, ...}`

2. **Ajouter `read_only=True`** aux connexions de lecture de `cached_load_player_match_result`

#### Tests √† ajouter

```python
# tests/test_cache_loaders.py

def test_cached_load_player_match_result_never_returns_none(tmp_path):
    """V√©rifie que la fonction ne retourne JAMAIS None, m√™me en cas d'erreur."""
    # Cr√©er une DB temporaire valide
    # Appeler cached_load_player_match_result
    # R√©sultat doit √™tre un dict, jamais None

def test_cached_load_player_match_result_survives_missing_mmr_table(tmp_path):
    """V√©rifie que la fonction retourne un dict m√™me si la table MMR n'existe pas."""
    # Cr√©er une DB temporaire sans table MMR
    # Appeler cached_load_player_match_result
    # R√©sultat doit √™tre un dict avec kills/deaths/assists √† None
```

---

### RC-8. Onglet Co√©quipiers ‚Äî MIGRATION V5 INCOMPL√àTE (graphes plats + profils similaires)

#### Diagnostic fondamental : migration `shared.match_participants` incompl√®te

Le principe de la V5 est clair (cf. `docs/ARCHITECTURE_V5.md`) : les donn√©es de match de **TOUS les joueurs** doivent vivre dans `shared.match_participants`. Les DB joueurs ne conservent que les **enrichissements personnels** (`player_match_enrichment` : performance_score, session_id, is_with_friends).

**Or, la migration est rest√©e √† mi-chemin** :

| Donn√©e | Disponible dans l'API (CoreStats) | Extraite par `extract_participants()` | Pr√©sente dans `MatchParticipantRow` | Colonne dans DDL `match_participants` | Pr√©sente dans `PARTICIPANT_COLUMNS` |
|--------|:---:|:---:|:---:|:---:|:---:|
| kills, deaths, assists | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| shots_fired, shots_hit | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| damage_dealt, damage_taken | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| avg_life_seconds | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| **headshot_kills** | ‚úÖ (`HeadshotKills`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **max_killing_spree** | ‚úÖ (`MaxKillingSpree`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **kda** | ‚úÖ (`KDA`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **accuracy** | ‚úÖ (`Accuracy`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **time_played_seconds** | ‚úÖ (`TimePlayed`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **grenade_kills** | ‚úÖ (`GrenadeKills`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **melee_kills** | ‚úÖ (`MeleeKills`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **power_weapon_kills** | ‚úÖ (`PowerWeaponKills`) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |

**Les fonctions d'extraction existent d√©j√†** dans `src/data/sync/transformers.py` mais ne sont appel√©es QUE pour le joueur principal (`me`) dans `transform_match_stats()` :
- `_extract_spree_headshots(player_obj)` (L186) ‚Üí retourne `(max_killing_spree, headshot_kills)` ‚Äî fonctionne sur N'IMPORTE QUEL participant
- `_extract_kda(player_obj)` (L175) ‚Üí retourne `kda`
- `_extract_life_time_stats(player_obj, match_obj)` (L201) ‚Üí retourne `(avg_life_seconds, time_played_seconds)`
- Les stats `grenade_kills`, `melee_kills`, `power_weapon_kills` sont dans `CoreStats` (L448+)

#### Preuve du trou dans `_get_match_source()` (`src/data/repositories/_match_queries.py`)

Quand `match_stats` locale existe (mode transitionnel) :
```python
spree_expr = "COALESCE(ms.max_killing_spree, 0)"  # ‚Üê fallback local
hs_expr = "COALESCE(ms.headshot_kills, 0)"         # ‚Üê fallback local
```

Quand `match_stats` locale N'EXISTE PAS (mode v5 pur) :
```python
spree_expr = "0"   # ‚Üê HARDCOD√â √Ä Z√âRO ‚Äî la donn√©e n'existe nulle part en shared
hs_expr = "0"      # ‚Üê HARDCOD√â √Ä Z√âRO
```

#### Cons√©quences en cascade

1. **Graphes co√©quipiers** : `load_teammate_stats()` va chercher dans la DB individuelle du co√©quipier (qui peut ne pas exister, ou √™tre incompl√®te) ‚Üí DataFrame vide ou partiel ‚Üí graphes plats
2. **`_get_match_source()` m√™me pour le joueur principal** : en v5 pur, `max_killing_spree` et `headshot_kills` retournent toujours 0
3. **`enrich_series_with_perfect_kills()`** : fallback sur la DB du joueur principal quand la DB co√©quipier n'existe pas ‚Üí donn√©es FAUSSES (perfect kills du joueur principal attribu√©s au co√©quipier)
4. **`compute_participation_profiles()`** : `personal_score_awards` charg√©es depuis les DB individuelles ‚Üí si DB absente ‚Üí profil ignor√© ‚Üí un seul profil affich√©
5. **`count_medal_by_match()`** fallback V4 : ne filtre pas par xuid ‚Üí m√©dailles de tous les joueurs confondues

#### Instructions de correction ‚Äî Phase 1 : Compl√©ter la migration shared

**√âtape 1.1 : Enrichir le mod√®le `MatchParticipantRow`** (`src/data/sync/models.py` L321-350)

Ajouter les champs manquants au dataclass :
```python
@dataclass
class MatchParticipantRow:
    # ... champs existants ...
    headshot_kills: int | None = None
    max_killing_spree: int | None = None
    kda: float | None = None
    accuracy: float | None = None
    time_played_seconds: int | None = None
    grenade_kills: int | None = None
    melee_kills: int | None = None
    power_weapon_kills: int | None = None
```

**√âtape 1.2 : Enrichir `extract_participants()`** (`src/data/sync/transformers.py` L1096-1200)

Appeler les fonctions d'extraction **d√©j√† existantes** pour chaque participant :
```python
# Apr√®s kills_val, deaths_val, assists_val, _ = _extract_player_stats(player)
kda_val = _extract_kda(player)
max_spree_val, headshots_val = _extract_spree_headshots(player)
_, time_played_val = _extract_life_time_stats(player, match_json)

# Depuis CoreStats
grenade_kills_val = _safe_int(stats_dict.get("GrenadeKills")) if stats_dict else None
melee_kills_val = _safe_int(stats_dict.get("MeleeKills")) if stats_dict else None
power_weapon_kills_val = _safe_int(stats_dict.get("PowerWeaponKills")) if stats_dict else None

# accuracy calcul√©e
accuracy_val = None
if shots_fired_val and shots_fired_val > 0 and shots_hit_val is not None:
    accuracy_val = round(shots_hit_val * 100.0 / shots_fired_val, 2)

rows.append(MatchParticipantRow(
    # ... existants ...,
    headshot_kills=headshots_val,
    max_killing_spree=max_spree_val,
    kda=kda_val,
    accuracy=accuracy_val,
    time_played_seconds=time_played_val,
    grenade_kills=grenade_kills_val,
    melee_kills=melee_kills_val,
    power_weapon_kills=power_weapon_kills_val,
))
```

**√âtape 1.3 : ALTER TABLE `match_participants`** (`src/data/sync/engine.py` DDL L157-178)

Ajouter les colonnes au DDL :
```sql
CREATE TABLE IF NOT EXISTS match_participants (
    -- ... colonnes existantes ...,
    headshot_kills SMALLINT,
    max_killing_spree SMALLINT,
    kda FLOAT,
    accuracy FLOAT,
    time_played_seconds INTEGER,
    grenade_kills SMALLINT,
    melee_kills SMALLINT,
    power_weapon_kills SMALLINT,
    PRIMARY KEY (match_id, xuid)
);
```

Et ajouter un bloc migration pour les DB existantes :
```python
for col, col_type in [
    ("headshot_kills", "SMALLINT"),
    ("max_killing_spree", "SMALLINT"),
    ("kda", "FLOAT"),
    ("accuracy", "FLOAT"),
    ("time_played_seconds", "INTEGER"),
    ("grenade_kills", "SMALLINT"),
    ("melee_kills", "SMALLINT"),
    ("power_weapon_kills", "SMALLINT"),
]:
    try:
        conn.execute(f"ALTER TABLE match_participants ADD COLUMN {col} {col_type}")
    except Exception:
        pass  # colonne existe d√©j√†
```

**√âtape 1.4 : Mettre √† jour `PARTICIPANT_COLUMNS`** (`src/data/sync/batch_insert.py` L461-476)

```python
PARTICIPANT_COLUMNS = [
    # ... existants ...,
    "headshot_kills",
    "max_killing_spree",
    "kda",
    "accuracy",
    "time_played_seconds",
    "grenade_kills",
    "melee_kills",
    "power_weapon_kills",
]
```

**√âtape 1.5 : Corriger `_get_match_source()`** (`src/data/repositories/_match_queries.py` L70-225)

Dans le bloc `else` (mode v5 pur sans `match_stats` locale) :
```python
# AVANT :
spree_expr = "0"
hs_expr = "0"

# APR√àS :
spree_expr = "COALESCE(p.max_killing_spree, 0)"
hs_expr = "COALESCE(p.headshot_kills, 0)"
```

Et dans le bloc `if has_ms` (mode transitionnel) :
```python
# AVANT :
spree_expr = "COALESCE(ms.max_killing_spree, 0)"
hs_expr = "COALESCE(ms.headshot_kills, 0)"

# APR√àS (shared d'abord, fallback local) :
spree_expr = "COALESCE(p.max_killing_spree, ms.max_killing_spree, 0)"
hs_expr = "COALESCE(p.headshot_kills, ms.headshot_kills, 0)"
```

**√âtape 1.6 : Backfill** ‚Äî Ajouter option `--participants-enrich` dans `scripts/backfill_data.py`

Pour les matchs d√©j√† synchronis√©s, les donn√©es API brutes ne sont plus disponibles. Il faudra :
- Soit relancer un `--full` sync (l'API retourne les CoreStats compl√®tes)
- Soit copier les donn√©es depuis `match_stats` locale existante vers `shared.match_participants` (puisque les colonnes existent dans match_stats pour le joueur principal ‚Äî mais cela ne couvre que SES stats, pas celles des co√©quipiers)
- Soit se r√©soudre √† ce que les anciens matchs aient NULL pour ces colonnes (les nouveaux matchs seront complets)

#### Instructions de correction ‚Äî Phase 2 : R√©√©crire les services co√©quipiers

**√âtape 2.1 : `load_teammate_stats()` ‚Üí utiliser `shared.match_participants`**

(`src/data/services/teammates_service.py` L75-115)

Remplacer le chargement depuis la DB individuelle par :
```python
def load_teammate_stats(self, gamertag: str, match_ids: set[str], db_path: str) -> pl.DataFrame:
    """Charge les stats d'un co√©quipier depuis shared.match_participants."""
    # R√©soudre le xuid du co√©quipier via shared.xuid_aliases
    conn = duckdb.connect(db_path, read_only=True)
    # ATTACH shared si pas d√©j√† fait
    xuid_row = conn.execute(
        "SELECT xuid FROM shared.xuid_aliases WHERE gamertag = ?", [gamertag]
    ).fetchone()
    if not xuid_row:
        return pl.DataFrame()
    
    teammate_xuid = xuid_row[0]
    placeholders = ",".join(["?"] * len(match_ids))
    query = f"""
        SELECT p.*, r.start_time, r.duration_seconds AS time_played_seconds,
               r.map_name, r.playlist_name, r.game_variant_name
        FROM shared.match_participants p
        JOIN shared.match_registry r ON p.match_id = r.match_id
        WHERE p.xuid = ? AND p.match_id IN ({placeholders})
    """
    params = [teammate_xuid] + list(match_ids)
    result = conn.execute(query, params).pl()
    conn.close()
    return result
```

**√âtape 2.2 : `enrich_series_with_perfect_kills()` ‚Üí utiliser `shared.medals_earned`**

(`src/data/services/teammates_service.py` L117-165)

```python
# AVANT : use_path = str(player_db) if player_db.exists() else db_path
# APR√àS : toujours utiliser shared.medals_earned avec filtre xuid
query = """
    SELECT match_id, SUM(count) as perfect_kills
    FROM shared.medals_earned
    WHERE xuid = ? AND medal_name_id = 1512363953
    AND match_id IN (...)
    GROUP BY match_id
"""
```

**√âtape 2.3 : `compute_participation_profiles()` ‚Üí utiliser `shared.match_participants`**

(`src/data/services/teammates_service.py` L170-270)

Au lieu de charger `personal_score_awards` depuis les DB individuelles, construire les profils √† partir des colonnes dispo dans `shared.match_participants` (damage_dealt, kills, deaths, assists, headshot_kills, grenade_kills, melee_kills, power_weapon_kills apr√®s migration Phase 1).

**√âtape 2.4 : `count_medal_by_match()` ‚Üí filtrer par xuid**

(`src/data/repositories/duckdb_repo.py` L493-502)

Ajouter `AND xuid = ?` dans la requ√™te fallback V4 pour ne compter que les m√©dailles du joueur cibl√©.

#### Tests √† ajouter

```python
# tests/test_v5_migration_completeness.py

def test_match_participant_row_has_extended_stats():
    """V√©rifie que MatchParticipantRow poss√®de les champs de stats √©tendues."""
    from src.data.sync.models import MatchParticipantRow
    row = MatchParticipantRow(match_id="m1", xuid="x1")
    extended_fields = ["headshot_kills", "max_killing_spree", "kda", "accuracy",
                       "time_played_seconds", "grenade_kills", "melee_kills", "power_weapon_kills"]
    for field in extended_fields:
        assert hasattr(row, field), f"MatchParticipantRow manque le champ '{field}'"

def test_participant_columns_includes_extended():
    """V√©rifie que PARTICIPANT_COLUMNS inclut les colonnes √©tendues."""
    from src.data.sync.batch_insert import PARTICIPANT_COLUMNS
    expected = {"headshot_kills", "max_killing_spree", "kda", "accuracy",
                "time_played_seconds", "grenade_kills", "melee_kills", "power_weapon_kills"}
    assert expected.issubset(set(PARTICIPANT_COLUMNS)), (
        f"Colonnes manquantes dans PARTICIPANT_COLUMNS: {expected - set(PARTICIPANT_COLUMNS)}"
    )

def test_extract_participants_extracts_extended_stats():
    """V√©rifie que extract_participants() extrait les stats √©tendues de l'API."""
    from src.data.sync.transformers import extract_participants
    # Construire un match_json minimal avec CoreStats contenant HeadshotKills & MaxKillingSpree
    match_json = {
        "MatchId": "test-match-id",
        "Players": [{
            "PlayerId": "xuid(12345)",
            "PlayerGamertag": "TestPlayer",
            "LastTeamId": 0,
            "Outcome": 2,
            "Rank": 1,
            "PlayerTeamStats": [{"Stats": {"CoreStats": {
                "Kills": 15, "Deaths": 5, "Assists": 8,
                "ShotsFired": 200, "ShotsHit": 80,
                "DamageDealt": 3000.0, "DamageTaken": 1500.0,
                "HeadshotKills": 7, "MaxKillingSpree": 10,
                "KDA": 3.5, "TimePlayed": "PT10M30S",
                "GrenadeKills": 2, "MeleeKills": 1, "PowerWeaponKills": 3,
                "Score": 2500,
            }}}],
        }],
    }
    rows = extract_participants(match_json)
    assert len(rows) == 1
    row = rows[0]
    assert row.headshot_kills == 7
    assert row.max_killing_spree == 10
    assert row.grenade_kills == 2
    assert row.melee_kills == 1
    assert row.power_weapon_kills == 3

def test_shared_match_participants_ddl_has_extended_columns(tmp_path):
    """V√©rifie que le DDL cr√©e les colonnes √©tendues dans match_participants."""
    import duckdb
    db_path = tmp_path / "test_shared.duckdb"
    conn = duckdb.connect(str(db_path))
    # Ex√©cuter le DDL du sync engine
    from src.data.sync.engine import SyncEngine
    # Cr√©er la table via le DDL
    # V√©rifier la pr√©sence des colonnes
    cols = {r[0] for r in conn.execute(
        "SELECT column_name FROM information_schema.columns WHERE table_name = 'match_participants'"
    ).fetchall()}
    expected = {"headshot_kills", "max_killing_spree", "kda", "accuracy",
                "time_played_seconds", "grenade_kills", "melee_kills", "power_weapon_kills"}
    assert expected.issubset(cols), f"Colonnes manquantes dans DDL: {expected - cols}"
    conn.close()

def test_get_match_source_v5_pure_uses_shared_spree_hs(tmp_path):
    """V√©rifie que _get_match_source() utilise p.max_killing_spree/headshot_kills en mode v5 pur."""
    # Cr√©er shared_matches.duckdb avec match_participants contenant les colonnes √©tendues
    # NE PAS cr√©er match_stats locale
    # Appeler _get_match_source()
    # V√©rifier que le SQL g√©n√©r√© ne contient PAS "spree_expr = '0'" mais "p.max_killing_spree"

# tests/test_teammates_service_v5.py

def test_load_teammate_stats_uses_shared_match_participants(tmp_path):
    """V√©rifie que les stats co√©quipier viennent de shared.match_participants, pas de DB individuelle."""
    import duckdb
    # Cr√©er la DB shared avec un match commun
    shared_path = tmp_path / "shared_matches.duckdb"
    shared_conn = duckdb.connect(str(shared_path))
    shared_conn.execute("""
        CREATE TABLE match_participants (
            match_id VARCHAR, xuid VARCHAR, gamertag VARCHAR, team_id INTEGER,
            outcome INTEGER, rank SMALLINT, score INTEGER,
            kills SMALLINT, deaths SMALLINT, assists SMALLINT,
            headshot_kills SMALLINT, max_killing_spree SMALLINT,
            shots_fired INTEGER, shots_hit INTEGER,
            damage_dealt FLOAT, damage_taken FLOAT,
            avg_life_seconds FLOAT, kda FLOAT, accuracy FLOAT,
            time_played_seconds INTEGER,
            PRIMARY KEY (match_id, xuid)
        )
    """)
    shared_conn.execute("""
        INSERT INTO match_participants VALUES
        ('m1', 'xuidA', 'PlayerA', 0, 2, 1, 2500, 15, 5, 8, 7, 10, 200, 80, 3000, 1500, 45.0, 3.5, 40.0, 630),
        ('m1', 'xuidB', 'CoequipierB', 0, 2, 2, 2000, 10, 8, 5, 3, 5, 150, 60, 2000, 1800, 35.0, 1.9, 40.0, 630)
    """)
    shared_conn.execute("""
        CREATE TABLE xuid_aliases (xuid VARCHAR PRIMARY KEY, gamertag VARCHAR, last_seen TIMESTAMP, source VARCHAR, updated_at TIMESTAMP)
    """)
    shared_conn.execute("INSERT INTO xuid_aliases VALUES ('xuidB', 'CoequipierB', NULL, 'api', NULL)")
    shared_conn.close()

    # NE PAS cr√©er de DB individuelle pour CoequipierB
    # Appeler load_teammate_stats
    # Le r√©sultat doit √™tre NON VIDE (donn√©es trouv√©es dans shared)
    # V√©rifier que headshot_kills == 3 et max_killing_spree == 5 pour CoequipierB

def test_perfect_kills_uses_shared_medals_not_main_player(tmp_path):
    """V√©rifie que les perfect_kills du co√©quipier viennent de shared.medals_earned."""
    import duckdb
    shared_path = tmp_path / "shared_matches.duckdb"
    shared_conn = duckdb.connect(str(shared_path))
    shared_conn.execute("""
        CREATE TABLE medals_earned (match_id VARCHAR, xuid VARCHAR, medal_name_id BIGINT, count INTEGER)
    """)
    # Joueur A a 5 perfect kills, co√©quipier B en a 2
    shared_conn.execute("INSERT INTO medals_earned VALUES ('m1', 'xuidA', 1512363953, 5)")
    shared_conn.execute("INSERT INTO medals_earned VALUES ('m1', 'xuidB', 1512363953, 2)")
    shared_conn.close()
    # Appeler enrich_series_with_perfect_kills pour xuidB
    # V√©rifier que B.perfect_kills == 2 (PAS 5)

def test_medal_count_by_match_filters_by_xuid(tmp_path):
    """V√©rifie que count_medal_by_match filtre bien par xuid."""
    import duckdb
    db = tmp_path / "test.duckdb"
    conn = duckdb.connect(str(db))
    conn.execute("CREATE TABLE medals_earned (match_id VARCHAR, xuid VARCHAR, medal_name_id BIGINT, count INTEGER)")
    conn.execute("INSERT INTO medals_earned VALUES ('m1', 'xuidA', 123, 3), ('m1', 'xuidB', 123, 1)")
    conn.close()
    # Appeler count_medal_by_match avec xuid=xuidB
    # V√©rifier count == 1 (pas 3+1=4)

def test_profiles_radar_uses_shared_data(tmp_path):
    """V√©rifie que compute_participation_profiles ne d√©pend PAS des DB individuelles."""
    # Cr√©er shared avec stats tr√®s diff√©rentes pour 2 joueurs
    # NE PAS cr√©er de DB individuelles
    # Appeler compute_participation_profiles
    # V√©rifier que les deux profils sont retourn√©s et DIFF√âRENTS
```

---

### RC-bonus. Patterns transversaux √† corriger

#### `except Exception: pass` syst√©matique

Pr√©sent dans 6+ des 8 bugs analys√©s. Ce pattern masque les vrais probl√®mes et rend le debug impossible.

**Instruction** : Remplacer tout `except Exception: pass` dans le chemin critique par :
```python
except Exception as e:
    logger.warning(f"[contexte]: {e}")
    # fallback explicite
```

#### Test √† ajouter

```python
# tests/test_no_silent_exceptions.py
import ast, pathlib

def test_no_bare_except_pass_in_src():
    """V√©rifie qu'aucun 'except Exception: pass' n'existe dans le code source."""
    src = pathlib.Path("src")
    violations = []
    for py in src.rglob("*.py"):
        tree = ast.parse(py.read_text(encoding="utf-8"))
        for node in ast.walk(tree):
            if isinstance(node, ast.ExceptHandler):
                body = node.body
                if len(body) == 1 and isinstance(body[0], ast.Pass):
                    violations.append(f"{py}:{node.lineno}")
    assert not violations, f"except‚Ä¶pass trouv√©s : {violations}"
```

---

## PLAN DE MIGRATION V5 FINALE ‚Äî Fin du dual write

> Ce plan corrige la racine de TOUS les bugs co√©quipiers, graphes plats, et ¬´ 0 matchs ¬ª :
> le sync √©crit encore dans les tables locales legacy au lieu de s'appuyer sur shared.

---

### 0. √âtat cible ‚Äî R√©partition d√©finitive des donn√©es

#### `shared_matches.duckdb` ‚Äî Donn√©es de TOUS les joueurs

| Table | Colonnes cl√©s | Nouveaut√©s V5 finale |
|-------|--------------|---------------------|
| `match_registry` | match_id (PK), start_time, map_*, playlist_*, game_variant_*, mode_category, is_ranked, is_firefight, duration_seconds, team_0/1_score, player_count‚Ä¶ | *(inchang√©e)* |
| `match_participants` | match_id+xuid (PK), gamertag, team_id, outcome, rank, score, kills, deaths, assists, shots_fired, shots_hit, damage_dealt, damage_taken, avg_life_seconds | **+headshot_kills**, **+max_killing_spree**, **+kda**, **+accuracy**, **+time_played_seconds**, **+grenade_kills**, **+melee_kills**, **+power_weapon_kills**, **+personal_score**, **+team_mmr**, **+kills_expected**, **+kills_stddev**, **+deaths_expected**, **+deaths_stddev**, **+assists_expected**, **+assists_stddev** |
| `highlight_events` | id, match_id, event_type, time_ms, killer_xuid, killer_gamertag, victim_xuid, victim_gamertag‚Ä¶ | *(inchang√©e)* |
| `medals_earned` | match_id+xuid+medal_name_id (PK), count | *(inchang√©e)* |
| `xuid_aliases` | xuid (PK), gamertag, last_seen, source | *(inchang√©e)* |
| `killer_victim_pairs` | match_id, killer_xuid, victim_xuid, kill_count‚Ä¶ | *(√† alimenter par le sync, plus seulement backfill)* |
| `schema_version` | version, description, applied_at | `version = 6` |

**Note sur `team_mmr` et `enemy_mmr`** : L'API fournit `team_mmr` par joueur (m√™me valeur pour toute l'√©quipe) et un dict `team_mmrs` avec tous les MMR d'√©quipe. On stocke `team_mmr` dans `match_participants` (redondant par √©quipe mais simple). `enemy_mmr` est d√©rivable (`team_mmrs[autre_team_id]`), on ne le stocke PAS en colonne : il est calcul√© via JOIN `match_participants self-join` ou enrichi au niveau query.

**Note sur `kills_expected`, `deaths_expected`, `assists_expected`** : L'API les fournit pour CHAQUE joueur dans la r√©ponse Skill. Ils sont per-player (pr√©dictions MMR sp√©cifiques). On les stocke dans `match_participants` car l'API les retourne d√©j√† pour tous les XUIDs pass√©s en param√®tre.

#### `stats.duckdb` ‚Äî Enrichissements PERSONNELS du joueur uniquement

| Table | R√¥le | Statut |
|-------|------|--------|
| `player_match_enrichment` | performance_score, session_id, session_label, is_with_friends, teammates_signature, known_teammates_count, friends_xuids | **CONSERV√âE ‚Äî ALIMENT√âE PAR LE SYNC** |
| `personal_score_awards` | Awards objectifs individuels du joueur | CONSERV√âE |
| `match_citations` | Citations calcul√©es par match (POV joueur) | CONSERV√âE |
| `career_progression` | Historique rangs | CONSERV√âE |
| `antagonists` | Rivalit√©s calcul√©es (POV joueur) | CONSERV√âE |
| `sessions` | Sessions de jeu regroup√©es | CONSERV√âE (cache) |
| `media_files` + `media_match_associations` | Fichiers m√©dias | CONSERV√âE |
| `mv_*` (4 tables) | Vues mat√©rialis√©es (cache) | CONSERV√âE (√† adapter pour lire shared) |
| `sync_meta` | Metadata de sync | CONSERV√âE |

#### Tables √† SUPPRIMER de `stats.duckdb`

| Table | Raison de suppression |
|-------|----------------------|
| **`match_stats`** | üî¥ Remplac√©e par `shared.match_registry` + `shared.match_participants` + `player_match_enrichment` |
| **`medals_earned`** (locale) | üî¥ Redondante avec `shared.medals_earned` (et sch√©ma diff√©rent : pas de colonne `xuid`) |
| **`highlight_events`** (locale) | üî¥ Redondante avec `shared.highlight_events` (et sch√©ma legacy killer/victim diff√©rent) |
| **`match_participants`** (copie locale) | üî¥ Redondante avec `shared.match_participants` |
| **`xuid_aliases`** (copie locale) | üî¥ Redondante avec `shared.xuid_aliases` |
| **`player_match_stats`** (MMR) | üî¥ Donn√©es d√©plac√©es dans `shared.match_participants` (team_mmr + expected stats per-player) |
| **`teammates_aggregate`** | üî¥ Obsol√®te ‚Äî `list_top_teammates()` calcule dynamiquement depuis `shared.match_participants` |
| **`skill_history`** | ‚ö†Ô∏è √Ä √©valuer ‚Äî si aliment√©e par un endpoint sp√©cifique CSR, peut rester locale |

---

### 1. Modifications du sync engine (`src/data/sync/engine.py`)

#### 1.1 STOP dual write ‚Äî Supprimer les √©critures locales redondantes

| M√©thode √† supprimer/modifier | Ligne | Action |
|-------------------------------|-------|--------|
| `_insert_match_row()` | L1762 | **SUPPRIMER** ‚Äî plus d'INSERT dans `match_stats` locale |
| `_insert_event_rows()` | L1833 | **SUPPRIMER** ‚Äî plus d'INSERT dans `highlight_events` locale |
| `_insert_medal_rows()` | L1885 | **SUPPRIMER** ‚Äî plus d'INSERT dans `medals_earned` locale |
| `_insert_participant_rows()` | L1896 | **SUPPRIMER** ‚Äî plus d'INSERT dans `match_participants` locale |
| `_insert_alias_rows()` | L1853 | **SUPPRIMER** ‚Äî plus d'INSERT dans `xuid_aliases` locale |
| `_insert_skill_row()` | L1826 | **SUPPRIMER** ‚Äî data d√©plac√©e dans `shared.match_participants` |
| `_compute_and_update_performance_score()` | L1650 | **MODIFIER** ‚Äî √©crire dans `player_match_enrichment` au lieu de `UPDATE match_stats` |
| `batch_compute_performance_scores()` | L1744 | **MODIFIER** ‚Äî lire depuis shared, √©crire dans `player_match_enrichment` |
| bitmask updates (`backfill_completed`) | L1015, L1157, L1382 | **SUPPRIMER** ‚Äî le flag backfill est dans `match_registry` |

#### 1.2 ALIMENTER `player_match_enrichment` depuis le sync

Le sync engine doit cr√©er et alimenter `player_match_enrichment` pour chaque nouveau match :

```python
# Dans _process_new_match() / _process_known_match(), APR√àS l'insertion dans shared
def _insert_enrichment_row(self, conn, match_id: str, row: MatchStatsRow) -> None:
    """Persiste les donn√©es d'enrichissement personnel dans player_match_enrichment."""
    conn.execute("""
        INSERT OR REPLACE INTO player_match_enrichment 
        (match_id, performance_score, session_id, session_label,
         is_with_friends, teammates_signature, known_teammates_count, 
         friends_xuids, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, NOW(), NOW())
    """, [match_id, row.performance_score, row.session_id, row.session_label,
          row.is_with_friends, row.teammates_signature, row.known_teammates_count,
          row.friends_xuids])
```

#### 1.3 √âCRIRE les donn√©es skill de TOUS les joueurs dans `shared.match_participants`

Modifier `transform_skill_stats()` pour retourner une liste (un `SkillRow` par joueur) au lieu d'un seul :

```python
# AVANT: transform_skill_stats(skill_json, match_id, xuid) ‚Üí PlayerMatchStatsRow (1 seul)
# APR√àS: transform_all_skill_stats(skill_json, match_id) ‚Üí list[SkillParticipantUpdate]

@dataclass
class SkillParticipantUpdate:
    match_id: str
    xuid: str
    team_mmr: float | None
    kills_expected: float | None
    kills_stddev: float | None
    deaths_expected: float | None
    deaths_stddev: float | None
    assists_expected: float | None
    assists_stddev: float | None
```

Puis dans le sync engine, apr√®s avoir ins√©r√© les `match_participants` de base :

```python
# UPDATE shared.match_participants SET team_mmr=?, kills_expected=?, ...
# WHERE match_id=? AND xuid=?
for skill_update in skill_updates:
    shared_conn.execute("""
        UPDATE match_participants SET 
            team_mmr = ?, kills_expected = ?, kills_stddev = ?,
            deaths_expected = ?, deaths_stddev = ?,
            assists_expected = ?, assists_stddev = ?
        WHERE match_id = ? AND xuid = ?
    """, [skill_update.team_mmr, skill_update.kills_expected, ...])
```

#### 1.4 ALIMENTER `killer_victim_pairs` dans shared depuis le sync

Actuellement aliment√©e seulement par backfill. Le sync doit la remplir √† chaque nouveau match :

```python
# Dans _process_new_match(), APR√àS _insert_shared_events()
kv_pairs = extract_killer_victim_pairs(events)  # D√©j√† r√©alis√© dans killer_victim.py
for pair in kv_pairs:
    shared_conn.execute("""
        INSERT OR IGNORE INTO killer_victim_pairs 
        (match_id, killer_xuid, killer_gamertag, victim_xuid, victim_gamertag, 
         kill_count, time_ms, is_validated, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, TRUE, NOW())
    """, [...])
```

#### 1.5 DDL ‚Äî Setup player DB all√©g√©

Modifier `_setup_player_db()` pour ne cr√©er QUE :
- `player_match_enrichment` (PK match_id)
- `personal_score_awards`
- `match_citations`
- `career_progression`
- `antagonists`
- `sessions`
- `sync_meta`
- `media_files` + `media_match_associations`

**NE PLUS cr√©er** : `match_stats`, `medals_earned`, `highlight_events`, `match_participants`, `xuid_aliases`, `player_match_stats`

---

### 2. Modifications du sch√©ma shared (`shared_matches.duckdb`)

#### 2.1 ALTER TABLE `match_participants` ‚Äî Nouvelles colonnes

```sql
-- Stats √©tendues (API CoreStats, disponibles pour TOUS les participants)
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS headshot_kills SMALLINT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS max_killing_spree SMALLINT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS kda FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS accuracy FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS time_played_seconds INTEGER;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS grenade_kills SMALLINT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS melee_kills SMALLINT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS power_weapon_kills SMALLINT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS personal_score INTEGER;

-- MMR et expected stats (API Skill, disponibles pour TOUS les joueurs)
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS team_mmr FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS kills_expected FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS kills_stddev FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS deaths_expected FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS deaths_stddev FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS assists_expected FLOAT;
ALTER TABLE match_participants ADD COLUMN IF NOT EXISTS assists_stddev FLOAT;
```

#### 2.2 Mettre √† jour le DDL dans `engine.py`

Le `CREATE TABLE IF NOT EXISTS match_participants` (L157-178) doit inclure toutes les nouvelles colonnes pour les nouvelles installations.

#### 2.3 `schema_version` ‚Üí version 6

Ins√©rer `(6, 'V5 finale - extended match_participants + stop dual write', NOW())`.

---

### 3. Modifications des extracteurs (`src/data/sync/transformers.py`)

#### 3.1 `MatchParticipantRow` ‚Äî Ajouter les champs

```python
# src/data/sync/models.py ‚Äî ajouter √† MatchParticipantRow :
headshot_kills: int | None = None
max_killing_spree: int | None = None
kda: float | None = None
accuracy: float | None = None
time_played_seconds: int | None = None
grenade_kills: int | None = None
melee_kills: int | None = None
power_weapon_kills: int | None = None
personal_score: int | None = None
```

#### 3.2 `extract_participants()` ‚Äî Appeler les extracteurs existants

Dans `src/data/sync/transformers.py` L1096-1200, APR√àS les extractions existantes (kills, deaths, assists, shots, damage), ajouter :

```python
# Stats √©tendues (d√©j√† dans CoreStats, fonctions existantes)
kda_val = _extract_kda(player)
max_spree_val, headshots_val = _extract_spree_headshots(player)
_, time_played_val = _extract_life_time_stats(player, match_json)

# Stats depuis CoreStats directement
grenade_kills_val = _safe_int(stats_dict.get("GrenadeKills")) if stats_dict else None
melee_kills_val = _safe_int(stats_dict.get("MeleeKills")) if stats_dict else None
power_weapon_kills_val = _safe_int(stats_dict.get("PowerWeaponKills")) if stats_dict else None
personal_score_val = _safe_int(stats_dict.get("PersonalScore")) if stats_dict else None

# accuracy calcul√©e
accuracy_val = None
if shots_fired_val and shots_fired_val > 0 and shots_hit_val is not None:
    accuracy_val = round(shots_hit_val * 100.0 / shots_fired_val, 2)

rows.append(MatchParticipantRow(
    # ... champs existants ...,
    headshot_kills=headshots_val,
    max_killing_spree=max_spree_val,
    kda=kda_val,
    accuracy=accuracy_val,
    time_played_seconds=time_played_val,
    grenade_kills=grenade_kills_val,
    melee_kills=melee_kills_val,
    power_weapon_kills=power_weapon_kills_val,
    personal_score=personal_score_val,
))
```

#### 3.3 `transform_all_skill_stats()` ‚Äî Nouvelle fonction pour TOUS les joueurs

```python
def transform_all_skill_stats(
    skill_data: dict[str, Any], match_id: str
) -> list[SkillParticipantUpdate]:
    """Extrait les donn√©es skill de TOUS les joueurs (pas juste le joueur courant)."""
    results = []
    values = skill_data.get("Value") or skill_data.get("value") or []
    if not isinstance(values, list):
        return results
    
    for entry in values:
        result = entry.get("Result") or entry.get("result") or {}
        xuid = _extract_xuid_from_skill_entry(entry)
        if not xuid:
            continue
        
        team_mmr = _safe_float(result.get("TeamMmr"))
        stat_perfs = result.get("StatPerformances") or result.get("RankRecap", {}).get("StatPerformances") or {}
        
        kills_perf = stat_perfs.get("Kills") or stat_perfs.get("kills") or {}
        deaths_perf = stat_perfs.get("Deaths") or stat_perfs.get("deaths") or {}
        assists_perf = stat_perfs.get("Assists") or stat_perfs.get("assists") or {}
        
        results.append(SkillParticipantUpdate(
            match_id=match_id,
            xuid=xuid,
            team_mmr=team_mmr,
            kills_expected=_safe_float(kills_perf.get("Expected")),
            kills_stddev=_safe_float(kills_perf.get("StdDev")),
            deaths_expected=_safe_float(deaths_perf.get("Expected")),
            deaths_stddev=_safe_float(deaths_perf.get("StdDev")),
            assists_expected=_safe_float(assists_perf.get("Expected")),
            assists_stddev=_safe_float(assists_perf.get("StdDev")),
        ))
    
    return results
```

#### 3.4 `PARTICIPANT_COLUMNS` ‚Äî Mise √† jour

```python
# src/data/sync/batch_insert.py
PARTICIPANT_COLUMNS = [
    "match_id", "xuid", "team_id", "outcome", "gamertag",
    "rank", "score", "kills", "deaths", "assists",
    "shots_fired", "shots_hit", "damage_dealt", "damage_taken",
    "avg_life_seconds",
    # V5 finale ‚Äî stats √©tendues
    "headshot_kills", "max_killing_spree", "kda", "accuracy",
    "time_played_seconds", "grenade_kills", "melee_kills",
    "power_weapon_kills", "personal_score",
]
```

---

### 4. Modifications du repository (`src/data/repositories/`)

#### 4.1 `_get_match_source()` ‚Äî Simplifier drastiquement

**AVANT** : Logique complexe de 150 lignes avec fallback `match_stats` locale, LEFT JOIN, COALESCE partout.

**APR√àS** : Lire UNIQUEMENT depuis `shared.match_registry` + `shared.match_participants` + LEFT JOIN `player_match_enrichment` (pour performance_score, session_id, is_with_friends).

```python
def _get_match_source(self, conn) -> tuple[str, list[str]]:
    """Sous-requ√™te v5 : shared + enrichissement personnel."""
    source = """(SELECT
        r.match_id,
        r.start_time,
        r.map_id, r.map_name,
        r.playlist_id, r.playlist_name,
        r.pair_id, r.pair_name,
        r.game_variant_id, r.game_variant_name,
        p.outcome, p.team_id,
        p.kda,
        COALESCE(p.max_killing_spree, 0) AS max_killing_spree,
        COALESCE(p.headshot_kills, 0) AS headshot_kills,
        COALESCE(p.avg_life_seconds, 0) AS avg_life_seconds,
        COALESCE(p.time_played_seconds, r.duration_seconds) AS time_played_seconds,
        COALESCE(p.kills, 0) AS kills,
        COALESCE(p.deaths, 0) AS deaths,
        COALESCE(p.assists, 0) AS assists,
        p.accuracy,
        CASE WHEN p.team_id = 0 THEN r.team_0_score ELSE r.team_1_score END AS my_team_score,
        CASE WHEN p.team_id = 0 THEN r.team_1_score ELSE r.team_0_score END AS enemy_team_score,
        p.team_mmr,
        -- enemy_mmr calcul√© via le team_mmr de l'autre √©quipe
        (SELECT p2.team_mmr FROM shared.match_participants p2 
         WHERE p2.match_id = r.match_id AND p2.team_id != p.team_id LIMIT 1) AS enemy_mmr,
        COALESCE(p.personal_score, p.score) AS personal_score,
        COALESCE(r.is_firefight, FALSE) AS is_firefight,
        COALESCE(r.is_ranked, FALSE) AS is_ranked,
        -- Enrichissements personnels
        e.performance_score,
        e.session_id, e.session_label,
        e.is_with_friends, e.teammates_signature,
        e.known_teammates_count, e.friends_xuids,
        p.rank
    FROM shared.match_registry r
    JOIN shared.match_participants p ON r.match_id = p.match_id AND p.xuid = ?
    LEFT JOIN player_match_enrichment e ON r.match_id = e.match_id
    ) AS match_stats"""
    return source, [self._xuid]
```

**Supprimer** : Tout le bloc `has_ms` / `else` / fallback `match_stats` locale / les expressions `COALESCE(ms.xxx, ...)`.

**Conserver un fallback minimal** uniquement pour les DB v3/v4 (XUID vide ou shared absent) : lire depuis `match_stats` si elle existe encore dans une DB non migr√©e.

#### 4.2 `load_match_mmr_batch()` ‚Äî Lire depuis shared

**AVANT** : JOIN `match_stats ms` + `player_match_stats pms` locale.

**APR√àS** : Lire `team_mmr`, `kills_expected`‚Ä¶ directement depuis `shared.match_participants` o√π ils existent maintenant.

```python
def load_match_mmr_batch(self, match_ids: list[str]) -> dict:
    """Charge les MMR depuis shared.match_participants."""
    placeholders = ",".join(["?"] * len(match_ids))
    query = f"""
        SELECT p.match_id, p.team_mmr,
               (SELECT p2.team_mmr FROM shared.match_participants p2 
                WHERE p2.match_id = p.match_id AND p2.team_id != p.team_id LIMIT 1) AS enemy_mmr
        FROM shared.match_participants p
        WHERE p.xuid = ? AND p.match_id IN ({placeholders})
    """
    # ...
```

#### 4.3 `load_top_medals()`, `load_match_medals()`, `count_medal_by_match()` ‚Äî Supprimer fallback V4

**AVANT** : Tentative shared, puis fallback `FROM medals_earned` locale (sans xuid).

**APR√àS** : Lecture **uniquement** depuis `shared.medals_earned` (qui a la colonne `xuid`). Supprimer le fallback V4. Les matchs anciens ont d√©j√† leurs m√©dailles dans shared car le sync les √©crivait dans les deux.

#### 4.4 `load_first_event_times()`, `load_highlight_events()` ‚Äî Supprimer fallback V4

**AVANT** : Tentative shared, puis fallback `FROM highlight_events` locale (sch√©ma legacy).

**APR√àS** : Lecture **uniquement** depuis `shared.highlight_events`. Supprimer le fallback V4.

#### 4.5 `_roster_loader.py` ‚Äî Supprimer tous les fallbacks locaux

Ce fichier contient ~15 fallbacks qui lisent `match_stats`, `highlight_events` (locale), `match_participants` (locale), `xuid_aliases` (locale). **TOUS doivent √™tre supprim√©s** au profit de la lecture shared uniquement.

Fonctions impact√©es :
- `_get_team_id()` L56 ‚Üí lire depuis `shared.match_participants`
- `_load_teammates_from_events()` L500 ‚Üí lire depuis `shared.highlight_events`
- `_load_teammates_from_participants()` L475 ‚Üí supprimer (redondant)
- `has_match_participants()` L533 ‚Üí v√©rifier dans shared
- `resolve_gamertag()` L591 ‚Üí utiliser `shared.xuid_aliases`
- `_build_full_xuid_map()` L711 ‚Üí utiliser `shared.xuid_aliases`
- `load_match_result_for_player()` L830 ‚Üí utiliser shared

#### 4.6 `_materialized_views.py` ‚Äî Adapter les 4 vues `mv_*`

Les 4 requ√™tes `FROM match_stats` (L141, 179, 200, 259) doivent √™tre r√©√©crites pour lire depuis la sous-requ√™te shared (m√™me logique que `_get_match_source()`).

```python
# AVANT:
"SELECT ... FROM match_stats WHERE ..."

# APR√àS:
"""SELECT ... FROM shared.match_registry r
   JOIN shared.match_participants p ON r.match_id = p.match_id AND p.xuid = ?
   WHERE ..."""
```

#### 4.7 `get_match_count()` ‚Äî Compter depuis shared

```python
# AVANT: SELECT COUNT(*) FROM match_stats
# APR√àS: SELECT COUNT(*) FROM shared.match_participants WHERE xuid = ?
```

---

### 5. Modifications de l'UI (`src/ui/`)

#### 5.1 `multiplayer.py` ‚Äî `list_duckdb_v4_players()` / `_discover_players()`

**AVANT** : Ouvre la DB de chaque joueur, `SELECT COUNT(*) FROM match_stats` / `player_match_enrichment` / `player_match_stats`.

**APR√àS** : Ouvrir `shared_matches.duckdb` en `read_only=True` et compter les matchs par joueur :

```python
@st.cache_data(ttl=60)
def list_duckdb_v4_players(base_dir: str) -> list[dict]:
    shared_path = Path(base_dir) / "warehouse" / "shared_matches.duckdb"
    conn = duckdb.connect(str(shared_path), read_only=True)
    results = conn.execute("""
        SELECT a.gamertag, a.xuid, COUNT(DISTINCT p.match_id) AS total_matches
        FROM xuid_aliases a
        JOIN match_participants p ON a.xuid = p.xuid
        GROUP BY a.gamertag, a.xuid
        HAVING total_matches > 0
        ORDER BY total_matches DESC
    """).fetchall()
    conn.close()
    return [{"gamertag": r[0], "xuid": r[1], "total_matches": r[2]} for r in results]
```

Plus de file lock sur les DB joueur. Plus de `except Exception: pass`.

#### 5.2 `cache_loaders.py` ‚Äî Adapter les acc√®s directs

- `resolve_player_xuid()` L130 : `SELECT DISTINCT xuid FROM player_match_stats` ‚Üí `shared.xuid_aliases WHERE gamertag = ?`
- `cached_load_highlight_events_for_match()` L402 : Lire depuis `shared.highlight_events`
- `cached_load_player_match_result()` L293 : adapter pour ne plus d√©pendre de `match_stats` locale

#### 5.3 `cache_filters.py` ‚Äî `cached_load_session_df()`

L67 : `FROM match_stats` direct ‚Üí Lire depuis shared + JOIN `player_match_enrichment` pour session_id/session_label.

#### 5.4 `pages/objective_analysis.py` ‚Äî `SELECT * FROM match_stats` direct

L94-102 : R√©√©crire pour lire depuis shared + enrichment.

#### 5.5 `pages/teammates_impact.py`

L44 : `FROM highlight_events` (locale) ‚Üí `FROM shared.highlight_events`
L71 : `FROM match_stats WHERE match_id IN (...)` ‚Üí `FROM shared.match_participants`

#### 5.6 `pages/media_library.py`

L520 : `FROM match_stats WHERE start_time IS NOT NULL` ‚Üí `FROM shared.match_registry`

#### 5.7 `aliases.py` ‚Äî `_load_aliases_from_db()`

L72 : `SELECT xuid, gamertag FROM xuid_aliases` ‚Üí `FROM shared.xuid_aliases`

---

### 6. Modifications des services (`src/data/services/`)

#### 6.1 `teammates_service.py` ‚Äî R√©√©criture compl√®te

**`load_teammate_stats()`** : Lire depuis `shared.match_participants` (voir RC-8 Phase 2).

**`enrich_series_with_perfect_kills()`** : Lire depuis `shared.medals_earned` avec filtre xuid.

**`compute_participation_profiles()`** : Construire les profils depuis `shared.match_participants` (grenade_kills, melee_kills, power_weapon_kills, headshot_kills apr√®s enrichissement).

**`load_impact_data()`** : `FROM shared.highlight_events` (d√©j√† couvert par RC-4).

**`get_impact_analysis()` L356** : `FROM match_stats WHERE match_id IN (...)` ‚Üí `FROM shared.match_participants WHERE match_id IN (...)`.

#### 6.2 `sessions_backfill.py`

L208-228 : `ALTER TABLE match_stats ADD COLUMN session_id` + `SELECT FROM match_stats` ‚Üí **R√©√©crire** pour lire depuis shared et √©crire dans `player_match_enrichment`.

---

### 7. Modifications des scripts ‚Äî Instructions PR√âCISES

---

#### 7.1 `src/data/sync/engine.py` ‚Äî Stop dual write

##### 7.1.1 `_process_new_match()` (L1227-L1400)

**Actuellement** : Phase 1 = √©crit dans shared, Phase 2 = √©crit TOUT dans player DB.

**Phase 2 (bloc `async with self._db_lock:`, L1337-L1384) ‚Äî lignes √† SUPPRIMER** :

| Appel | Table player | Ligne | Action |
|-------|-------------|-------|--------|
| `self._insert_match_row(match_row)` | `match_stats` | L1339 | ‚ùå SUPPRIMER |
| `self._insert_skill_row(skill_row)` | `player_match_stats` | L1342 | ‚ùå SUPPRIMER |
| `self._insert_medal_rows(medal_rows_personal)` | `medals_earned` | L1346 | ‚ùå SUPPRIMER |
| `self._insert_participant_rows(participant_rows_player)` | `match_participants` | L1352 | ‚ùå SUPPRIMER |
| `self._insert_alias_rows(alias_rows)` | `xuid_aliases` | L1355 | ‚ùå SUPPRIMER |
| `UPDATE match_stats SET backfill_completed...` | `match_stats` | L1376-L1383 | ‚ùå SUPPRIMER |

**Lignes √† CONSERVER dans le bloc player** :
- `self._insert_personal_score_rows(personal_score_rows)` ‚Üí reste dans player DB (table `personal_score_awards`)
- `self._compute_and_update_performance_score(match_id, match_row)` ‚Üí **R√â√âCRIRE** pour ins√©rer dans `player_match_enrichment` au lieu de `UPDATE match_stats`

**Lignes √† AJOUTER dans le bloc player** :
```python
# Ins√©rer dans player_match_enrichment (performance_score, session sera calcul√© plus tard)
self._insert_enrichment_row(match_id, match_row)
```

**Phase 1 (bloc shared, L1303-L1336)** ‚Äî lignes √† MODIFIER :

- `extract_participants(stats_json)` L1283 ‚Üí modifier `extract_participants()` pour extraire les 16 colonnes √©tendues (stats + MMR). L'appel ici ne change pas, c'est la fonction elle-m√™me qui change (voir ¬ß1).
- **AJOUTER** : √©criture du skill de TOUS les joueurs dans `shared.match_participants` via les colonnes MMR. Actuellement `transform_skill_stats()` ne retourne que le skill du joueur courant. Deux options :
  - **Option A** : Extraire les skills de tous dans `extract_participants()` directement depuis `skill_json`
  - **Option B** : Cr√©er `transform_all_skill_stats(skill_json, match_id)` ‚Üí retourne une liste de dicts `{xuid, team_mmr, kills_expected, ...}`, puis `UPDATE shared.match_participants SET team_mmr = ?, ... WHERE match_id = ? AND xuid = ?` en batch

##### 7.1.2 `_process_known_match()` (L1029-L1220)

**Actuellement** : Phase 1 = √©crit TOUT dans player, Phase 2 = backfill s√©lectif dans shared.

**Phase 1 (bloc `async with self._db_lock:`, L1131-L1167) ‚Äî m√™mes suppressions** :

| Appel | Table player | Ligne | Action |
|-------|-------------|-------|--------|
| `self._insert_match_row(match_row)` | `match_stats` | L1133 | ‚ùå SUPPRIMER |
| `self._insert_skill_row(skill_row)` | `player_match_stats` | L1136 | ‚ùå SUPPRIMER |
| `self._insert_medal_rows(medal_rows)` | `medals_earned` | L1140 | ‚ùå SUPPRIMER |
| `self._insert_participant_rows(participant_rows)` | `match_participants` | L1147 | ‚ùå SUPPRIMER |
| `self._insert_alias_rows(alias_rows)` | `xuid_aliases` | L1150 | ‚ùå SUPPRIMER |
| `UPDATE match_stats SET backfill_completed...` | `match_stats` | L1159-L1166 | ‚ùå SUPPRIMER |

**Lignes √† CONSERVER** :
- `self._insert_personal_score_rows(personal_score_rows)` ‚Üí player DB
- `self._compute_and_update_performance_score(match_id, match_row)` ‚Üí **R√â√âCRIRE** ‚Üí `player_match_enrichment`

**Lignes √† AJOUTER** :
- `self._insert_enrichment_row(match_id, match_row)` ‚Üí `player_match_enrichment`

**Phase 2 (bloc shared, L1170-L1211)** :
- `_insert_shared_participants()` L1177 ‚Üí OK mais doit maintenant inclure stats √©tendues + MMR
- Le `player_count` increment (L1205-L1210) ‚Üí OK, reste tel quel
- **AJOUTER** : aliases vers shared si absents (d√©j√† fait L1202-L1203, OK)

##### 7.1.3 `_process_single_match_legacy()` (L842-L1026)

**Ce mode legacy** √©crit tout dans player uniquement. Il est activ√© quand `shared_conn is None`.

**Action** : Le conserver pour compatibilit√© arri√®re, mais ajouter un `logger.warning("Mode legacy v4 sans shared DB ‚Äî donn√©es incompl√®tes")`.

##### 7.1.4 Nouvelle m√©thode `_insert_enrichment_row()` (√† CR√âER)

```python
def _insert_enrichment_row(self, match_id: str, match_row: MatchStatsRow) -> None:
    """Ins√®re/met √† jour une ligne dans player_match_enrichment."""
    conn = self._get_connection()
    conn.execute("""
        INSERT OR REPLACE INTO player_match_enrichment
        (match_id, performance_score, teammates_signature, updated_at)
        VALUES (?, ?, ?, ?)
    """, (
        match_id,
        None,  # sera calcul√© par _compute_and_update_performance_score
        getattr(match_row, 'teammates_signature', None),
        datetime.now(timezone.utc),
    ))
```

##### 7.1.5 Modifier `_compute_and_update_performance_score()` (L1696-L1755)

**Actuellement** (L1745-1755) :
```python
conn.execute("UPDATE match_stats SET performance_score = ? WHERE match_id = ?", [score, match_id])
```

**Remplacer par** :
```python
conn.execute(
    "INSERT INTO player_match_enrichment (match_id, performance_score, updated_at) "
    "VALUES (?, ?, ?) "
    "ON CONFLICT (match_id) DO UPDATE SET performance_score = ?, updated_at = ?",
    [match_id, score, now, score, now]
)
```

##### 7.1.6 Modifier `_load_existing_match_ids()` (L495-L555)

**Actuellement** : 3 fallbacks ‚Äî `match_stats` ‚Üí `player_match_stats` ‚Üí `shared.match_participants`

**Apr√®s migration** : Une seule source ‚Äî `shared.match_participants WHERE xuid = ?`
```python
# Supprim√© : SELECT DISTINCT match_id FROM match_stats
# Supprim√© : SELECT DISTINCT match_id FROM player_match_stats WHERE xuid = ?
# Gard√©   : SELECT DISTINCT match_id FROM match_participants WHERE xuid = ? (shared)
```

##### 7.1.7 M√©thodes `_insert_*` devenues orphelines (√† SUPPRIMER apr√®s migration)

| M√©thode | Ligne | Raison |
|---------|-------|--------|
| `_insert_match_row()` | L1756-L1808 | `match_stats` supprim√©e |
| `_insert_skill_row()` | L1810-L1828 | `player_match_stats` supprim√©e |
| `_insert_event_rows()` | L1829-L1848 | Events seulement dans shared |
| `_insert_medal_rows()` | L1876-L1896 | M√©dailles seulement dans shared |
| `_insert_participant_rows()` | L1887-L1900 | Participants seulement dans shared |
| `_insert_alias_rows()` | L1835-L1852 | Aliases seulement dans shared |

**‚ö†Ô∏è Conserver temporairement** `_insert_match_row()` pour le mode legacy (¬ß7.1.3) jusqu'√† suppression compl√®te.

##### 7.1.8 `_ensure_player_schema()` (L329-L452)

**Actuellement** : Cr√©e `match_stats`, `medals_earned`, `xuid_aliases`, `highlight_events`, `player_match_stats`, `match_participants` dans la player DB.

**Apr√®s migration** : Cr√©er uniquement :
- `player_match_enrichment` (nouvelle table)
- `personal_score_awards`
- `match_citations`
- `sync_meta`

Supprimer la cr√©ation de : `match_stats`, `medals_earned`, `xuid_aliases`, `highlight_events`, `player_match_stats`, `match_participants` (toutes dans shared).

---

#### 7.2 `scripts/backfill_data.py` + sous-modules ‚Äî Adaptations pr√©cises

L'arbre d'appels est : `backfill_data.py` ‚Üí `backfill/cli.py` (argparse) ‚Üí `backfill/orchestrator.py` ‚Üí `backfill/detection.py` + `backfill/core.py` + `backfill/strategies.py` + `src/data/sessions_backfill.py`.

##### 7.2.1 Modes qui √©crivent dans `match_stats` locale ‚Üí √Ä REDIRIGER

Tous ces modes font `UPDATE match_stats SET ... WHERE match_id = ?` dans la player DB. Apr√®s migration, `match_stats` n'existe plus.

| Mode | Fichier | Lignes | SQL actuel | Cible apr√®s migration |
|------|---------|--------|-----------|----------------------|
| `--accuracy` | orchestrator.py | L1210-L1224 | `UPDATE match_stats SET accuracy = ?` | `UPDATE shared.match_participants SET accuracy = ? WHERE match_id = ? AND xuid = ?` |
| `--shots` | orchestrator.py | L1236-L1250 | `UPDATE match_stats SET shots_fired = ?, shots_hit = ?` | Plus n√©cessaire : ces colonnes sont d√©j√† dans `shared.match_participants`. Supprimer ce mode OU le rediriger vers `--participants-shots`. |
| `--performance-scores` | strategies.py | L352-L355 | `UPDATE match_stats SET performance_score = ?` | `INSERT/UPDATE player_match_enrichment SET performance_score = ?` |
| `--end-time` | strategies.py | L235-L259 | `UPDATE match_stats SET end_time = ...` | `UPDATE shared.match_registry SET end_time = ... WHERE end_time IS NULL` (match_registry a la colonne `end_time`) |
| `--assets` | orchestrator.py | L1260-L1275 | `UPDATE match_stats SET playlist_name = ?, map_name = ?, ...` | `UPDATE shared.match_registry SET playlist_name = ?, map_name = ?, pair_name = ?, game_variant_name = ?` |

##### 7.2.2 Modes qui √©crivent dans `medals_earned` locale ‚Üí REDIRIGER vers shared

| Mode | Fichier | Lignes | SQL actuel | Cible apr√®s migration |
|------|---------|--------|-----------|----------------------|
| `--medals` | core.py | L35-L49 | `batch_upsert_rows(conn, "medals_earned", ...)` ‚Äî **conn = player** | Passer `shared_conn` au lieu de `conn`. √âcrire dans `shared.medals_earned`. |

**Changement dans orchestrator.py** L980-L986 :
```python
# AVANT
medal_rows = extract_medals(stats_json, xuid)
if medal_rows:
    n = insert_medal_rows(conn, medal_rows)

# APR√àS
medals_all = extract_all_medals(stats_json)  # TOUS les joueurs
if medals_all:
    n = insert_medal_rows(shared_conn, medals_all)  # Dans shared
```

##### 7.2.3 Modes qui √©crivent dans `highlight_events` locale ‚Üí REDIRIGER vers shared

| Mode | Fichier | Lignes | SQL actuel | Cible apr√®s migration |
|------|---------|--------|-----------|----------------------|
| `--events` | core.py | L52-L81 | `batch_insert_rows(conn, "highlight_events", ...)` ‚Äî **conn = player** | Passer `shared_conn`. |

**Changement dans orchestrator.py** L980-L986 :
```python
# AVANT
event_rows = transform_highlight_events(highlight_events, match_id)
if event_rows:
    n = insert_event_rows(conn, event_rows)

# APR√àS
event_rows = transform_highlight_events(highlight_events, match_id)
if event_rows:
    n = insert_event_rows(shared_conn, event_rows)  # Dans shared
```

##### 7.2.4 Modes qui √©crivent dans `player_match_stats` locale ‚Üí REDIRIGER vers `shared.match_participants`

| Mode | Fichier | Lignes | SQL actuel | Cible apr√®s migration |
|------|---------|--------|-----------|----------------------|
| `--skill` | core.py | L84-L126 | `batch_upsert_rows(conn, "player_match_stats", ...)` ‚Äî colonnes: match_id, xuid, team_id, team_mmr, enemy_mmr, kills_expected, kills_stddev, deaths_expected, deaths_stddev, assists_expected, assists_stddev | `UPDATE shared.match_participants SET team_mmr = ?, kills_expected = ?, ... WHERE match_id = ? AND xuid = ?` |
| `--enemy-mmr` | orchestrator.py | L1299-L1332 | `UPDATE player_match_stats SET enemy_mmr = ? WHERE match_id = ? AND xuid = ?` | `UPDATE shared.match_participants SET enemy_mmr = ? WHERE match_id = ? AND xuid = ?` ‚Äî note: `enemy_mmr` est un concept par joueur, pas par participant. Si on veut le garder, l'ajouter comme colonne √† `match_participants` ou le calculer √† la vol√©e depuis les `team_mmr` des joueurs adverses. |

**Important** : `--skill` doit maintenant extraire les skills de TOUS les joueurs (pas que le xuid courant). Modifier l'appel :
```python
# AVANT (core.py L84-L126)
skill_row = transform_skill_stats(skill_json, match_id, xuid)
insert_skill_row(conn, skill_row, xuid)

# APR√àS
all_skill_updates = transform_all_skill_stats(skill_json, match_id)  # TOUS les xuids
for skill_update in all_skill_updates:
    shared_conn.execute(
        "UPDATE match_participants SET team_mmr = ?, kills_expected = ?, kills_stddev = ?, "
        "deaths_expected = ?, deaths_stddev = ?, assists_expected = ?, assists_stddev = ? "
        "WHERE match_id = ? AND xuid = ?",
        (skill_update["team_mmr"], skill_update["kills_expected"], skill_update["kills_stddev"],
         skill_update["deaths_expected"], skill_update["deaths_stddev"],
         skill_update["assists_expected"], skill_update["assists_stddev"],
         match_id, skill_update["xuid"])
    )
```

##### 7.2.5 Modes qui √©crivent dans `xuid_aliases` locale ‚Üí REDIRIGER vers shared

| Mode | Fichier | Lignes | SQL actuel | Cible apr√®s migration |
|------|---------|--------|-----------|----------------------|
| `--aliases` | core.py | L173-L199 | `batch_upsert_rows(conn, "xuid_aliases", ...)` ‚Äî **conn = player** | Passer `shared_conn`. |

##### 7.2.6 Modes qui √©crivent dans `match_participants` ‚Üí D√©j√† correct (shared prioritaire)

| Mode | Fichier | DB cible actuelle | Action |
|------|---------|-------------------|--------|
| `--participants` | core.py L202-L238 | **player** (conn local) | ‚ùå REDIRIGER vers `shared_conn` ‚Äî la table `match_participants` n'existe plus en local |
| `--participants-scores` | orchestrator.py L913-L942 | `shared_conn` si dispo, sinon `conn` local | ‚úÖ OK ‚Äî mais supprimer le fallback `conn` local |
| `--participants-kda` | idem | idem | ‚úÖ OK ‚Äî supprimer fallback |
| `--participants-shots` | idem | idem | ‚úÖ OK ‚Äî supprimer fallback |
| `--participants-damage` | idem | idem | ‚úÖ OK ‚Äî supprimer fallback |
| `--participants-avg-life` | idem | idem | ‚úÖ OK ‚Äî supprimer fallback |

**Changement dans orchestrator.py** L913 :
```python
# AVANT
mp_conn = shared_conn if shared_conn is not None else conn

# APR√àS (shared obligatoire, pas de fallback local)
mp_conn = shared_conn
if mp_conn is None:
    logger.error("shared_conn requis pour participants updates en v5")
    continue
```

##### 7.2.7 Modes locaux OK (restent dans player DB)

| Mode | Fichier | Table | Changement |
|------|---------|-------|-----------|
| `--personal-scores` | core.py L129-L170 | `personal_score_awards` (player) | ‚úÖ Aucun changement |
| `--citations` | strategies.py L416-L460 | `match_citations` (player) | ‚ö†Ô∏è MAIS `CitationEngine` lit `match_stats` ‚Üí doit lire `shared.match_participants + match_registry` (voir ¬ß8) |
| `--killer-victim` | strategies.py L76-L170 | `killer_victim_pairs` (shared ou player) | ‚ö†Ô∏è Forcer shared uniquement, supprimer fallback local |

##### 7.2.8 `--sessions` ‚Äî R√©√©criture compl√®te

**Actuellement** (src/data/sessions_backfill.py) :
- L199-L203 : `SELECT match_id, start_time, teammates_signature, session_id FROM match_stats`
- L180-L183 : `ALTER TABLE match_stats ADD COLUMN session_id/session_label`
- L232-L235 : `UPDATE match_stats SET session_id = ?, session_label = ? WHERE match_id = ?`

**Apr√®s migration** ‚Äî `match_stats` n'existe plus :

1. **READS** : Remplacer `FROM match_stats` par :
```sql
-- Joindre shared.match_registry (pour start_time) + player_match_enrichment (pour session_id existant)
SELECT mr.match_id, mr.start_time, pme.teammates_signature, pme.session_id
FROM shared.match_participants mp
JOIN shared.match_registry mr ON mr.match_id = mp.match_id
LEFT JOIN player_match_enrichment pme ON pme.match_id = mr.match_id
WHERE mp.xuid = ?
AND mr.start_time IS NOT NULL
ORDER BY mr.start_time ASC
```
Note : `teammates_signature` est maintenant dans `player_match_enrichment`, pas dans shared.

2. **WRITES** : Remplacer `UPDATE match_stats SET session_id = ?, session_label = ?` par :
```sql
INSERT INTO player_match_enrichment (match_id, session_id, session_label, updated_at)
VALUES (?, ?, ?, NOW())
ON CONFLICT (match_id) DO UPDATE SET
    session_id = EXCLUDED.session_id,
    session_label = EXCLUDED.session_label,
    updated_at = NOW()
```

3. **SUPPRIMER** les `ALTER TABLE match_stats ADD COLUMN session_id/session_label` (L180-L183) ‚Äî ces colonnes n'existent plus dans `match_stats`. Remplacer par un `CREATE TABLE IF NOT EXISTS player_match_enrichment (...)` si la table n'existe pas.

4. **ATTACH shared** (L113-L118) : Le `ATTACH ? AS shared_tmp (READ_ONLY)` est correct, mais renommer en `shared` pour coh√©rence avec le reste du code.

##### 7.2.9 `--performance-scores` ‚Äî R√©√©criture des lectures

**Actuellement** (strategies.py L286-L355) :
```sql
SELECT performance_score FROM match_stats WHERE match_id = ?
SELECT match_id, start_time, kills, deaths, assists, kda, accuracy,
       time_played_seconds, avg_life_seconds, personal_score, damage_dealt,
       rank, team_mmr, enemy_mmr
FROM match_stats WHERE match_id = ?
```

**Apr√®s migration** ‚Äî toutes ces colonnes sont dans `shared.match_participants` + `shared.match_registry` :
```sql
-- Lecture du performance_score existant
SELECT performance_score FROM player_match_enrichment WHERE match_id = ?

-- Lecture des stats pour calculer le score
SELECT mp.match_id, mr.start_time, mp.kills, mp.deaths, mp.assists, mp.kda,
       mp.accuracy, mp.time_played_seconds, mp.avg_life_seconds,
       mp.personal_score, mp.damage_dealt, mp.rank, mp.team_mmr
FROM shared.match_participants mp
JOIN shared.match_registry mr ON mr.match_id = mp.match_id
WHERE mp.match_id = ? AND mp.xuid = ?

-- Historique pour le score relatif
SELECT mp.match_id, mr.start_time, mp.kills, mp.deaths, mp.assists, mp.kda,
       mp.accuracy, mp.time_played_seconds, mp.avg_life_seconds,
       mp.personal_score, mp.damage_dealt, mp.rank, mp.team_mmr
FROM shared.match_participants mp
JOIN shared.match_registry mr ON mr.match_id = mp.match_id
WHERE mp.xuid = ? AND mr.start_time IS NOT NULL AND mr.start_time < ?
ORDER BY mr.start_time ASC
```

**√âcriture** :
```sql
-- AVANT
UPDATE match_stats SET performance_score = ? WHERE match_id = ?

-- APR√àS
INSERT INTO player_match_enrichment (match_id, performance_score, updated_at)
VALUES (?, ?, NOW())
ON CONFLICT (match_id) DO UPDATE SET performance_score = ?, updated_at = NOW()
```

**Cons√©quence** : `backfill_performance_scores()` dans strategies.py a besoin d'un acc√®s shared en lecture. Modifier la signature pour accepter `shared_conn` et le xuid.

##### 7.2.10 D√©tection des matchs manquants ‚Äî `detection.py`

**Actuellement** (L316-L322) : La requ√™te principale de d√©tection est :
```sql
SELECT DISTINCT ms.match_id FROM match_stats ms WHERE ({conditions}) ORDER BY ms.start_time DESC
```

**Apr√®s migration** ‚Äî `match_stats` n'existe plus. Deux cas :

1. **Pour les modes qui ciblent shared** (`--medals`, `--events`, `--skill`, `--aliases`, `--accuracy`, `--shots`, `--participants`, `--assets`, `--end-time`) :
```sql
SELECT DISTINCT mp.match_id
FROM shared.match_participants mp
JOIN shared.match_registry mr ON mr.match_id = mp.match_id
WHERE mp.xuid = ? AND ({conditions})
ORDER BY mr.start_time DESC
```

2. **Pour les modes qui ciblent player** (`--performance-scores`, `--sessions`, `--citations`) :
```sql
SELECT DISTINCT mp.match_id
FROM shared.match_participants mp
JOIN shared.match_registry mr ON mr.match_id = mp.match_id
LEFT JOIN player_match_enrichment pme ON pme.match_id = mp.match_id
WHERE mp.xuid = ? AND ({conditions})
ORDER BY mr.start_time DESC
```

**Conditions √† adapter** (exemples) :
```sql
-- AVANT (--medals)
ms.match_id NOT IN (SELECT DISTINCT match_id FROM medals_earned)
-- APR√àS
mp.match_id NOT IN (SELECT DISTINCT match_id FROM shared.medals_earned WHERE xuid = ?)

-- AVANT (--performance-scores)
ms.performance_score IS NULL
-- APR√àS
pme.performance_score IS NULL OR pme.match_id IS NULL

-- AVANT (--shots)
ms.shots_fired IS NULL OR ms.shots_hit IS NULL
-- APR√àS
mp.shots_fired IS NULL OR mp.shots_hit IS NULL

-- AVANT (--accuracy)
ms.accuracy IS NULL
-- APR√àS
mp.accuracy IS NULL
```

##### 7.2.11 Connexions DB ‚Äî `orchestrator.py` L229

**Actuellement** : `conn = duckdb.connect(str(db_path), read_only=False)` ouvre la player DB. `shared_conn` n'est ouvert que si des flags participants sont demand√©s (L285-L310).

**Apr√®s migration** : `shared_conn` doit √™tre ouvert **TOUJOURS** (c'est la source principale). `conn` (player) n'est n√©cessaire que pour `personal_score_awards`, `player_match_enrichment`, `match_citations`, `sessions`.

**Changement orchestrator.py** L229 + L285 :
```python
# AVANT
conn = duckdb.connect(str(db_path), read_only=False)
# shared_conn ouvert seulement si participants_flags_requested

# APR√àS
conn = duckdb.connect(str(db_path), read_only=False)
shared_conn = _get_shared_connection(db_path)  # TOUJOURS ouvrir shared
if shared_conn is None:
    logger.error("shared_matches.duckdb introuvable ‚Äî impossible de backfill en v5")
    conn.close()
    return _empty_result()
```

##### 7.2.12 `backfill_completed` bitmask ‚Äî orchestrator.py L1068-L1095

**Actuellement** : Deux chemins selon `participants_only` :
- v5 participants-only ‚Üí `UPDATE match_registry SET backfill_completed = ...` (shared)
- v4/mixte ‚Üí `UPDATE match_stats SET backfill_completed = ...` (player)

**Apr√®s migration** : **Tout** le bitmask va dans `match_registry` (shared) :
```python
# AVANT (L1085-L1095)
if shared_conn is not None and participants_only:
    shared_conn.execute("UPDATE match_registry SET backfill_completed = ... WHERE match_id = ?")
else:
    _mark_backfill_completed(conn, match_id, mask=mask)

# APR√àS
shared_conn.execute(
    "UPDATE match_registry SET backfill_completed = COALESCE(backfill_completed, 0) | ? WHERE match_id = ?",
    [mask, match_id]
)
# Supprimer tout appel √† _mark_backfill_completed() qui √©crit dans match_stats
```

##### 7.2.13 `--all-data` ‚Äî orchestrator.py L155-L158

**Actuellement** active tous les flags. Apr√®s migration, les flags `medals`, `events`, `skill`, `aliases`, qui √©crivaient dans player, doivent maintenant naturellement √©crire dans shared. Pas de changement de logique ici, juste v√©rifier que les fonctions sous-jacentes utilisent bien `shared_conn`.

##### 7.2.14 Mode `--participants` (full insert) ‚Äî core.py L202-L238

**Actuellement** :
```python
batch_upsert_rows(conn, "match_participants", rows, PARTICIPANT_COLUMNS)
```
avec `conn` = player DB.

**Apr√®s migration** :
```python
batch_upsert_rows(shared_conn, "match_participants", rows, PARTICIPANT_COLUMNS)
# PARTICIPANT_COLUMNS doit inclure les 16 nouvelles colonnes (stats √©tendues + MMR)
```

**Changement requis** : `extract_participants()` doit maintenant extraire les 16 colonnes √©tendues. Donc quand on bacfkill un match existant, on re-t√©l√©charge les stats depuis l'API et on √©crit le roster COMPLET dans shared.

##### 7.2.15 Nouveau mode `--participants-enrich` (√† CR√âER)

Pour backfiller les colonnes √©tendues (headshot_kills, max_killing_spree, kda, accuracy, time_played_seconds, grenade_kills, melee_kills, power_weapon_kills, personal_score) + MMR (team_mmr, kills_expected, kills_stddev, deaths_expected, deaths_stddev, assists_expected, assists_stddev) sur les matchs EXISTANTS dans shared qui ont ces colonnes √† NULL.

**D√©tection** :
```sql
SELECT DISTINCT mp.match_id
FROM match_participants mp
WHERE mp.headshot_kills IS NULL
   OR mp.kda IS NULL
   OR mp.team_mmr IS NULL
ORDER BY (SELECT mr.start_time FROM match_registry mr WHERE mr.match_id = mp.match_id) DESC
LIMIT ?
```

**Traitement** : Pour chaque match_id, appeler l'API (`get_match_stats` + `get_skill_stats`), puis `extract_participants()` (version √©tendue) ‚Üí `UPDATE match_participants SET ... WHERE match_id = ? AND xuid = ?` pour CHAQUE participant.

**Ajouter dans cli.py** :
```python
group.add_argument("--participants-enrich", action="store_true",
    help="Backfill colonnes √©tendues + MMR dans shared.match_participants")
group.add_argument("--force-participants-enrich", action="store_true",
    help="Force le recalcul m√™me si les colonnes sont remplies")
```

---

#### 7.3 `scripts/sync.py` ‚Äî Adaptations

##### 7.3.1 `rebuild_teammates_aggregate()` (L249-L254)

**Actuellement** : Stub `# supprim√©e en v5`.

**Action** : Supprimer enti√®rement la fonction et tous les appels.

##### 7.3.2 `print_stats()` (L959-L1020)

**Actuellement** (L1004-L1007) : Compte les lignes de `match_stats`, `player_match_stats`, `highlight_events`, `xuid_aliases`, `medals_earned` dans la player DB.

**Apr√®s migration** : Lire depuis shared + player enrichment :
```python
# AVANT
tables = ["match_stats", "player_match_stats", "highlight_events", "xuid_aliases", "medals_earned"]
conn = duckdb.connect(str(db_path), read_only=True)
for table in tables:
    count = conn.execute(f"SELECT COUNT(*) FROM {table}").fetchone()[0]

# APR√àS
shared_path = db_path.parent.parent / "warehouse" / "shared_matches.duckdb"
conn = duckdb.connect(str(shared_path), read_only=True)
# Compter les matchs du joueur dans shared
xuid = _resolve_xuid(gamertag)
match_count = conn.execute(
    "SELECT COUNT(DISTINCT match_id) FROM match_participants WHERE xuid = ?", [xuid]
).fetchone()[0]
participant_count = conn.execute("SELECT COUNT(*) FROM match_participants").fetchone()[0]
# ...
conn.close()

# Player enrichment
player_conn = duckdb.connect(str(db_path), read_only=True)
enrichment_count = player_conn.execute(
    "SELECT COUNT(*) FROM player_match_enrichment"
).fetchone()[0] if table_exists("player_match_enrichment") else 0
```

##### 7.3.3 `_try_sync_duckdb()` (L726-L791)

Pas de changement n√©cessaire : cette fonction d√©l√®gue √† `sync_player_duckdb()` qui instancie `DuckDBSyncEngine`. Les changements sont dans engine.py (¬ß7.1).

##### 7.3.4 `_resolve_player_in_db()` (L148-L158)

**Actuellement** : `SELECT xuid FROM xuid_aliases WHERE LOWER(gamertag) = LOWER(?) LIMIT 1` ‚Äî ouvre la player DB.

**Apr√®s migration** : Lire depuis `shared.xuid_aliases` :
```python
# AVANT
conn = duckdb.connect(str(player_db_path), read_only=True)
row = conn.execute("SELECT xuid FROM xuid_aliases WHERE LOWER(gamertag) = LOWER(?) LIMIT 1", [gamertag]).fetchone()

# APR√àS
shared_path = _get_shared_db_path()
conn = duckdb.connect(str(shared_path), read_only=True)
row = conn.execute("SELECT xuid FROM xuid_aliases WHERE LOWER(gamertag) = LOWER(?) LIMIT 1", [gamertag]).fetchone()
```

##### 7.3.5 `refresh_duckdb_materialized_views()` (L284-L296)

Pas de changement ici ‚Äî les vues mat√©rialis√©es restent dans la player DB. Mais `DuckDBRepository.refresh_materialized_views()` devra √™tre adapt√© (voir ¬ß6).

#### 7.4 `launcher.py`

L245-249 : Adapter discovery pour utiliser shared au lieu de DB par joueur.

---

### 8. Modifications de l'analyse (`src/analysis/`)

#### 8.1 `citations/engine.py`

L415 : `FROM match_stats WHERE match_id=?` ‚Üí `FROM shared.match_participants + match_registry`
L497 : Idem (fallback V4)
L374 : `FROM medals_earned` locale ‚Üí `FROM shared.medals_earned`

#### 8.2 `killer_victim.py`

L192, L625, L628 : Corriger acc√®s TypedDict (voir RC-1).

---

### 9. Modifications du media indexer (`src/data/media_indexer.py`)

L666-765 : `FROM match_stats` ‚Üí `FROM shared.match_registry` (pour les timestamps de matchs).
Ouvrir `shared_matches.duckdb` en `read_only=True` au lieu de la DB joueur ‚Üí **√©limine la race condition** (RC-3).

---

### 10. `visualization/participation_radar.py`

L91 : `FROM match_stats` direct ‚Üí Lire depuis shared.

---

### 11. Script de migration `migrate_to_v5_final.py` (√† cr√©er)

Ce script effectue la migration des DB existantes :

```python
"""Migration vers V5 finale ‚Äî Stop dual write."""

def migrate_shared(shared_path: str) -> None:
    """Ajoute les colonnes √©tendues √† match_participants."""
    conn = duckdb.connect(shared_path)
    new_columns = [
        ("headshot_kills", "SMALLINT"),
        ("max_killing_spree", "SMALLINT"),
        ("kda", "FLOAT"),
        ("accuracy", "FLOAT"),
        ("time_played_seconds", "INTEGER"),
        ("grenade_kills", "SMALLINT"),
        ("melee_kills", "SMALLINT"),
        ("power_weapon_kills", "SMALLINT"),
        ("personal_score", "INTEGER"),
        ("team_mmr", "FLOAT"),
        ("kills_expected", "FLOAT"),
        ("kills_stddev", "FLOAT"),
        ("deaths_expected", "FLOAT"),
        ("deaths_stddev", "FLOAT"),
        ("assists_expected", "FLOAT"),
        ("assists_stddev", "FLOAT"),
    ]
    for col, col_type in new_columns:
        try:
            conn.execute(f"ALTER TABLE match_participants ADD COLUMN {col} {col_type}")
        except Exception:
            pass  # colonne existe d√©j√†
    
    conn.execute("""
        INSERT OR REPLACE INTO schema_version VALUES 
        (6, 'V5 finale - extended match_participants + stop dual write', NOW())
    """)
    conn.close()

def backfill_from_local(shared_path: str, player_db_path: str, xuid: str) -> None:
    """Copie les colonnes √©tendues depuis match_stats locale vers shared.match_participants."""
    conn = duckdb.connect(shared_path)
    conn.execute(f"ATTACH '{player_db_path}' AS player (READ_ONLY)")
    
    # Copier les stats √©tendues du joueur depuis sa DB locale
    conn.execute("""
        UPDATE match_participants p SET
            headshot_kills = ms.headshot_kills,
            max_killing_spree = ms.max_killing_spree,
            kda = ms.kda,
            accuracy = ms.accuracy,
            time_played_seconds = ms.time_played_seconds,
            grenade_kills = ms.grenade_kills,
            melee_kills = ms.melee_kills,
            power_weapon_kills = ms.power_weapon_kills,
            personal_score = ms.personal_score
        FROM player.match_stats ms
        WHERE p.match_id = ms.match_id AND p.xuid = ?
    """, [xuid])
    
    # Copier les MMR
    conn.execute("""
        UPDATE match_participants p SET
            team_mmr = pms.team_mmr,
            kills_expected = pms.kills_expected,
            kills_stddev = pms.kills_stddev,
            deaths_expected = pms.deaths_expected,
            deaths_stddev = pms.deaths_stddev,
            assists_expected = pms.assists_expected,
            assists_stddev = pms.assists_stddev
        FROM player.player_match_stats pms
        WHERE p.match_id = pms.match_id AND p.xuid = ?
    """, [xuid])
    
    conn.execute("DETACH player")
    conn.close()

def ensure_enrichment_table(player_db_path: str) -> None:
    """Cr√©e player_match_enrichment si absente et la peuple depuis match_stats."""
    conn = duckdb.connect(player_db_path)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS player_match_enrichment (
            match_id VARCHAR PRIMARY KEY,
            performance_score FLOAT,
            session_id VARCHAR,
            session_label VARCHAR,
            is_with_friends BOOLEAN,
            teammates_signature VARCHAR,
            known_teammates_count SMALLINT,
            friends_xuids VARCHAR,
            created_at TIMESTAMP DEFAULT NOW(),
            updated_at TIMESTAMP DEFAULT NOW()
        )
    """)
    # Migrer depuis match_stats si enrichment est vide
    count = conn.execute("SELECT COUNT(*) FROM player_match_enrichment").fetchone()[0]
    if count == 0:
        has_ms = conn.execute(
            "SELECT COUNT(*) FROM information_schema.tables WHERE table_name = 'match_stats'"
        ).fetchone()[0]
        if has_ms:
            conn.execute("""
                INSERT INTO player_match_enrichment 
                (match_id, performance_score, session_id, session_label,
                 is_with_friends, teammates_signature, known_teammates_count, friends_xuids)
                SELECT match_id, performance_score, session_id, session_label,
                       is_with_friends, teammates_signature, known_teammates_count, friends_xuids
                FROM match_stats
                WHERE performance_score IS NOT NULL 
                   OR session_id IS NOT NULL
                   OR is_with_friends IS NOT NULL
            """)
    conn.close()
```

---

### 12. Analyse de contexte AVANT migration (pr√©-requis)

Avant toute modification de code ou de structure de donn√©es, r√©aliser cette analyse compl√®te pour √©viter les r√©gressions.

#### 12.1 Inventaire de l'√©tat actuel des donn√©es

Pour CHAQUE joueur dans `db_profiles.json`, relever :

```bash
# Compter les matchs dans chaque DB
python -c "
import duckdb, json
from pathlib import Path

profiles = json.loads(Path('db_profiles.json').read_text())['profiles']
shared = duckdb.connect('data/warehouse/shared_matches.duckdb', read_only=True)

for gt, p in profiles.items():
    db = Path(p['db_path'])
    if not db.exists(): continue
    conn = duckdb.connect(str(db), read_only=True)
    local = conn.execute('SELECT COUNT(*) FROM match_stats').fetchone()[0]
    xuid = conn.execute('SELECT xuid FROM xuid_aliases LIMIT 1').fetchone()
    conn.close()
    if xuid:
        in_shared = shared.execute(
            'SELECT COUNT(DISTINCT match_id) FROM match_participants WHERE xuid = ?', [xuid[0]]
        ).fetchone()[0]
    else:
        in_shared = 0
    delta = local - in_shared
    print(f'{gt}: local={local}, shared={in_shared}, delta={delta}')
shared.close()
"
```

**Ce qu'on cherche** :
- Des matchs pr√©sents en local mais absents de shared ‚Üí **il faut les migrer avant de nettoyer**
- Des joueurs avec 0 matchs dans shared ‚Üí jamais migr√©s, **ne pas nettoyer**
- Des √©carts de colonnes (ex: `headshot_kills` NULL dans shared mais rempli en local)

#### 12.2 V√©rification du sch√©ma shared actuel

```bash
python -c "
import duckdb
conn = duckdb.connect('data/warehouse/shared_matches.duckdb', read_only=True)
cols = conn.execute(\"SELECT column_name FROM information_schema.columns WHERE table_name = 'match_participants' ORDER BY ordinal_position\").fetchall()
print('Colonnes match_participants:', [c[0] for c in cols])
conn.close()
"
```

**Colonnes attendues APR√àS ALTER TABLE** (31 colonnes) :
- Les 15 actuelles : match_id, xuid, gamertag, team_id, outcome, rank, score, kills, deaths, assists, shots_fired, shots_hit, damage_dealt, damage_taken, avg_life_seconds
- Les 9 stats √©tendues : headshot_kills, max_killing_spree, kda, accuracy, time_played_seconds, grenade_kills, melee_kills, power_weapon_kills, personal_score
- Les 7 MMR : team_mmr, kills_expected, kills_stddev, deaths_expected, deaths_stddev, assists_expected, assists_stddev

#### 12.3 Points d'attention sp√©cifiques connus

| Point | Risque | V√©rification |
|-------|--------|--------------|
| `match_stats.teammates_signature` | Uniquement dans le DB perso, sera dans `player_match_enrichment` | V√©rifier que la migration vers `player_match_enrichment` copie bien cette colonne |
| `match_stats.is_firefight` | Drapeau utilis√© pour filtrer les modes | V√©rifier que `match_registry` a bien cette colonne (OUI, elle existe) |
| `match_stats.mode_category` | Cat√©gorie de mode (pvp, pve, etc.) | Dans `match_registry`, pas dans `match_participants` ‚Äî les requ√™tes doivent faire le JOIN |
| `match_stats.performance_score` | Score relatif calcul√© localement | Exclusivement dans `player_match_enrichment` apr√®s migration |
| `match_stats.session_id` / `session_label` | Calcul de sessions | Idem, `player_match_enrichment` |
| `match_stats.backfill_completed` | Bitmask de suivi | Migr√© vers `match_registry.backfill_completed` (shared) |
| `player_match_stats.enemy_mmr` | MMR √©quipe adverse ‚Äî sp√©cifique au POV du joueur | Cette donn√©e n'est PAS par participant mais par match+joueur. Options : (a) calculer √† la vol√©e depuis les `team_mmr` des adversaires, ou (b) ajouter comme colonne √† `match_participants` |
| `xuid_aliases` en local | Peut contenir des alias non encore dans shared | La migration doit fusionner avant de supprimer |

#### 12.4 Test de non-r√©gression √† ex√©cuter AVANT tout changement

```bash
# Suite de tests stable actuelle
python -m pytest --ignore=tests/integration -q

# V√©rifier que l'app d√©marre
python -m streamlit run streamlit_app.py --server.headless true &
# Tester les pages principales, puis kill
```

Conserver le r√©sultat comme **baseline** de r√©f√©rence.

---

### 13. Ordre d'ex√©cution de la migration

**Phase 0 ‚Äî Pr√©-requis** (sans modification de code) :
1. Ex√©cuter l'analyse de contexte (¬ß12)
2. Sauvegarder les r√©sultats des tests comme baseline
3. Cr√©er un backup de TOUTES les DBs : `python scripts/backup_player.py --all`

**Phase 1 ‚Äî ALTER TABLE shared** (non destructif) :
4. `migrate_shared()` ‚Äî Ajouter les 16 colonnes √©tendues √† `shared.match_participants`

**Phase 2 ‚Äî Backfill shared depuis les DBs locales** :
5. `ensure_enrichment_table()` pour chaque joueur ‚Äî Cr√©e/peuple `player_match_enrichment`
6. `backfill_from_local()` pour chaque joueur ‚Äî Copie les stats √©tendues et MMR vers shared
7. V√©rifier la couverture : `python scripts/cleanup_player_dbs_v5.py --all --dry-run --verbose`

**Phase 3 ‚Äî D√©ployer le nouveau code** :
8. Modifier les transformers (¬ß1), mod√®les (¬ß1), batch_insert (¬ß1)
9. Modifier le sync engine (¬ß7.1)
10. Modifier les repositories et services (¬ß5, ¬ß6)
11. Modifier les scripts backfill (¬ß7.2) et sync (¬ß7.3)
12. Modifier l'UI (¬ß3, ¬ß4)

**Phase 4 ‚Äî Validation** :
13. Ex√©cuter la suite de tests compl√®te
14. Tester manuellement l'application sur toutes les pages
15. Sync un joueur de test et v√©rifier que les nouvelles donn√©es arrivent dans shared

**Phase 5 ‚Äî Nettoyage brutal des DBs perso** :
16. `python scripts/cleanup_player_dbs_v5.py --all --backup` ‚Äî Supprime les tables migr√©es
17. V√©rifier que l'application fonctionne toujours (seules les donn√©es shared restent)
18. Si des donn√©es manquent ‚Üí elles sont imm√©diatement visibles (erreurs claires, pas des 0 silencieux)

**‚ö†Ô∏è NE PAS passer √† la Phase 5 AVANT d'avoir valid√© la Phase 4 compl√®tement.**

Le nettoyage brutal est volontaire : il force la d√©tection imm√©diate de tout code qui lirait encore les tables locales au lieu de shared.

---

### 14. Script de nettoyage `cleanup_player_dbs_v5.py` ‚Äî D√©tails

Le script existant a √©t√© adapt√© pour la V5 finale :

#### 14.1 Tables supprim√©es (8 tables)

```python
TABLES_TO_REMOVE = [
    "match_stats",           # 48 colonnes ‚Üí shared.match_participants + match_registry
    "match_participants",    # copie locale ‚Üí shared.match_participants
    "highlight_events",      # copie locale ‚Üí shared.highlight_events
    "medals_earned",         # copie locale ‚Üí shared.medals_earned
    "killer_victim_pairs",   # locale ‚Üí shared.killer_victim_pairs
    "teammates_aggregate",   # obsol√®te (stub en v5)
    "player_match_stats",    # MMR/skill ‚Üí colonnes dans shared.match_participants
    "xuid_aliases",          # mapping ‚Üí shared.xuid_aliases
]
```

#### 14.2 Tables conserv√©es (9 tables + mv_*)

```python
TABLES_TO_KEEP = [
    "player_match_enrichment",   # performance_score, session_id, is_with_friends
    "personal_score_awards",     # awards objectifs (PersonalScores API)
    "antagonists",               # rivalit√©s killer/victim agr√©g√©es
    "match_citations",           # citations calcul√©es par match
    "career_progression",        # historique des rangs
    "media_files",               # fichiers m√©dias index√©s
    "media_match_associations",  # associations m√©dias‚Üîmatchs
    "sync_meta",                 # m√©tadonn√©es de sync
    "sessions",                  # sessions group√©es
    # + mv_* (vues mat√©rialis√©es)
]
```

#### 14.3 V√©rification de couverture shared (NOUVEAU)

Avant de supprimer quoi que ce soit, le script v√©rifie que 100% des matchs du joueur (pr√©sents dans `match_stats` locale) existent dans `shared.match_participants`.

```bash
# Simuler en voyant la couverture
python scripts/cleanup_player_dbs_v5.py --all --dry-run --verbose

# Si couverture < 100% ‚Üí le script REFUSE de supprimer
# Pour forcer (dangereux) :
python scripts/cleanup_player_dbs_v5.py --all --backup --skip-coverage-check
```

#### 14.4 S√©quence recommand√©e

```bash
# 1. Backup complet
python scripts/backup_player.py --all

# 2. Dry run pour v√©rifier
python scripts/cleanup_player_dbs_v5.py --all --dry-run --verbose

# 3. Nettoyage avec backup de s√©curit√©
python scripts/cleanup_player_dbs_v5.py --all --backup

# 4. Supprimer aussi les views de compatibilit√© (optionnel)
python scripts/cleanup_player_dbs_v5.py --all --remove-compat-views

# 5. Lancer l'app et v√©rifier que tout fonctionne
python -m streamlit run streamlit_app.py
```

---

### 15. Inventaire EXHAUSTIF de tous les fichiers impact√©s

| # | Fichier | Modifications | Priorit√© |
|---|---------|--------------|----------|
| 7 | `src/data/repositories/_roster_loader.py` | Supprimer ~15 fallbacks locaux | P1 |
| 8 | `src/data/repositories/duckdb_repo.py` | `load_top_medals()`, `load_match_medals()`, `count_medal_by_match()`, `load_first_event_times()`, `load_highlight_events()`, `list_other_player_xuids()`, `get_storage_info()`, `get_match_session_info()` | P1 |
| 9 | `src/data/services/teammates_service.py` | `load_teammate_stats()`, `enrich_series_with_perfect_kills()`, `compute_participation_profiles()`, `load_impact_data()`, `get_impact_analysis()` | P0 |
| 10 | `src/data/sessions_backfill.py` | Lire shared, √©crire `player_match_enrichment` | P1 |
| 11 | `src/data/media_indexer.py` | `FROM match_stats` ‚Üí `FROM shared.match_registry` (read_only) | P1 |
| 12 | `src/ui/multiplayer.py` | `list_duckdb_v4_players()` ‚Üí lire shared + cache | P0 |
| 13 | `src/ui/cache_loaders.py` | `resolve_player_xuid()`, `cached_load_highlight_events_for_match()`, `cached_load_player_match_result()` | P1 |
| 14 | `src/ui/cache_filters.py` | `cached_load_session_df()` ‚Üí shared + enrichment | P1 |
| 15 | `src/ui/aliases.py` | `_load_aliases_from_db()` ‚Üí `shared.xuid_aliases` | P2 |
| 16 | `src/ui/pages/objective_analysis.py` | `SELECT * FROM match_stats` ‚Üí shared | P1 |
| 17 | `src/ui/pages/teammates_impact.py` | `FROM highlight_events` ‚Üí `shared.highlight_events` | P0 |
| 18 | `src/ui/pages/media_library.py` | `FROM match_stats` ‚Üí `shared.match_registry` | P2 |
| 19 | `src/analysis/citations/engine.py` | `FROM match_stats` ‚Üí shared, noms colonnes V5 | P1 |
| 20 | `src/analysis/killer_victim.py` | TypedDict `.kills` ‚Üí `["kills"]` | P0 |
| 21 | `src/app/data_loader.py` | Player discovery ‚Üí shared | P1 |
| 22 | `src/app/filters.py` | `render_session_filters()` ‚Üí Polars natif | P1 |
| 23 | `src/app/filters_render.py` | `apply_filters()` type consistency | P1 |
| 24 | `src/ui/components/checkbox_filter.py` | Ne pas vider s√©lections hors p√©riode | P1 |
| 25 | `src/utils/xuid.py` | `resolve_xuid_from_db()` ‚Üí shared | P2 |
| 26 | `src/visualization/participation_radar.py` | `FROM match_stats` ‚Üí shared | P2 |
| 27 | `launcher.py` | Player discovery ‚Üí shared | P1 |
| 28 | `scripts/backfill_data.py` | Adapter pour √©crire dans les bonnes tables | P1 |
| 29 | `scripts/sync.py` | Supprimer stub `rebuild_teammates_aggregate()` | P2 |
| 30 | `scripts/migration/migrate_to_v5_final.py` | **NOUVEAU** ‚Äî Script de migration | P0 |
| 31 | `scripts/cleanup_player_dbs_v5.py` | Ajouter `player_match_stats` + `xuid_aliases` dans TABLES_TO_REMOVE, v√©rification couverture shared | P1 |

**Total : 31 fichiers impact√©s, dont 8 en priorit√© P0.**

---

### 16. Tests de compl√©tude de la migration

```python
# tests/test_v5_final_migration.py

import ast
import pathlib
import re

def test_no_from_match_stats_in_src():
    """V√©rifie qu'aucun fichier src/ ne lit directement FROM match_stats (table locale supprim√©e)."""
    src = pathlib.Path("src")
    violations = []
    # Pattern: FROM match_stats (sans shared. devant)
    pattern = re.compile(r'\bFROM\s+match_stats\b', re.IGNORECASE)
    shared_pattern = re.compile(r'\bFROM\s+shared\.match_stats\b', re.IGNORECASE)
    for py in src.rglob("*.py"):
        content = py.read_text(encoding="utf-8")
        for i, line in enumerate(content.splitlines(), 1):
            if pattern.search(line) and not shared_pattern.search(line):
                # Autoriser les alias "AS match_stats" (sortie de _get_match_source)
                if "AS match_stats" not in line:
                    violations.append(f"{py}:{i}: {line.strip()}")
    assert not violations, f"Acc√®s directs √† match_stats locale trouv√©s:\n" + "\n".join(violations)

def test_no_local_medals_earned_read():
    """V√©rifie que medals_earned est toujours lu depuis shared."""
    src = pathlib.Path("src")
    violations = []
    for py in src.rglob("*.py"):
        content = py.read_text(encoding="utf-8")
        for i, line in enumerate(content.splitlines(), 1):
            if re.search(r'\bFROM\s+medals_earned\b', line, re.IGNORECASE):
                if 'shared.' not in line:
                    violations.append(f"{py}:{i}: {line.strip()}")
    assert not violations, f"Lectures locales de medals_earned:\n" + "\n".join(violations)

def test_no_local_highlight_events_read():
    """V√©rifie que highlight_events est toujours lu depuis shared."""
    src = pathlib.Path("src")
    violations = []
    for py in src.rglob("*.py"):
        content = py.read_text(encoding="utf-8")
        for i, line in enumerate(content.splitlines(), 1):
            if re.search(r'\bFROM\s+highlight_events\b', line, re.IGNORECASE):
                if 'shared.' not in line:
                    violations.append(f"{py}:{i}: {line.strip()}")
    assert not violations, f"Lectures locales de highlight_events:\n" + "\n".join(violations)

def test_no_local_xuid_aliases_read():
    """V√©rifie que xuid_aliases est toujours lu depuis shared."""
    src = pathlib.Path("src")
    violations = []
    for py in src.rglob("*.py"):
        content = py.read_text(encoding="utf-8")
        for i, line in enumerate(content.splitlines(), 1):
            if re.search(r'\bFROM\s+xuid_aliases\b', line, re.IGNORECASE):
                if 'shared.' not in line:
                    violations.append(f"{py}:{i}: {line.strip()}")
    assert not violations, f"Lectures locales de xuid_aliases:\n" + "\n".join(violations)

def test_no_player_match_stats_in_src():
    """V√©rifie que player_match_stats (table locale MMR) n'est plus lue dans src/."""
    src = pathlib.Path("src")
    violations = []
    for py in src.rglob("*.py"):
        content = py.read_text(encoding="utf-8")
        for i, line in enumerate(content.splitlines(), 1):
            if re.search(r'\bplayer_match_stats\b', line, re.IGNORECASE):
                if 'CREATE' not in line and 'DROP' not in line and '#' not in line:
                    violations.append(f"{py}:{i}: {line.strip()}")
    assert not violations, f"R√©f√©rences √† player_match_stats:\n" + "\n".join(violations)

def test_sync_engine_does_not_write_match_stats():
    """V√©rifie que le sync engine n'ins√®re plus dans match_stats locale."""
    engine_path = pathlib.Path("src/data/sync/engine.py")
    content = engine_path.read_text(encoding="utf-8")
    # Chercher INSERT INTO match_stats (pas INSERT INTO shared.match_*)
    assert "INSERT" not in content or "match_stats" not in content.split("INSERT")[1].split("\n")[0], \
        "Le sync engine ins√®re encore dans match_stats locale"

def test_sync_engine_writes_player_match_enrichment():
    """V√©rifie que le sync engine alimente player_match_enrichment."""
    engine_path = pathlib.Path("src/data/sync/engine.py")
    content = engine_path.read_text(encoding="utf-8")
    assert "player_match_enrichment" in content, \
        "Le sync engine n'√©crit pas dans player_match_enrichment"

def test_match_participants_has_extended_columns():
    """V√©rifie que PARTICIPANT_COLUMNS inclut les stats √©tendues + MMR."""
    from src.data.sync.batch_insert import PARTICIPANT_COLUMNS
    expected = {
        "headshot_kills", "max_killing_spree", "kda", "accuracy",
        "time_played_seconds", "grenade_kills", "melee_kills",
        "power_weapon_kills", "personal_score",
    }
    assert expected.issubset(set(PARTICIPANT_COLUMNS)), (
        f"Colonnes stats manquantes: {expected - set(PARTICIPANT_COLUMNS)}"
    )

def test_match_participant_row_has_all_fields():
    """V√©rifie que le mod√®le MatchParticipantRow a tous les champs."""
    from src.data.sync.models import MatchParticipantRow
    row = MatchParticipantRow(match_id="m1", xuid="x1")
    for field in ["headshot_kills", "max_killing_spree", "kda", "accuracy",
                   "time_played_seconds", "grenade_kills", "melee_kills",
                   "power_weapon_kills", "personal_score"]:
        assert hasattr(row, field), f"Champ manquant: {field}"

def test_extract_participants_extracts_all_stats():
    """V√©rifie que extract_participants extrait les stats √©tendues de l'API."""
    from src.data.sync.transformers import extract_participants
    match_json = {
        "MatchId": "test-id",
        "Players": [{
            "PlayerId": "xuid(111)",
            "PlayerGamertag": "Tester",
            "LastTeamId": 0, "Outcome": 2, "Rank": 1,
            "PlayerTeamStats": [{"Stats": {"CoreStats": {
                "Kills": 10, "Deaths": 3, "Assists": 5,
                "ShotsFired": 100, "ShotsHit": 50,
                "DamageDealt": 2000.0, "DamageTaken": 1000.0,
                "HeadshotKills": 4, "MaxKillingSpree": 8,
                "KDA": 2.5, "TimePlayed": "PT8M",
                "GrenadeKills": 1, "MeleeKills": 2, "PowerWeaponKills": 3,
                "Score": 1500, "PersonalScore": 1800,
            }}}],
        }],
    }
    rows = extract_participants(match_json)
    assert len(rows) == 1
    r = rows[0]
    assert r.headshot_kills == 4
    assert r.max_killing_spree == 8
    assert r.grenade_kills == 1
    assert r.melee_kills == 2
    assert r.power_weapon_kills == 3
    assert r.personal_score == 1800

def test_list_players_uses_shared_not_player_db(tmp_path):
    """V√©rifie que la d√©couverte de joueurs utilise shared, pas les DB individuelles."""
    import duckdb
    shared = tmp_path / "shared_matches.duckdb"
    conn = duckdb.connect(str(shared))
    conn.execute("CREATE TABLE xuid_aliases (xuid VARCHAR PRIMARY KEY, gamertag VARCHAR, last_seen TIMESTAMP, source VARCHAR, updated_at TIMESTAMP)")
    conn.execute("INSERT INTO xuid_aliases VALUES ('x1', 'Player1', NULL, 'api', NULL)")
    conn.execute("""CREATE TABLE match_participants (
        match_id VARCHAR, xuid VARCHAR, gamertag VARCHAR, team_id INT, outcome INT,
        rank SMALLINT, score INT, kills SMALLINT, deaths SMALLINT, assists SMALLINT,
        shots_fired INT, shots_hit INT, damage_dealt FLOAT, damage_taken FLOAT,
        avg_life_seconds FLOAT, PRIMARY KEY (match_id, xuid))""")
    conn.execute("INSERT INTO match_participants VALUES ('m1','x1','Player1',0,2,1,100,5,3,2,50,25,1000,500,30)")
    conn.close()
    # Appeler la fonction de discovery avec shared_path
    # V√©rifier qu'elle retourne Player1 avec 1 match
    # NE PAS avoir besoin d'ouvrir data/players/Player1/stats.duckdb
```

---

### 17. R√©sum√© de l'√©tat cible

```
shared_matches.duckdb                    stats.duckdb (par joueur)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                     ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
match_registry          ‚Üê m√©tadonn√©es    player_match_enrichment  ‚Üê perf. score, sessions
match_participants      ‚Üê TOUTES les       personal_score_awards  ‚Üê awards objectifs
  (stats √©tendues          stats de        match_citations        ‚Üê citations calcul√©es
   + MMR + expected        TOUS les        career_progression     ‚Üê rangs
   pour TOUS)              joueurs         antagonists            ‚Üê rivalit√©s
highlight_events        ‚Üê √©v√©nements       sessions              ‚Üê sessions group√©es
medals_earned           ‚Üê m√©dailles        media_files            ‚Üê fichiers m√©dias
xuid_aliases            ‚Üê mapping          media_match_assoc.     ‚Üê associations
killer_victim_pairs     ‚Üê paires k/v       mv_* (4 tables)        ‚Üê cache mat√©rialis√©
schema_version                             sync_meta              ‚Üê metadata sync

                        SUPPRIM√âES de stats.duckdb :
                        ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                        ‚ùå match_stats (48 cols) ‚Üí shared
                        ‚ùå medals_earned (locale) ‚Üí shared
                        ‚ùå highlight_events (legacy) ‚Üí shared
                        ‚ùå match_participants (copie) ‚Üí shared
                        ‚ùå xuid_aliases (copie) ‚Üí shared
                        ‚ùå player_match_stats (MMR) ‚Üí shared
                        ‚ùå teammates_aggregate ‚Üí obsol√®te
```

---

### 18. Documentation √† mettre √† jour IMP√âRATIVEMENT

Ces fichiers de documentation doivent √™tre mis √† jour pour refl√©ter l'architecture V5 finale. Toute incoh√©rence entre doc et code est une source de bugs futurs.

#### 18.1 Documents d'architecture (critiques)

| Fichier | Contenu √† modifier | Priorit√© |
|---------|-------------------|----------|
| `docs/ARCHITECTURE_V5.md` | Refl√©ter le stop dual write : player DB ne contient plus que les enrichissements perso. Sch√©ma "√©tat cible" (¬ß17) √† y reporter int√©gralement. Documenter les 31 colonnes de `match_participants`. | **P0** |
| `docs/SHARED_MATCHES_SCHEMA.md` | Ajouter les 16 nouvelles colonnes de `match_participants` (9 stats √©tendues + 7 MMR). Mettre √† jour le DDL. | **P0** |
| `docs/SQL_SCHEMA.md` | Refl√©ter les tables supprim√©es de `stats.duckdb` et les colonnes ajout√©es √† shared. | **P0** |
| `docs/DATA_ARCHITECTURE.md` | Mettre √† jour les flux de donn√©es : sync ‚Üí shared uniquement (plus de dual write). | **P1** |

#### 18.2 Guides utilisateur

| Fichier | Contenu √† modifier | Priorit√© |
|---------|-------------------|----------|
| `docs/SYNC_GUIDE.md` | Expliquer que `sync --delta` √©crit dans shared + `player_match_enrichment` uniquement. Supprimer toute r√©f√©rence √† `match_stats` locale. | **P1** |
| `docs/CLEANUP_V5.md` | Mettre √† jour la liste des tables supprim√©es (8 au lieu de 6). Documenter `--skip-coverage-check`. Ajouter `player_match_stats` et `xuid_aliases`. | **P1** |
| `docs/CLEANUP_V5_QUICKSTART.md` | Ajouter l'√©tape de v√©rification de couverture. S√©quence : backup ‚Üí dry-run ‚Üí cleanup. | **P1** |
| `docs/COMMANDS.md` | Mettre √† jour les commandes cleanup et backfill avec les nouvelles options (`--participants-enrich`, `--skip-coverage-check`). | **P1** |
| `docs/BACKUP_RESTORE.md` | Pr√©ciser que les backups de player DB sont plus petits apr√®s cleanup (seuls les enrichissements). | **P2** |

#### 18.3 Documentation interne IA

| Fichier | Contenu √† modifier | Priorit√© |
|---------|-------------------|----------|
| `CLAUDE.md` | Mettre √† jour la section "Tables DuckDB Principales" : `match_stats` n'existe plus dans les player DBs. Ajouter les 16 colonnes √©tendues de `match_participants`. Mettre √† jour "Architecture Multi-Joueurs" pour refl√©ter que les co√©quipiers se lisent depuis shared, pas depuis leurs DBs individuelles. | **P0** |
| `.github/copilot-instructions.md` | M√™me mise √† jour que `CLAUDE.md` : tables `stats.duckdb` r√©duites, colonnes `match_participants` √©tendues. | **P0** |
| `.ai/project_map.md` | Mettre √† jour la cartographie : flux sync, tables par DB, fichiers modifi√©s. | **P1** |
| `.ai/data_lineage.md` | Mettre √† jour les flux : API ‚Üí shared uniquement. Plus de dual write. Enrichissements ‚Üí player DB. | **P1** |
| `.ai/thought_log.md` | Documenter la d√©cision : ¬´ V5 finale ‚Äî stop dual write, cleanup brutal des player DBs pour forcer la d√©tection de lectures locales r√©siduelles ¬ª. | **P1** |

#### 18.4 Points d'architecture critiques √† documenter

Ces points DOIVENT appara√Ætre clairement dans `docs/ARCHITECTURE_V5.md` et `CLAUDE.md` :

1. **`match_stats` n'existe plus** dans les player DBs. Toute lecture de stats de match doit passer par `shared.match_participants` (stats joueur) + `shared.match_registry` (m√©tadonn√©es match).

2. **`player_match_stats` n'existe plus**. Le MMR (team_mmr, kills_expected, etc.) de TOUS les joueurs est dans `shared.match_participants`. Plus de table s√©par√©e pour le skill.

3. **`xuid_aliases` est dans shared uniquement**. La table locale n'existe plus. Toute r√©solution xuid‚Üígamertag passe par `shared.xuid_aliases`.

4. **`player_match_enrichment` est la SEULE table de donn√©es match** restant dans les player DBs. Elle contient : performance_score, session_id, session_label, is_with_friends, teammates_signature, known_teammates_count, friends_xuids.

5. **Les co√©quipiers se lisent depuis shared**, pas depuis leurs DBs individuelles. `shared.match_participants WHERE match_id IN (...)` donne les stats de TOUS les joueurs d'un match.

6. **Le nettoyage brutal est intentionnel** : il force la d√©tection imm√©diate de tout code r√©siduel qui lirait encore les tables locales. Mieux vaut une erreur explicite ¬´ table introuvable ¬ª qu'un 0 silencieux.

7. **Le sync engine n'√©crit dans les player DBs** que : `player_match_enrichment` (performance_score, teammates_signature) et `personal_score_awards`. Tout le reste va dans shared.

---

### 19. D√©coupage en phases de travail (max 1 jour/phase)

Ce plan repr√©sente environ **2 semaines de travail intensif** (11 phases). Chaque phase est con√ßue pour √™tre compl√©t√©e en 1 journ√©e de d√©veloppement (6-8h effectives).

---

#### **PHASE 0 ‚Äî Pr√©-requis et analyse** (1 jour)

**Objectif** : Pr√©parer le terrain en s√©curisant les donn√©es et en comprenant l'√©tat actuel.

**T√¢ches** :
1. ‚úÖ Backup complet de toutes les DBs : `python scripts/backup_player.py --all`
2. ‚úÖ Ex√©cuter la suite de tests actuelle comme baseline : `python -m pytest --ignore=tests/integration -q > test_baseline.txt`
3. ‚úÖ Ex√©cuter l'analyse de contexte (¬ß12.1) : inventaire local vs shared pour chaque joueur
4. ‚úÖ V√©rifier le sch√©ma shared actuel (¬ß12.2) : colonnes `match_participants`
5. ‚úÖ Cr√©er le script de migration `scripts/migration/migrate_to_v5_final.py` (¬ß11) avec les 3 fonctions : `migrate_shared()`, `ensure_enrichment_table()`, `backfill_from_local()`

**Livrables** :
- Backups dans `backups/v5_final/`
- `test_baseline.txt` (r√©f√©rence)
- Rapport d'inventaire (local count vs shared count par joueur)
- Script de migration fonctionnel (test√© en dry-run)

**Validation** : Aucun code applicatif modifi√©, donn√©es sauvegard√©es, √©tat initial document√©.

---

#### **PHASE 1 ‚Äî ALTER TABLE shared + backfill donn√©es** (1 jour)

**Objectif** : Enrichir `shared.match_participants` avec les 16 colonnes √©tendues et backfiller les donn√©es depuis les DBs locales.

**T√¢ches** :
1. ‚úÖ Ex√©cuter `migrate_shared()` : ALTER TABLE pour ajouter les 16 colonnes (9 stats + 7 MMR)
2. ‚úÖ Pour chaque joueur : `ensure_enrichment_table()` ‚Äî cr√©er/peupler `player_match_enrichment`
3. ‚úÖ Pour chaque joueur : `backfill_from_local()` ‚Äî copier stats √©tendues + MMR vers shared
4. ‚úÖ V√©rifier la couverture : `python scripts/cleanup_player_dbs_v5.py --all --dry-run --verbose`
5. ‚úÖ INSERT INTO schema_version : V6 "V5 finale - extended match_participants"

**Livrables** :
- `shared.match_participants` avec 31 colonnes (15 + 16)
- `player_match_enrichment` cr√©√©e et peupl√©e pour chaque joueur
- Rapport de couverture √† 100% pour tous les joueurs

**Validation** : 
```sql
SELECT * FROM shared.match_participants LIMIT 1  -- doit avoir headshot_kills, team_mmr, etc.
SELECT COUNT(*) FROM player_match_enrichment WHERE performance_score IS NOT NULL  -- > 0
```

**‚ö†Ô∏è Point de non-retour** : Une fois cette phase valid√©e, les donn√©es sont dans shared. Le rollback n√©cessite de restaurer les backups.

---

#### **PHASE 2 ‚Äî Transformers, mod√®les, batch_insert** (1 jour)

**Objectif** : Adapter le code d'extraction/transformation pour remplir les 16 nouvelles colonnes.

**Fichiers modifi√©s** :
- [src/data/sync/models.py](src/data/sync/models.py#L321-L350)
- [src/data/sync/transformers.py](src/data/sync/transformers.py#L1096-L1200)
- [src/data/sync/batch_insert.py](src/data/sync/batch_insert.py#L461-L476)

**T√¢ches** :
1. ‚úÖ **models.py** : Ajouter 16 champs √† `MatchParticipantRow` (¬ß1.1)
2. ‚úÖ **transformers.py** : Modifier `extract_participants()` pour extraire les 16 colonnes depuis `CoreStats` (¬ß1.2)
3. ‚úÖ **transformers.py** : Cr√©er `transform_all_skill_stats(skill_json, match_id)` ‚Üí liste de dicts skill pour TOUS les joueurs (¬ß1.3)
4. ‚úÖ **batch_insert.py** : √âtendre `PARTICIPANT_COLUMNS` avec les 16 nouveaux champs (¬ß1.4)
5. ‚úÖ Tests unitaires : `test_extract_participants_extended()`, `test_transform_all_skill_stats()`

**Livrables** :
- `MatchParticipantRow` avec 31 attributs
- `extract_participants()` retourne les stats HeadshotKills, MaxKillingSpree, etc.
- `transform_all_skill_stats()` retourne [{xuid, team_mmr, kills_expected, ...}, ...]
- `PARTICIPANT_COLUMNS` = 31 colonnes
- Tests passent

**Validation** : `pytest tests/test_transformers.py tests/test_models.py -v`

---

#### **PHASE 3 ‚Äî Sync engine : stop dual write** (1 jour)

**Objectif** : Modifier le sync engine pour qu'il n'√©crive plus dans les tables locales (sauf `player_match_enrichment` et `personal_score_awards`).

**Fichier modifi√©** :
- [src/data/sync/engine.py](src/data/sync/engine.py) (~2093 lignes)

**T√¢ches selon ¬ß7.1** :
1. ‚úÖ `_process_new_match()` L1227-1400 : supprimer les appels √† `_insert_match_row`, `_insert_skill_row`, `_insert_medal_rows`, `_insert_participant_rows`, `_insert_alias_rows`, et le UPDATE `backfill_completed` sur `match_stats`
2. ‚úÖ `_process_known_match()` L1029-1220 : m√™mes suppressions
3. ‚úÖ Cr√©er `_insert_enrichment_row(match_id, match_row)` ‚Üí INSERT INTO `player_match_enrichment`
4. ‚úÖ Modifier `_compute_and_update_performance_score()` L1696-1755 : UPDATE `player_match_enrichment` au lieu de `match_stats`
5. ‚úÖ Modifier `_load_existing_match_ids()` L495-555 : lire depuis `shared.match_participants WHERE xuid = ?` uniquement
6. ‚úÖ Modifier `_ensure_player_schema()` L329-452 : ne plus cr√©er `match_stats`, `medals_earned`, etc. Cr√©er seulement `player_match_enrichment`, `personal_score_awards`, `match_citations`
7. ‚úÖ Conserver `_process_single_match_legacy()` (mode v4 sans shared) avec un warning

**Livrables** :
- Sync engine ne fait plus de dual write
- Tests d'int√©gration : `pytest tests/integration/test_sync_engine.py -v` (si existant)
- Sync de test r√©ussi : `python scripts/sync.py --player TestPlayer --delta --max-matches 10`

**Validation** : 
- Apr√®s un sync, v√©rifier que `player_match_enrichment` a de nouvelles lignes
- V√©rifier que `shared.match_participants` a les nouvelles donn√©es (31 colonnes remplies)
- V√©rifier qu'aucune table `match_stats`, `player_match_stats`, etc. n'a √©t√© cr√©√©e dans une nouvelle player DB

---

#### **PHASE 4 ‚Äî Scripts backfill** (1 jour)

**Objectif** : Adapter `backfill_data.py` et ses sous-modules pour √©crire dans shared au lieu de local.

**Fichiers modifi√©s selon ¬ß7.2** :
- [scripts/backfill_data.py](scripts/backfill_data.py)
- [scripts/backfill/orchestrator.py](scripts/backfill/orchestrator.py)
- [scripts/backfill/detection.py](scripts/backfill/detection.py)
- [scripts/backfill/core.py](scripts/backfill/core.py)
- [scripts/backfill/strategies.py](scripts/backfill/strategies.py)
- [src/data/sessions_backfill.py](src/data/sessions_backfill.py)

**T√¢ches (¬ß7.2.1 √† ¬ß7.2.15)** :
1. ‚úÖ `--accuracy` : UPDATE `shared.match_participants` au lieu de `match_stats`
2. ‚úÖ `--shots` : rediriger vers `--participants-shots` ou supprimer (d√©j√† dans shared)
3. ‚úÖ `--performance-scores` : lire shared, √©crire `player_match_enrichment`
4. ‚úÖ `--end-time` : UPDATE `shared.match_registry`
5. ‚úÖ `--assets` : UPDATE `shared.match_registry`
6. ‚úÖ `--medals` : √©crire dans `shared.medals_earned`
7. ‚úÖ `--events` : √©crire dans `shared.highlight_events`
8. ‚úÖ `--skill` : UPDATE `shared.match_participants` (team_mmr, etc.) pour TOUS les joueurs
9. ‚úÖ `--aliases` : √©crire dans `shared.xuid_aliases`
10. ‚úÖ `--participants` : √©crire dans `shared.match_participants` uniquement
11. ‚úÖ Supprimer tous les fallbacks `conn` local (forcer `shared_conn`)
12. ‚úÖ `--sessions` : r√©√©crire pour lire shared + √©crire `player_match_enrichment` (¬ß7.2.8)
13. ‚úÖ `detection.py` : FROM `shared.match_participants JOIN match_registry` (¬ß7.2.10)
14. ‚úÖ `orchestrator.py` : ouvrir `shared_conn` **toujours**, pas seulement si participants (¬ß7.2.11)
15. ‚úÖ `backfill_completed` bitmask : toujours dans `match_registry`, jamais dans `match_stats` (¬ß7.2.12)
16. ‚úÖ Cr√©er mode `--participants-enrich` pour backfiller les 16 colonnes √©tendues (¬ß7.2.15)

**Livrables** :
- Tous les modes backfill √©crivent dans shared (ou `player_match_enrichment`)
- Tests : `pytest tests/test_backfill.py -v`
- Backfill de test r√©ussi : `python scripts/backfill_data.py --player TestPlayer --all-data --max-matches 10`

**Validation** : Les donn√©es backfill√©es apparaissent dans shared, pas dans les tables locales obsol√®tes.

---

#### **PHASE 5 ‚Äî Services et repositories (partie 1)** (1 jour)

**Objectif** : Adapter les services critiques pour lire depuis shared au lieu des DBs individuelles.

**Fichiers modifi√©s** :
- [src/data/services/teammates_service.py](src/data/services/teammates_service.py) (¬ß5)
- [src/data/repositories/_match_queries.py](src/data/repositories/_match_queries.py) (¬ß6.1)
- [src/data/repositories/_roster_loader.py](src/data/repositories/_roster_loader.py) (¬ß6.2)

**T√¢ches** :
1. ‚úÖ **teammates_service.py** :
   - `load_teammate_stats()` : lire depuis shared au lieu d'ouvrir la DB du co√©quipier (¬ß5.1)
   - `enrich_series_with_perfect_kills()` : lire `shared.match_participants` (¬ß5.2)
   - `compute_participation_profiles()` : idem (¬ß5.3)
   - `load_impact_data()` : lire shared (¬ß5.4)
   - `get_impact_analysis()` : FROM `shared.match_participants` (¬ß5.5)
2. ‚úÖ **_match_queries.py** :
   - Simplifier `_get_match_source()` : retourner directement shared (¬ß6.1.1)
   - `load_match_mmr_batch()` : lire shared (¬ß6.1.2)
   - `get_match_count()` : COUNT DISTINCT depuis shared (¬ß6.1.3)
3. ‚úÖ **_roster_loader.py** :
   - Supprimer ~15 fallbacks locaux (¬ß6.2)
   - Toujours lire depuis shared

**Livrables** :
- Services teammates lisent shared uniquement
- Tests : `pytest tests/test_teammates_service.py tests/test_repositories.py -v`

**Validation** : Page "Analyse co√©quipiers" fonctionne correctement avec les donn√©es shared.

---

#### **PHASE 6 ‚Äî Repositories (partie 2) + UI critique** (1 jour)

**Objectif** : Finir les repositories et adapter les pages UI critiques.

**Fichiers modifi√©s** :
- [src/data/repositories/duckdb_repo.py](src/data/repositories/duckdb_repo.py) (¬ß6.3)
- [src/data/repositories/_materialized_views.py](src/data/repositories/_materialized_views.py) (¬ß6.4)
- [src/ui/pages/teammates_impact.py](src/ui/pages/teammates_impact.py) (¬ß3.2)
- [src/ui/pages/objective_analysis.py](src/ui/pages/objective_analysis.py) (¬ß3.5)

**T√¢ches** :
1. ‚úÖ **duckdb_repo.py** : 8 m√©thodes √† adapter (¬ß6.3) :
   - `load_top_medals()` : FROM `shared.medals_earned`
   - `load_match_medals()` : idem
   - `count_medal_by_match()` : idem
   - `load_first_event_times()` : FROM `shared.highlight_events`
   - `load_highlight_events()` : idem
   - `list_other_player_xuids()` : FROM `shared.match_participants`
   - `get_storage_info()` : refl√©ter les tables conserv√©es
   - `get_match_session_info()` : lire `player_match_enrichment`
2. ‚úÖ **_materialized_views.py** : 4 requ√™tes FROM `match_stats` ‚Üí shared (¬ß6.4)
3. ‚úÖ **teammates_impact.py** : FROM `shared.highlight_events` (¬ß3.2)
4. ‚úÖ **objective_analysis.py** : FROM shared (¬ß3.5)

**Livrables** :
- Repositories 100% sur shared
- Pages UI critiques fonctionnelles
- Tests : `pytest tests/test_ui.py -v`

**Validation** : Navigation dans l'app sur toutes les pages critiques sans erreur.

---

#### **PHASE 7 ‚Äî UI compl√®te + filtres** (1 jour)

**Objectif** : Finaliser toutes les pages UI et les filtres.

**Fichiers modifi√©s** :
- [src/ui/pages/citations.py](src/ui/pages/citations.py) (¬ß3.1)
- [src/ui/pages/personal_performance.py](src/ui/pages/personal_performance.py) (¬ß3.3)
- [src/ui/pages/media_library.py](src/ui/pages/media_library.py) (¬ß3.4)
- [src/app/filters.py](src/app/filters.py) (¬ß4.1)
- [src/app/filters_render.py](src/app/filters_render.py) (¬ß4.2)
- [src/ui/components/checkbox_filter.py](src/ui/components/checkbox_filter.py) (¬ß4.3)
- [scripts/sync.py](scripts/sync.py) (¬ß7.3)

**T√¢ches** :
1. ‚úÖ **citations.py** : requ√™tes shared (¬ß3.1)
2. ‚úÖ **personal_performance.py** : idem (¬ß3.3)
3. ‚úÖ **media_library.py** : FROM `shared.match_registry` (¬ß3.4)
4. ‚úÖ **filters.py** : `render_session_filters()` Polars natif (¬ß4.1)
5. ‚úÖ **filters_render.py** : type consistency (¬ß4.2)
6. ‚úÖ **checkbox_filter.py** : `& set(options)` ‚Üí ne pas vider s√©lections (¬ß4.3)
7. ‚úÖ **sync.py** : supprimer `rebuild_teammates_aggregate()`, adapter `print_stats()`, `_resolve_player_in_db()` (¬ß7.3)

**Livrables** :
- Toutes les pages UI fonctionnelles
- Filtres modes/maps/sessions corrects
- Tests : `pytest tests/test_filters.py -v`

**Validation** : Navigation compl√®te dans l'app, filtres appliqu√©s, sessions visibles.

---

#### **PHASE 8 ‚Äî Modules secondaires** (1 jour)

**Objectif** : Nettoyer les modules annexes (citations, media, viz, launcher).

**Fichiers modifi√©s** :
- [src/analysis/killer_victim.py](src/analysis/killer_victim.py) (¬ß8.2)
- [src/analysis/citations/engine.py](src/analysis/citations/engine.py) (¬ß8.1)
- [src/data/media_indexer.py](src/data/media_indexer.py) (¬ß9)
- [src/visualization/participation_radar.py](src/visualization/participation_radar.py) (¬ß10)
- [launcher.py](launcher.py) (¬ß7.4)
- [src/ui/multiplayer.py](src/ui/multiplayer.py) (¬ß6.5)
- [src/ui/cache_loaders.py](src/ui/cache_loaders.py) (¬ß6.6)
- [src/ui/cache_filters.py](src/ui/cache_filters.py) (¬ß6.7)
- [src/ui/aliases.py](src/ui/aliases.py) (¬ß6.8)
- [src/app/data_loader.py](src/app/data_loader.py) (¬ß6.9)
- [src/utils/xuid.py](src/utils/xuid.py) (¬ß6.10)

**T√¢ches** :
1. ‚úÖ **killer_victim.py** : corriger TypedDict `.kills` ‚Üí `["kills"]` (¬ß8.2)
2. ‚úÖ **citations/engine.py** : FROM shared, noms colonnes V5 (¬ß8.1)
3. ‚úÖ **media_indexer.py** : FROM `shared.match_registry`, ouvrir shared en read_only (¬ß9)
4. ‚úÖ **participation_radar.py** : FROM shared (¬ß10)
5. ‚úÖ **launcher.py** : discovery via shared (¬ß7.4)
6. ‚úÖ **multiplayer.py** : `list_duckdb_v4_players()` ‚Üí shared (¬ß6.5)
7. ‚úÖ Cache loaders, filters, aliases, data_loader, xuid : tous sur shared

**Livrables** :
- Tous les modules secondaires sur shared
- Tests : `pytest tests/ -v --ignore=tests/integration`

**Validation** : Suite de tests compl√®te passe.

---

#### **PHASE 9 ‚Äî Validation + cleanup brutal** (1 jour)

**Objectif** : Valider la migration compl√®te, puis supprimer brutalement les tables locales pour forcer la d√©tection de lectures r√©siduelles.

**T√¢ches** :
1. ‚úÖ Ex√©cuter les tests de compl√©tude (¬ß16) : tous les tests anti-r√©gression
2. ‚úÖ Tests manuels : naviguer dans toutes les pages de l'app
3. ‚úÖ Sync de test : `python scripts/sync.py --player TestPlayer --delta --max-matches 50`
4. ‚úÖ V√©rifier les donn√©es dans shared et `player_match_enrichment`
5. ‚úÖ **Cleanup brutal** : `python scripts/cleanup_player_dbs_v5.py --all --backup`
6. ‚úÖ Relancer l'app ET v√©rifier que tout fonctionne encore
7. ‚úÖ Si erreurs "table introuvable" ‚Üí identifier le code r√©siduel et corriger imm√©diatement

**Livrables** :
- Suite de tests compl√®te : ‚úÖ PASS
- App fonctionnelle apr√®s cleanup
- Tables locales supprim√©es : `match_stats`, `medals_earned`, etc. n'existent plus
- Rapport des tailles DBs avant/apr√®s cleanup

**Validation critique** :
```bash
# V√©rifier qu'aucune table supprim√©e n'existe plus
python -c "
import duckdb, json
from pathlib import Path
profiles = json.loads(Path('db_profiles.json').read_text())['profiles']
for gt, p in profiles.items():
    db = Path(p['db_path'])
    if not db.exists(): continue
    conn = duckdb.connect(str(db), read_only=True)
    tables = [r[0] for r in conn.execute('SELECT table_name FROM information_schema.tables').fetchall()]
    forbidden = {'match_stats', 'player_match_stats', 'medals_earned', 'highlight_events'}
    found = set(tables) & forbidden
    if found:
        print(f'‚ùå {gt}: tables interdites trouv√©es: {found}')
    conn.close()
print('‚úÖ Cleanup OK')
"
```

**‚ö†Ô∏è Point de vigilance** : Si l'app plante apr√®s cleanup ‚Üí c'est VOULU. Identifier le code qui lit encore les tables locales, le corriger, red√©ployer, puis relancer cleanup.

---

#### **PHASE 10 ‚Äî Documentation + d√©ploiement** (1 jour)

**Objectif** : Mettre √† jour TOUTE la documentation pour refl√©ter l'architecture V5 finale.

**Fichiers √† modifier selon ¬ß18** (13 fichiers) :

**Architecture (P0)** :
1. ‚úÖ [docs/ARCHITECTURE_V5.md](docs/ARCHITECTURE_V5.md) : sch√©ma √©tat cible (¬ß17), 31 colonnes `match_participants`, stop dual write
2. ‚úÖ [docs/SHARED_MATCHES_SCHEMA.md](docs/SHARED_MATCHES_SCHEMA.md) : 16 colonnes √©tendues, DDL complet
3. ‚úÖ [docs/SQL_SCHEMA.md](docs/SQL_SCHEMA.md) : tables supprim√©es de player DB
4. ‚úÖ [docs/DATA_ARCHITECTURE.md](docs/DATA_ARCHITECTURE.md) : flux sync ‚Üí shared uniquement

**Guides (P1-P2)** :
5. ‚úÖ [docs/SYNC_GUIDE.md](docs/SYNC_GUIDE.md) : sync √©crit shared + `player_match_enrichment`
6. ‚úÖ [docs/CLEANUP_V5.md](docs/CLEANUP_V5.md) : 8 tables supprim√©es, `--skip-coverage-check`
7. ‚úÖ [docs/CLEANUP_V5_QUICKSTART.md](docs/CLEANUP_V5_QUICKSTART.md) : s√©quence backup ‚Üí dry-run ‚Üí cleanup
8. ‚úÖ [docs/COMMANDS.md](docs/COMMANDS.md) : nouvelles options `--participants-enrich`
9. ‚úÖ [docs/BACKUP_RESTORE.md](docs/BACKUP_RESTORE.md) : backups plus petits apr√®s cleanup

**Docs internes IA (P0-P1)** :
10. ‚úÖ [CLAUDE.md](CLAUDE.md) : tables player DB r√©duites, colonnes `match_participants` √©tendues, co√©quipiers depuis shared
11. ‚úÖ [.github/copilot-instructions.md](.github/copilot-instructions.md) : idem
12. ‚úÖ [.ai/project_map.md](.ai/project_map.md) : flux sync, tables par DB
13. ‚úÖ [.ai/data_lineage.md](.ai/data_lineage.md) : API ‚Üí shared uniquement

**T√¢ches suppl√©mentaires** :
- ‚úÖ V√©rifier coh√©rence doc/code (grep pour rechercher `match_stats` dans les docs)
- ‚úÖ Mettre √† jour `README.md` si n√©cessaire
- ‚úÖ Mettre √† jour `CHANGELOG.md` : nouvelle version V5.1 "Final - Stop dual write"
- ‚úÖ Tag Git : `git tag v5.1.0-final`

**Livrables** :
- 13 fichiers de doc mis √† jour
- Coh√©rence doc/code v√©rifi√©e
- CHANGELOG.md √† jour
- Tag Git cr√©√©

**Validation** : Relecture crois√©e des 7 points d'architecture critiques (¬ß18.4) dans `ARCHITECTURE_V5.md` et `CLAUDE.md`.

---

### R√©capitulatif chronologique

| Phase | Dur√©e | Focus | Validation |
|-------|-------|-------|------------|
| **0** | 1j | Pr√©-requis : backup, baseline, inventaire | Donn√©es s√©curis√©es, √©tat initial document√© |
| **1** | 1j | ALTER TABLE shared + backfill | shared enrichie, couverture 100% |
| **2** | 1j | Transformers + mod√®les | Tests unitaires passent |
| **3** | 1j | Sync engine (stop dual write) | Sync de test OK, plus de dual write |
| **4** | 1j | Scripts backfill | Tous les modes sur shared |
| **5** | 1j | Services teammates + repositories (1/2) | Page co√©quipiers OK |
| **6** | 1j | Repositories (2/2) + UI critique | Pages critiques OK |
| **7** | 1j | UI compl√®te + filtres | Navigation compl√®te OK |
| **8** | 1j | Modules secondaires | Suite de tests compl√®te passe |
| **9** | 1j | Validation + cleanup brutal | App fonctionne apr√®s suppression tables locales |
| **10** | 1j | Documentation + d√©ploiement | Coh√©rence doc/code, tag Git |

**Total estim√©** : **11 jours ouvr√©s** (2 semaines + 1 jour) pour une migration compl√®te et s√©curis√©e.

**Strat√©gie de rollback** : Conserver les backups de Phase 0 pendant 1 mois apr√®s la Phase 10. En cas de probl√®me critique, restaurer les DBs et revenir au code avant Phase 2.

---

**Cr√©√© le** : 15 f√©vrier 2026
**Auteur** : Assistant IA (corrections suite aux rapports de bugs)
**Derni√®re mise √† jour** : 15 f√©vrier 2026 ‚Äî Plan migration V5 finale (stop dual write, cleanup brutal, documentation) ‚Äî **D√©coupage en 11 phases de 1 jour**
